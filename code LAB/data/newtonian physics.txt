Classical Mechanics
Joel A. Shapiro
October 5, 2010

ii
Copyright C 1994-2010 by Joel A. Shapiro
All rights reserved. No part of this publication may be reproduced, stored in
a retrieval system, or transmitted in any form or by any means, electronic,
mechanical, photocopying, or otherwise, without the prior written permission
of the author.
This is a preliminary version of the book, not to be considered a fully
published edition.
The author welcomes corrections, comments, and criticism.

Contents
1 Particle Kinematics
1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Single Particle Kinematics . . . . . . . . . . . . . . . . . . . .
1.2.1 Motion in configuration space . . . . . . . . . . . . . .
1.2.2 Conserved Quantities . . . . . . . . . . . . . . . . . . .
1.3 Systems of Particles . . . . . . . . . . . . . . . . . . . . . . . .
1.3.1 External and internal forces . . . . . . . . . . . . . . .
1.3.2 Constraints . . . . . . . . . . . . . . . . . . . . . . . .
1.3.3 Generalized Coordinates for Unconstrained Systems . .
1.3.4 Kinetic energy in generalized coordinates . . . . . . . .
1.4 Phase Space . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4.1 Dynamical Systems . . . . . . . . . . . . . . . . . . . .
1.4.2 Phase Space Flows . . . . . . . . . . . . . . . . . . . .

1
1
3
3
5
9
9
13
16
17
20
21
25

2 Lagrange‚Äôs and Hamilton‚Äôs Equations
2.1 Lagrangian for unconstrained systems . . . . . . . . . . . . . .
2.2 Lagrangian for Constrained Systems . . . . . . . . . . . . . .
2.2.1 Some examples of the use of Lagrangians . . . . . . . .
2.3 Hamilton‚Äôs Principle . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 Examples of functional variation . . . . . . . . . . . . .
2.4 Conserved Quantities . . . . . . . . . . . . . . . . . . . . . . .
2.4.1 Ignorable Coordinates . . . . . . . . . . . . . . . . . .
2.4.2 Energy Conservation . . . . . . . . . . . . . . . . . . .
2.5 Hamilton‚Äôs Equations . . . . . . . . . . . . . . . . . . . . . . .
2.6 Don‚Äôt plug Equations of Motion into the Lagrangian! . . . . .
2.7 Velocity-dependent forces . . . . . . . . . . . . . . . . . . . . .

35
36
39
42
44
46
48
48
50
52
54
55

iii

iv

CONTENTS

3 Two Body Central Forces
3.1 Reduction to a one dimensional problem . . . . . . . . . . . .
3.1.1 Reduction to a one-body problem . . . . . . . . . . . .
3.1.2 Reduction to one dimension . . . . . . . . . . . . . . .
3.2 Integrating the motion . . . . . . . . . . . . . . . . . . . . . .
3.2.1 The Kepler problem . . . . . . . . . . . . . . . . . . .
3.2.2 Nearly Circular Orbits . . . . . . . . . . . . . . . . . .
3.3 The Laplace-Runge-Lenz Vector . . . . . . . . . . . . . . . . .
3.4 The virial theorem . . . . . . . . . . . . . . . . . . . . . . . .
3.5 Rutherford Scattering . . . . . . . . . . . . . . . . . . . . . . .

65
65
65
67
68
70
73
76
77
78

4 Rigid Body Motion
85
4.1 Configuration space for a rigid body . . . . . . . . . . . . . . . 85
4.1.1 Orthogonal Transformations . . . . . . . . . . . . . . . 87
4.1.2 Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
4.2 Kinematics in a rotating coordinate system . . . . . . . . . . . 93
4.3 The moment of inertia tensor . . . . . . . . . . . . . . . . . . 97
4.3.1 Motion about a fixed point . . . . . . . . . . . . . . . . 97
4.3.2 More General Motion . . . . . . . . . . . . . . . . . . . 99
4.4 Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
4.4.1 Euler‚Äôs Equations . . . . . . . . . . . . . . . . . . . . . 106
4.4.2 Euler angles . . . . . . . . . . . . . . . . . . . . . . . . 112
4.4.3 The symmetric top . . . . . . . . . . . . . . . . . . . . 115
5 Small Oscillations
123
5.1 Small oscillations about stable equilibrium . . . . . . . . . . . 123
5.1.1 Molecular Vibrations . . . . . . . . . . . . . . . . . . . 126
5.1.2 An Alternative Approach . . . . . . . . . . . . . . . . . 132
5.2 Other interactions . . . . . . . . . . . . . . . . . . . . . . . . . 133
5.3 String dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . 134
5.4 Field theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
5.4.1 Lagrangian density . . . . . . . . . . . . . . . . . . . . 139
5.4.2 Three dimensional continua . . . . . . . . . . . . . . . 142
6 Hamilton‚Äôs Equations
153
6.1 Legendre transforms . . . . . . . . . . . . . . . . . . . . . . . 153
6.2 Variations on phase curves . . . . . . . . . . . . . . . . . . . . 158
6.3 Canonical transformations . . . . . . . . . . . . . . . . . . . . 159

CONTENTS
6.4
6.5
6.6
6.7
6.8

v

Poisson Brackets . . . . . . . . . . . . . . . . . . . . . . . . . 162
Higher Differential Forms . . . . . . . . . . . . . . . . . . . . . 167
The natural symplectic 2-form . . . . . . . . . . . . . . . . . . 175
6.6.1 Generating Functions . . . . . . . . . . . . . . . . . . . 179
Hamilton‚ÄìJacobi Theory . . . . . . . . . . . . . . . . . . . . . 187
Action-Angle Variables . . . . . . . . . . . . . . . . . . . . . . 192

7 Perturbation Theory
197
7.1 Integrable systems . . . . . . . . . . . . . . . . . . . . . . . . 197
7.2 Canonical Perturbation Theory . . . . . . . . . . . . . . . . . 206
7.2.1 Time Dependent Perturbation Theory . . . . . . . . . 208
7.3 Adiabatic Invariants . . . . . . . . . . . . . . . . . . . . . . . 210
7.3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . 210
7.3.2 For a time-independent Hamiltonian . . . . . . . . . . 210
7.3.3 Slow time variation in H(q, p, t) . . . . . . . . . . . . . 211
7.3.4 Systems with Many Degrees of Freedom . . . . . . . . 217
7.3.5 Formal Perturbative Treatment . . . . . . . . . . . . . 220
7.4 Rapidly Varying Perturbations . . . . . . . . . . . . . . . . . . 222
8 Field Theory
229
8.1 Lagrangian Mechanics for Fields . . . . . . . . . . . . . . . . . 229
8.2 Special Relativity . . . . . . . . . . . . . . . . . . . . . . . . . 239
8.3 Noether‚Äôs Theorem . . . . . . . . . . . . . . . . . . . . . . . . 242
8.3.1 Applications of Noether‚Äôs Theorem . . . . . . . . . . . 250
8.4 Examples of Relativistic Fields . . . . . . . . . . . . . . . . . 252
A Appendices
259
A.1 ijk and cross products . . . . . . . . . . . . . . . . . . . . . . 259
A.1.1 Vector Operations: Œ¥ij and ijk . . . . . . . . . . . . . . 259
A.2 The gradient operator . . . . . . . . . . . . . . . . . . . . . . 262
A.3 Gradient in Spherical Coordinates . . . . . . . . . . . . . . . . 264

vi

CONTENTS

Chapter 1
Particle Kinematics
1.1

Introduction

Classical mechanics, narrowly defined, is the investigation of the motion of
systems of particles in Euclidean three-dimensional space, under the influence
of specified force laws, with the motion‚Äôs evolution determined by Newton‚Äôs
second law, a second order differential equation. That is, given certain laws
determining physical forces, and some boundary conditions on the positions
of the particles at some particular times, the problem is to determine the positions of all the particles at all times. We will be discussing motions under
specific fundamental laws of great physical importance, such as Coulomb‚Äôs
law for the electrostatic force between charged particles. We will also discuss laws which are less fundamental, because the motion under them can be
solved explicitly, allowing them to serve as very useful models for approximations to more complicated physical situations, or as a testbed for examining
concepts in an explicitly evaluatable situation. Techniques suitable for broad
classes of force laws will also be developed.
The formalism of Newtonian classical mechanics, together with investigations into the appropriate force laws, provided the basic framework for
physics from the time of Newton until the beginning of the last century. The
systems considered had a wide range of complexity. One might consider a
single particle on which the Earth‚Äôs gravity acts. But one could also consider systems as the limit of an infinite number of very small particles, with
displacements smoothly varying in space, which gives rise to the continuum
limit. One example of this is the consideration of transverse waves on a
1

2

CHAPTER 1. PARTICLE KINEMATICS

stretched string, in which every point on the string has an associated degree
of freedom, its transverse displacement.
The scope of classical mechanics was broadened in the 19th century, in
order to consider electromagnetism. Here the degrees of freedom were not
just the positions in space of charged particles, but also other quantities,
distributed throughout space, such as the the electric field at each point.
This expansion in the type of degrees of freedom has continued, and now in
fundamental physics one considers many degrees of freedom which correspond
to no spatial motion, but one can still discuss the classical mechanics of such
systems.
As a fundamental framework for physics, classical mechanics gave way
on several fronts to more sophisticated concepts in the early 1900‚Äôs. Most
dramatically, quantum mechanics has changed our focus from specific solutions for the dynamical degrees of freedom as a function of time to the wave
function, which determines the probabilities that a system have particular
values of these degrees of freedom. Special relativity not only produced a
variation of the Galilean invariance implicit in Newton‚Äôs laws, but also is, at
a fundamental level, at odds with the basic ingredient of classical mechanics
‚Äî that one particle can exert a force on another, depending only on their
simultaneous but different positions. Finally general relativity brought out
the narrowness of the assumption that the coordinates of a particle are in a
Euclidean space, indicating instead not only that on the largest scales these
coordinates describe a curved manifold rather than a flat space, but also that
this geometry is itself a dynamical field.
Indeed, most of 20th century physics goes beyond classical Newtonian
mechanics in one way or another. As many readers of this book expect
to become physicists working at the cutting edge of physics research, and
therefore will need to go beyond classical mechanics, we begin with a few
words of justification for investing effort in understanding classical mechanics.
First of all, classical mechanics is still very useful in itself, and not just
for engineers. Consider the problems (scientific ‚Äî not political) that NASA
faces if it wants to land a rocket on a planet. This requires an accuracy
of predicting the position of both planet and rocket far beyond what one
gets assuming Kepler‚Äôs laws, which is the motion one predicts by treating
the planet as a point particle influenced only by the Newtonian gravitational
field of the Sun, also treated as a point particle. NASA must consider other
effects, and either demonstrate that they are ignorable or include them into
the calculations. These include

1.2. SINGLE PARTICLE KINEMATICS

3

‚Ä¢ multipole moments of the sun
‚Ä¢ forces due to other planets
‚Ä¢ effects of corrections to Newtonian gravity due to general relativity
‚Ä¢ friction due to the solar wind and gas in the solar system
Learning how to estimate or incorporate such effects is not trivial.
Secondly, classical mechanics is not a dead field of research ‚Äî in fact, in
the last few decades there has been a great deal of interest in ‚Äúdynamical
systems‚Äù. Attention has shifted from calculation of the trajectory over fixed
intervals of time to questions of the long-term stability of the motion. New
ways of looking at dynamical behavior have emerged, such as chaos and
fractal systems.
Thirdly, the fundamental concepts of classical mechanics provide the conceptual framework of quantum mechanics. For example, although the Hamiltonian and Lagrangian were developed as sophisticated techniques for performing classical mechanics calculations, they provide the basic dynamical
objects of quantum mechanics and quantum field theory respectively. One
view of classical mechanics is as a steepest path approximation to the path
integral which describes quantum mechanics. This integral over paths is of
a classical quantity depending on the ‚Äúaction‚Äù of the motion.
So classical mechanics is worth learning well, and we might as well jump
right in.

1.2

Single Particle Kinematics

We start with the simplest kind of system, a single unconstrained particle,
free to move in three dimensional space, under the influence of a force F~ .

1.2.1

Motion in configuration space

The motion of the particle is described by a function which gives its position as a function of time. These positions are points in Euclidean space.
Euclidean space is similar to a vector space, except that there is no special
point which is fixed as the origin. It does have a metric, that is, a notion
of distance between any two points, D(A, B). It also has the concept of a
displacement A ‚àí B from one point B in the Euclidean space to another,

4

CHAPTER 1. PARTICLE KINEMATICS

A. These displacements do form a vector space, and for a three-dimensional
Euclidean space, the vectors form a three-dimensional real vector space R3 ,
which can be given an orthonormal
qP basis such that the distance between A
3
2
and B is given by D(A, B) =
i=1 [(A ‚àí B)i ] . Because the mathematics
of vector spaces is so useful, we often convert our Euclidean space to a vector
space by choosing a particular point as the origin. Each particle‚Äôs position
is then equated to the displacement of that position from the origin, so that
it is described by a position vector ~r relative to this origin. But the origin
has no physical significance unless it has been choosen in some physically
meaningful way. In general the multiplication of a position vector by a scalar
is as meaningless physically as saying that 42nd street is three times 14th
street. The cartesian components of the vector ~r, with respect to some fixed
though arbitrary coordinate system, are called the coordinates, cartesian coordinates in this case. We shall find that we often (even usually) prefer to
change to other sets of coordinates, such as polar or spherical coordinates,
but for the time being we stick to cartesian coordinates.
The motion of the particle is the function ~r(t) of time. Certainly one of
the central questions of classical mechanics is to determine, given the physical
properties of a system and some initial conditions, what the subsequent motion is. The required ‚Äúphysical properties‚Äù is a specification of the force, F~ .
The beginnings of modern classical mechanics was the realization early in the
17th century that the physics, or dynamics, enters into the motion (or kinematics) through the force and its effect on the acceleration, and not through
any direct effect of dynamics on the position or velocity of the particle.
Most likely the force will depend on the position of the particle, say for a
particle in the gravitational field of a fixed (heavy) source at the origin, for
which
GM m
F~ (~r) = ‚àí 3 ~r.
r

(1.1)

But the force might also depend explicitly on time. For example, for the
motion of a spaceship near the Earth, we might assume that the force is
given by sum of the Newtonian gravitational forces of the Sun, Moon and
Earth. Each of these forces depends on the positions of the corresponding
heavenly body, which varies with time. The assumption here is that the
motion of these bodies is independent of the position of the light spaceship.
We assume someone else has already performed the nontrivial problem of
finding the positions of these bodies as functions of time. Given that, we

1.2. SINGLE PARTICLE KINEMATICS

5

can write down the force the spaceship feels at time t if it happens to be at
position ~r,
~ S (t)
~ E (t)
~r ‚àí R
~r ‚àí R
F~ (~r, t) = ‚àíGmMS
‚àí
GmM
E
|r ‚àí RS (t)|3
|r ‚àí RE (t)|3
~ M (t)
~r ‚àí R
‚àíGmMM
.
|r ‚àí RM (t)|3
So there is an explicit dependence on t Finally, the force might depend on
the velocity of the particle, as for example for the Lorentz force on a charged
particle in electric and magnetic fields
~ r, t) + q ~v √ó B(~
~ r, t).
F~ (~r, ~v , t) = q E(~

(1.2)

However the force is determined, it determines the motion of the particle
through the second order differential equation known as Newton‚Äôs Second
Law
d2~r
F~ (~r, ~v , t) = m~a = m 2 .
dt
As this is a second order differential equation, the solution depends in general
on two arbitrary (3-vector) parameters, which we might choose to be the
initial position and velocity, ~r(0) and ~v (0).
For a given physical situation and a given set of initial conditions for
the particle, Newton‚Äôs laws determine the motion ~r(t), which is a curve in
configuration space parameterized by time t, known as the trajectory in
configuration space. If we consider the curve itself, independent of how it
depends on time, this is called the orbit of the particle. For example, the
orbit of a planet, in the approximation that it feels only the field of a fixed
sun, is an ellipse. That word does not imply any information about the time
dependence or parameterization of the curve.

1.2.2

Conserved Quantities

While we tend to think of Newtonian mechanics as centered on Newton‚Äôs
Second Law in the form F~ = m~a, he actually started with the observation
that in the absence of a force, there was uniform motion. We would now say
that under these circumstances the momentum p~(t) is conserved, d~p/dt =

6

CHAPTER 1. PARTICLE KINEMATICS

0. In his second law, Newton stated the effect of a force as producing a rate
of change of momentum, which we would write as
F~ = d~p/dt,
rather than as producing an acceleration F~ = m~a. In focusing on the concept of momentum, Newton emphasized one of the fundamental quantities of
physics, useful beyond Newtonian mechanics, in both relativity and quantum
mechanics1 . Only after using the classical relation of momentum to velocity,
p~ = m~v , and the assumption that m is constant, do we find the familiar
F~ = m~a.
One of the principal tools in understanding the motion of many systems
is isolating those quantities which do not change with time. A conserved
quantity is a function of the positions and momenta, and perhaps explicitly
of time as well, Q(~r, p~, t), which remains unchanged when evaluated along
the actual motion, dQ(~r(t), p~(t), t)/dt = 0. A function depending on the
positions, momenta, and time is said to be a function on extended phase
space2 . When time is not included, the space is called phase space. In this
language, a conserved quantity is a function on extended phase space with
a vanishing total time derivative along any path which describes the motion
of the system.
A single particle with no forces acting on it provides a very simple example. As Newton tells us, p~Àô = d~p/dt = F~ = 0, so the momentum is conserved.
~ r, p~, t) := ~r(t) ‚àí t~p(t)/m, which
There are three more conserved quantities Q(~
Àô
~
have a time rate of change dQ/dt = ~r ‚àí p~/m ‚àítp~Àô/m = 0. These six independent conserved quantities are as many as one could have for a system with
a six dimensional phase space, and they completely solve for the motion. Of
course this was a very simple system to solve. We now consider a particle
under the influence of a force.
Energy
Consider a particle under the influence of an external force F~ . In general,
the momentum will not be conserved, although if any cartesian component
of the force vanishes along the motion, that component of the momentum
1
2

The relationship of momentum to velocity is changed in these extensions, however.
Phase space is discussed further in section 1.4.

1.2. SINGLE PARTICLE KINEMATICS

7

will be conserved. Also the kinetic energy, defined as T = 12 m~v 2 , will not
in general be conserved, because
dT
= m~vÀô ¬∑ ~v = F~ ¬∑ ~v .
dt
As the particle moves from the point ~ri to the point ~rf the total change in
the kinetic energy is the work done by the force F~ ,
‚àÜT =

Z ~rf

F~ ¬∑ d~r.

~
ri

If the force law F~ (~r, p~, t) applicable to the particle is independent of time
and velocity, then the work done will not depend on how quickly the particle
moved along the path from ~ri to ~rf . If in addition the work done is independent of the path taken between these points, so it depends only on the
endpoints, then the force is called a conservative force and we assosciate
with it potential energy
U (~r) = U (~r0 ) +

Z ~r0

F~ (~r 0 ) ¬∑ d~r 0 ,

~
r

where ~r0 is some arbitrary reference position and U (~r0 ) is an arbitrarily
chosen reference energy, which has no physical significance in ordinary mechanics. U (~r) represents the potential the force has for doing work on the
particle if the particle is at position ~r.
rf

The condition for the path integral to be independent of the path is
that it gives the same results along
any two coterminous paths Œì1 and Œì2 ,
or alternatively that it give zero when
evaluated along any closed path such
as Œì = Œì1 ‚àí Œì2 , the path consisting of
following Œì1 and then taking Œì2 backwards to the starting point. By Stokes‚Äô
Theorem, this line integral is equivalent to an integral over any surface S
bounded by Œì,
I
Œì

F~ ¬∑ d~r =

Z
S

~ √ó F~ dS.
‚àá

rf

Œì2

Œì
Œì1

ri

ri

R

R

Independence of path Œì1 = Œì2 is
equivalent to vanishing of the path
integral over closed paths Œì, which
is in turn equivalent to the vanishing
of the curl on the surface whose
boundary is Œì.

8

CHAPTER 1. PARTICLE KINEMATICS

Thus the requirement that the integral of F~ ¬∑ d~r vanish around any closed
path is equivalent to the requirement that the curl of F~ vanish everywhere
in space.
By considering an infinitesimal path from ~r to ~r + ‚àÜ~r, we see that
~ ‚àí U (~r) = ‚àíF~ ¬∑ ‚àÜ~r, or
U (~r + ‚àÜ)
~ (r).
F~ (r) = ‚àí‚àáU
The value of the concept of potential energy is that it enables finding
a conserved quantity, the total energy, in situtations in which all forces are
conservative. Then the total energy E = T + U changes at a rate
dE
dT
d~r ~
=
+
¬∑ ‚àáU = F~ ¬∑ ~v ‚àí ~v ¬∑ F~ = 0.
dt
dt
dt
The total energy can also be used in systems with both conservative and nonconservative forces, giving a quantity whose rate of change is determined by
the work done only by the nonconservative forces. One example of this usefulness is in the discussion of a slightly damped harmonic oscillator driven by
a periodic force near resonance. Then the amplitude of steady-state motion
is determined by a balence between the average power input by the driving
force and the average power dissipated by friction, the two nonconservative
forces in the problem, without needing to worry about the work done by the
spring.
Angular momentum
Another quantity which is often useful because it may be conserved is the angular momentum. The definition requires a reference point in the Euclidean
space, say ~r0 . Then a particle at position ~r with momentum p~ has an angu~ = (~r ‚àí ~r0 ) √ó p~. Very often we take the
lar momentum about ~r0 given by L
reference point ~r0 to be the same as the point we have chosen as the origin
in converting the Euclidian space to a vector space, so ~r0 = 0, and
~ = ~r √ó p~
L
~
d~r
d~p
1
dL
=
√ó p~ + ~r √ó
= p~ √ó p~ + ~r √ó F~ = 0 + ~œÑ = ~œÑ .
dt
dt
dt
m
where we have defined the torque about ~r0 as œÑ = (~r ‚àí ~r0 ) √ó F~ in general,
and œÑ = ~r √ó F~ when our reference point ~r0 is at the origin.

1.3. SYSTEMS OF PARTICLES

9

We see that if the torque ~œÑ (t) vanishes (at all times) the angular momentum is conserved. This can happen not only if the force is zero, but also if
the force always points to the reference point. This is the case in a central
force problem such as motion of a planet about the sun.

1.3

Systems of Particles

So far we have talked about a system consisting of only a single particle,
possibly influenced by external forces. Consider now a system of n particles
with positions ~ri , i = 1, . . . , n, in flat space. The configuration of the system
then has 3n coordinates (configuration space is R3n ), and the phase space
has 6n coordinates {~ri , p~i }.

1.3.1

External and internal forces

Let F~i be the total force acting on particle i. It is the sum of the forces
produced by each of the other particles and that due to any external force.
Let F~ji be the force particle j exerts on particle i and let F~iE be the external
force on particle i. Using Newton‚Äôs second law on particle i, we have
F~i = F~iE +

X

F~ji = p~Àôi = mi~vÀô i ,

j

where mi is the mass of the i‚Äôth particle. Here we are assuming forces have
identifiable causes, which is the real meaning of Newton‚Äôs second law, and
that the causes are either individual particles or external forces. Thus we are
assuming there are no ‚Äúthree-body‚Äù forces which are not simply the sum of
‚Äútwo-body‚Äù forces that one object exerts on another.
Define the center of mass and total mass
P

~ = Pmi~ri ,
R
mi

M=

X

mi .

Then if we define the total momentum
P~ =
we have

X

p~i =

X

mi~vi =

~
d X
dR
mi~ri = M
,
dt
dt

X
X
X
dP~
Àô XÀô
= P~ =
p~i =
F~i =
F~iE +
F~ji .
dt
i
ij

10

CHAPTER 1. PARTICLE KINEMATICS

Let us define F~ E =
Third Law holds,

~E
i Fi

P

to be the total external force. If Newton‚Äôs

F~ji = ‚àíF~ij , so

X

F~ij = 0, and

ij

Àô
P~ = F~ E .

(1.3)

Thus the internal forces cancel in pairs in their effect on the total momentum,
which changes only in response to the total external force. As an obvious
but very important consequence3 the total momentum of an isolated system
is conserved.
The total angular momentum is also just a sum over the individual angular momenta, so for a system of point particles,
~ =
L

X

~i =
L

X

~ri √ó p~i .

Its rate of change with time is
~
X
X
X
X
dL
~Àô =
=L
~vi √ó p~i +
~ri √ó F~i = 0 +
~ri √ó F~iE +
~ri √ó F~ji .
dt
i
i
ij
3

There are situations and ways of describing them in which the law of action and
reaction seems not to hold. For example, a current i1 flowing through a wire segment d~s1
~ = ¬µ0 i1 d~s1 √ó
contributes, according to the law of Biot and Savart, a magnetic field dB
3
~r/4œÄ|r| at a point ~r away from the current element. If a current i2 flows through a
segment of wire d~s2 at that point, it feels a force
¬µ0
d~s2 √ó (d~s1 √ó ~r)
F~12 =
i1 i2
4œÄ
|r|3
due to element 1. On the other hand F~21 is given by the same expression with d~s1 and
d~s2 interchanged and the sign of ~r reversed, so
¬µ0 i1 i2
[d~s1 (d~s2 ¬∑ ~r) ‚àí d~s2 (d~s1 ¬∑ ~r)] ,
F~12 + F~21 =
4œÄ |r|3
which is not generally zero.
One should not despair for the validity of momentum conservation. The Law of Biot
and Savart only holds for time-independent current distributions. Unless the currents form
closed loops, there will be a charge buildup and Coulomb forces need to be considered. If
the loops are
R R closed, the total momentum will involve integrals over the two closed loops,
for which
F12 + F21 can be shown to vanish. More generally, even the sum of the
momenta of the current elements is not the whole story, because there is momentum in
the electromagnetic field, which will be changing in the time-dependent situation.

1.3. SYSTEMS OF PARTICLES

11

The total external torque is naturally defined as
~œÑ =

X

~ri √ó F~iE ,

i

so we might ask if the last term vanishes due the Third Law, which permits
us to rewrite F~ji = 12 F~ji ‚àí F~ij . Then the last term becomes
1X
1X
~ri √ó F~ji =
~ri √ó F~ji ‚àí
~ri √ó F~ij
2
2
ij
ij
ij

X

=

1X
1X
~ri √ó F~ji ‚àí
~rj √ó F~ji
2 ij
2 ij

=

1X
(~ri ‚àí ~rj ) √ó F~ji .
2 ij

This is not automatically zero, but vanishes if one assumes a stronger form
of the Third Law, namely that the action and reaction forces between two
particles acts along the line of separation of the particles. If the force law
is independent of velocity and rotationally and translationally symmetric,
there is no other direction for it to point. For spinning particles and magnetic
forces the argument is not so simple ‚Äî in fact electromagnetic forces between
moving charged particles are really only correctly viewed in a context in which
the system includes not only the particles but also the fields themselves.
For such a system, in general the total energy, momentum, and angular
momentum of the particles alone will not be conserved, because the fields can
carry all of these quantities. But properly defining the energy, momentum,
and angular momentum of the electromagnetic fields, and including them in
the totals, will result in quantities conserved as a result of symmetries of the
underlying physics. This is further discussed in section 8.3.
Making the assumption that the strong form of Newton‚Äôs Third Law
holds, we have shown that
~œÑ =

~
dL
.
dt

(1.4)

The conservation laws are very useful because they permit algebraic solution for part of the velocity. Taking a single particle as an example, if
E = 12 mv 2 + U (~r) is conserved, the speed |v(t)| is determined at all times
~ is conserved,
(as a function of ~r) by one arbitrary constant E. Similarly if L

12

CHAPTER 1. PARTICLE KINEMATICS

the components of ~v which are perpendicular to ~r are determined in terms
~ With both conserved, ~v is completely determined
of the fixed constant L.
except for the sign of the radial component. Examples of the usefulness of
conserved quantities are everywhere, and will be particularly clear when we
consider the two body central force problem later. But first we continue our
discussion of general systems of particles.
As we mentioned earlier, the total angular momentum depends on the
point of evaluation, that is, the origin of the coordinate system used. We
now show that it consists of two contributions, the angular momentum about
the center of mass and the angular momentum of a fictitious point object
located at the center of mass. Let ~r 0i be the position of the i‚Äôth particle with
~ Then
respect to the center of mass, so ~r 0i = ~ri ‚àí R.
~ =
L

X

=

X

mi~ri √ó ~vi =

X

mi~r 0i √ó ~rÀô 0i +

X

i



~ √ó ~rÀô 0 + R
~Àô
mi ~r 0i + R
i






i

i

~Àô
mi~r 0i √ó R

i

~ √óR
~Àô
mi~rÀô 0i + M R
X
~ √ó P~ .
=
~r 0i √ó ~p 0i + R
~√ó
+R

X

i

Here we have noted that mi~r 0i = 0, and also its derivative mi~v 0i = 0.
We have defined ~p 0i = mi~v 0i , the momentum in the center of mass reference
frame. The first term of the final form is the sum of the angular momenta
of the particles about their center of mass, while the second term is the
angular momentum the system would have if it were collapsed to a point at
the center of mass. Notice we did not need to assume the center of mass is
unaccelerated.
What about the total energy? The kinetic energy
P

1X  0 ~  0 ~
1X
mi vi2 =
mi ~v i + V ¬∑ ~v i + V
2
2
1X
1
2
=
mi v 0 i + M V 2 ,
2
2

P

T =

(1.5)

~Àô is the velocity of the center of mass. The cross term vanishes
where V~ = R
P
once again, because mi~v 0i = 0. Thus the kinetic energy of the system can
also be viewed as the sum of the kinetic energies of the constituents about

1.3. SYSTEMS OF PARTICLES

13

the center of mass, plus the kinetic energy the system would have if it were
collapsed to a particle at the center of mass.
If the forces on the system are due to potentials, the total energy will
be conserved, but this includes not only the potential due to the external
P
forces but also that due to interparticle forces, Uij (~ri , ~rj ). In general this
contribution will not be zero or even constant with time, and the internal
potential energy will need to be considered. One exception to this is the case
of a rigid body.

1.3.2

Constraints

A rigid body is defined as a system of n particles for which all the interparticle distances are constrained to fixed constants, |~ri ‚àí ~rj | = cij , and the
interparticle potentials are functions only of these interparticle distances. As
these distances do not vary, neither does the internal potential energy. These
interparticle forces cannot do work, and the internal potential energy may
be ignored.
The rigid body is an example of a constrained system, in which the general 3n degrees of freedom are restricted by some forces of constraint which
place conditions on the coordinates ~ri , perhaps in conjunction with their momenta. In such descriptions we do not wish to consider or specify the forces
themselves, but only their (approximate) effect. The forces are assumed to
be whatever is necessary to have that effect. It is generally assumed, as in
the case with the rigid body, that the constraint forces do no work under displacements allowed by the constraints. We will consider this point in more
detail later.
If the constraints can be phrased so that they are on the coordinates
and time only, as Œ¶i (~r1 , ...~rn , t) = 0, i = 1, . . . , k, they are known as holonomic constraints. These constraints determine hypersurfaces in configuration space to which all motion of the system is confined. In general this
hypersurface forms a 3n ‚àí k dimensional manifold. We might describe the
configuration point on this manifold in terms of 3n ‚àí k generalized coordinates, qj , j = 1, . . . , 3n ‚àí k, so that the 3n ‚àí k variables qj , together with the
k constraint conditions Œ¶i ({~ri }) = 0, determine the ~ri = ~ri (q1 , . . . , q3n‚àík , t)

14

CHAPTER 1. PARTICLE KINEMATICS

The constrained subspace of
configuration space need not be a
flat space. Consider, for examz
ple, a mass on one end of a rigid
light rod of length L, the other
Œ∏
end of which is fixed to be at the
L
origin ~r = 0, though the rod is
completely free to rotate. Clearly
the possible values of the cartey
sian coordinates ~r of the position
œï
of the mass satisfy the constraint
|~r| = L, so ~r lies on the surx
face of a sphere of radius L. We
might choose as generalized coorGeneralized coordinates (Œ∏, œÜ) for
dinates the standard spherical ana particle constrained to lie on a
gles Œ∏ and œÜ. Thus the constrained
sphere.
subspace is two dimensional but
[Note: mathematics books tend
not flat ‚Äî rather it is the surface
to interchange Œ∏ and œÜ from the
of a sphere, which mathematicians
choice we use here, which is what
call S 2 . It is natural to reexpress
most physics books use.]
the dynamics in terms of Œ∏ and œÜ.
Note that with this constrained configuration space, we see that ideas
common in Euclidean space are no longer clear. The displacement between
two points A and B, as a three vector, cannot be added to a general point
C, and in two dimensions, a change, for example, of ‚àÜœÜ is a very differnent
change in configuration depending on what Œ∏ is.
The use of generalized (non-cartesian) coordinates is not just for constrained systems. The motion of a particle in a central force field about the
origin, with a potential U (~r) = U (|~r|), is far more naturally described in
terms of spherical coordinates r, Œ∏, and œÜ than in terms of x, y, and z.
Before we pursue a discussion of generalized coordinates, it must be
pointed out that not all constraints are holonomic. The standard example is
a disk of radius R, which rolls on a fixed horizontal plane. It is constrained
to always remain vertical, and also to roll without slipping on the plane. As
coordinates we can choose the x and y of the center of the disk, which are
also the x and y of the contact point, together with the angle a fixed line on
the disk makes with the downward direction, œÜ, and the angle the axis of the
disk makes with the x axis, Œ∏.

1.3. SYSTEMS OF PARTICLES

15

As the disk rolls through an
angle dœÜ, the point of contact
moves a distance RdœÜ in a direction depending on Œ∏,

z
R

RdœÜ sin Œ∏ = dx
RdœÜ cos Œ∏ = dy
Dividing by dt, we get two constraints involving the positions
and velocities,
Œ¶1 := RœÜÃá sin Œ∏ ‚àí xÃá = 0
Œ¶2 := RœÜÃá cos Œ∏ ‚àí yÃá = 0.
The fact that these involve
velocities does not automatically make them nonholonomic.
In the simpler one-dimensional
problem in which the disk is
confined to the yz plane, rolling

œÜ
x

y

Œ∏

A vertical disk free to roll on a plane. A
fixed line on the disk makes an angle of œÜ
with respect to the vertical, and the axis of
the disk makes an angle Œ∏ with the x-axis.
The long curved path is the trajectory of
the contact point. The three small paths
are alternate trajectories illustrating that
x, y, and œÜ can each be changed without
any net change in the other coordinates.

along x = 0 (Œ∏ = 0), we would have only the coordinates œÜ and y, with
the rolling constraint RœÜÃá ‚àí yÃá = 0. But this constraint can be integrated,
RœÜ(t) ‚àí y(t) = c, for some constant c, so that it becomes a constraint among
just the coordinates, and is holomorphic. This cannot be done with the twodimensional problem. We can see that there is no constraint among the four
coordinates themselves because each of them can be changed by a motion
which leaves the others unchanged. Rotating Œ∏ without moving the other
coordinates is straightforward. By rolling the disk along each of the three
small paths shown to the right of the disk, we can change one of the variables
x, y, or œÜ, respectively, with no net change in the other coordinates. Thus
all values of the coordinates4 can be achieved in this fashion.
There are other, less interesting, nonholonomic constraints given by inequalities rather than constraint equations. A bug sliding down a bowling
4

Thus the configuration space is x ‚àà R, y ‚àà R, Œ∏ ‚àà [0, 2œÄ) and œÜ ‚àà [0, 2œÄ), or, if
we allow more carefully for the continuity as Œ∏ and œÜ go through 2œÄ, the more accurate
2
statement is that configuration space is R √ó (S 1 )2 , where S 1 is the circumference of a
circle, Œ∏ ‚àà [0, 2œÄ], with the requirement that Œ∏ = 0 is equivalent to Œ∏ = 2œÄ.

16

CHAPTER 1. PARTICLE KINEMATICS

ball obeys the constraint |~r| ‚â• R. Such problems are solved by considering
the constraint with an equality (|~r| = R), but restricting the region of validity of the solution by an inequality on the constraint force (N ‚â• 0), and
then supplementing with the unconstrained problem once the bug leaves the
surface.
In quantum field theory, anholonomic constraints which are functions of
the positions and momenta are further subdivided into first and second class
constraints aÃÄ la Dirac, with the first class constraints leading to local gauge
invariance, as in Quantum Electrodynamics or Yang-Mills theory. But this
is heading far afield.

1.3.3

Generalized Coordinates for Unconstrained Systems

Before we get further into constrained systems and D‚ÄôAlembert‚Äôs Principle,
we will discuss the formulation of a conservative unconstrained system in
generalized coordinates. Thus we wish to use 3n generalized coordinates qj ,
which, together with time, determine all of the 3n cartesian coordinates ~ri :
~ri = ~ri (q1 , ..., q3n , t).
Notice that this is a relationship between different descriptions of the same
point in configuration space, and the functions ~ri ({q}, t) are independent of
the motion of any particle. We are assuming that the ~ri and the qj are each
a complete set of coordinates for the space, so the q‚Äôs are also functions of
the {~ri } and t:
qj = qj (~r1 , ..., ~rn , t).
The t dependence permits there to be an explicit dependence of this relation
on time, as we would have, for example, in relating a rotating coordinate
system to an inertial cartesian one.
Let us change the cartesian coordinate notation slightly, with {xk } the
3n cartesian coordinates of the n 3-vectors ~ri , deemphasizing the division of
these coordinates into triplets.
A small change in the coordinates of a particle in configuration space,
whether an actual change over a small time interval dt or a ‚Äúvirtual‚Äù change
between where a particle is and where it might have been under slightly
altered circumstances, can be described by a set of Œ¥xk or by a set of Œ¥qj . If

1.3. SYSTEMS OF PARTICLES

17

we are talking about a virtual change at the same time, these are related by
the chain rule
Œ¥xk =

X ‚àÇxk
j

‚àÇqj

Œ¥qj ,

Œ¥qj =

X ‚àÇqj
k

‚àÇxk

Œ¥xk ,

(for Œ¥t = 0).

(1.6)

For the actual motion through time, or any variation where Œ¥t is not assumed
to be zero, we need the more general form,
Œ¥xk =

X ‚àÇxk
j

‚àÇqj

Œ¥qj +

‚àÇxk
Œ¥t,
‚àÇt

Œ¥qj =

X ‚àÇqj
k

‚àÇxk

Œ¥xk +

‚àÇqk
Œ¥t.
‚àÇt

(1.7)

A virtual displacement, with Œ¥t = 0, is the kind of variation we need to
find the forces described by a potential. Thus the force is
Fk = ‚àí

X ‚àÇU ({x({q})}) ‚àÇqj
X ‚àÇqj
‚àÇU ({x})
=‚àí
=
Qj ,
‚àÇxk
‚àÇqj
‚àÇxk
j
j ‚àÇxk

(1.8)

where
Qj :=

X
k

Fk

‚àÇU ({x({q})})
‚àÇxk
=‚àí
‚àÇqj
‚àÇqj

(1.9)

is known as the generalized force. We may think of UÃÉ (q, t) := U (x(q), t)
as a potential in the generalized coordinates {q}. Note that if the coordinate
transformation is time-dependent, it is possible that a time-independent potential U (x) will lead to a time-dependent potential UÃÉ (q, t), and a system
with forces described by a time-dependent potential is not conservative.
The definition of the generalized force Qj in the left part of (1.9) holds
even if the cartesian force is not described by a potential.
The qk do not necessarily have units of distance. For example, one qk
might be an angle, as in polar or spherical coordinates. The corresponding
component of the generalized force will have the units of energy and we might
consider it a torque rather than a force.

1.3.4

Kinetic energy in generalized coordinates

We have seen that, under the right circumstances, the potential energy can be
thought of as a function of the generalized coordinates qk , and the generalized

18

CHAPTER 1. PARTICLE KINEMATICS

forces Qk are given by the potential just as for ordinary cartesian coordinates
and their forces. Now we examine the kinetic energy
T =

2
1X
1X
mi~rÀôi =
mj xÃá2j
2 i
2 j

where the 3n values mj are not really independent, as each particle has the
same mass in all three dimensions in ordinary Newtonian mechanics5 . Now
Ô£´

Ô£∂

X ‚àÇxj
‚àÜqk Ô£∏ ‚àÇxj
‚àÜxj
= lim Ô£≠
+
,
xÃáj = lim
‚àÜt‚Üí0
‚àÜt‚Üí0 ‚àÜt
‚àÇt q
k ‚àÇqk q,t ‚àÜt

where |q,t means that t and the q‚Äôs other than qk are held fixed. The last
term is due to the possibility that the coordinates xi (q1 , ..., q3n , t) may vary
with time even for fixed values of qk . So the chain rule is giving us

xÃáj =

‚àÇxj
dxj X ‚àÇxj
qÃák +
=
.
dt
‚àÇt q
k ‚àÇqk q,t

(1.10)

Plugging this into the kinetic energy, we see that
Ô£´

Ô£∂2

X
‚àÇxj Ô£∏
1X
1X
‚àÇxj ‚àÇxj
‚àÇxj ‚àÇxj
mj Ô£≠
T =
mj
qÃák qÃá` +
mj
qÃák
+
. (1.11)
2 j,k,`
‚àÇqk ‚àÇq`
‚àÇq
‚àÇt
2
‚àÇt
k
j
j,k
q
q

What is the interpretation of these terms? Only the first term arises if the
relation between x and q is time independent. The second and third terms
are the sources of the ~rÀô ¬∑ (~œâ √ó ~r) and (~œâ √ó ~r)2 terms in the kinetic energy
when we consider rotating coordinate systems6 .

5

But in an anisotropic crystal, the effective mass of a particle might in fact be different
in different directions.
6
This will be fully developed in section 4.2

1.3. SYSTEMS OF PARTICLES

19

Let‚Äôs work a simple example: we
will consider a two dimensional system
using polar coordinates with Œ∏ measured
from a direction rotating at angular velocity œâ. Thus the angle the radius vector to an arbitrary point (r, Œ∏) makes
with the inertial x1 -axis is Œ∏ + œât, and
the relations are

r
Œ∏
œât

x2

x1

x1 = r cos(Œ∏ + œât),
x2 = r sin(Œ∏ + œât),
Rotating polar coordinates
related to inertial cartesian
coordinates.

with inverse relations
r =

q

x21 + x22 ,

Œ∏ = sin‚àí1 (x2 /r) ‚àí œât.
So xÃá1 = rÃá cos(Œ∏ + œât) ‚àí Œ∏Ãár sin(Œ∏ + œât) ‚àí œâr sin(Œ∏ + œât), where the last term
is from ‚àÇxj /‚àÇt, and xÃá2 = rÃá sin(Œ∏ + œât) + Œ∏Ãár cos(Œ∏ + œât) + œâr cos(Œ∏ + œât). In
P
the square, things get a bit simpler, xÃá2i = rÃá2 + r2 (œâ + Œ∏Ãá)2 .
We see that the form of the kinetic energy in terms of the generalized coordinates and their velocities is much more complicated than it is in cartesian
inertial coordinates, where it is coordinate independent, and a simple diagonal quadratic form in the velocities. In generalized coordinates, it is quadratic
but not homogeneous7 in the velocities, and with an arbitrary dependence on
the coordinates. In general, even if the coordinate transformation is time independent, the form of the kinetic energy is still coordinate dependent and,
while a purely quadratic form in the velocities, it is not necessarily diagonal.
In this time-independent situation, we have
T =

1X
Mk` ({q})qÃák qÃá` ,
2 k`

with

Mk` ({q}) =

X
j

mj

‚àÇxj ‚àÇxj
,
‚àÇqk ‚àÇq`

(1.12)

where Mk` is known as the mass matrix, and is always symmetric but not
necessarily diagonal or coordinate independent.
The mass matrix is independent of the ‚àÇxj /‚àÇt terms, and we can understand the results we just obtained for it in our two-dimensional example
7

It involves quadratic and lower order terms in the velocities, not just quadratic ones.

20

CHAPTER 1. PARTICLE KINEMATICS

above,
M11 = m,

M12 = M21 = 0,

M22 = mr2 ,

by considering the case without rotation, œâ = 0. We can also derive this
expression for the kinetic energy in nonrotating polar coordinates by expressing the velocity vector ~v = rÃáeÃÇr + rŒ∏ÃáeÃÇŒ∏ in terms of unit vectors in the
radial and tangential directions respectively. The coefficients of these unit
vectors can be understood graphically with geometric arguments. This leads
more quickly to ~v 2 = (rÃá)2 + r2 (Œ∏Ãá)2 , T = 12 mrÃá2 + 21 mr2 Œ∏Ãá2 , and the mass matrix
follows. Similar geometric arguments are usually used to find the form of the
kinetic energy in spherical coordinates, but the formal approach of (1.12)
enables us to find the form even in situations where the geometry is difficult
to picture.
It is important to keep in mind that when we view T as a function of
coordinates and velocities, these are independent arguments evaluated at a
particular moment of time. Thus we can ask independently how T varies as
we change xi or as we change xÃái , each time holding the other variable fixed.
Thus the kinetic energy is not a function on the 3n-dimensional configuration
space, but on a larger, 6n-dimensional space8 with a point specifying both
the coordinates {qi } and the velocities {qÃái }.

1.4

Phase Space

If the trajectory of the system in configuration space, ~r(t), is known, the
velocity as a function of time, ~v (t) is also determined. As the mass of the
particle is simply a physical constant, the momentum p~ = m~v contains the
same information as the velocity. Viewed as functions of time, this gives
nothing beyond the information in the trajectory. But at any given time,
~r and p~ provide a complete set of initial conditions, while ~r alone does not.
We define phase space as the set of possible positions and momenta for
the system at some instant. Equivalently, it is the set of possible initial
conditions, or the set of possible motions obeying the equations of motion9 .
For a single particle in cartesian coordinates, the six coordinates of phase
8

This space is called the tangent bundle to configuration space. For cartesian coordinates it is almost identical to phase space, which is in general the ‚Äúcotangent bundle‚Äù
to configuration space.
9
As each initial condition gives rise to a unique future development of a trajectory,
there is an isomorphism between initial conditions and allowed trajectories.

1.4. PHASE SPACE

21

space are the three components of ~r and the three components of p~. At any
instant of time, the system is represented by a point in this space, called the
phase point, and that point moves with time according to the physical laws
of the system. These laws are embodied in the force function, which we now
consider as a function of p~ rather than ~v , in addition to ~r and t. We may
write these equations as
p~
d~r
=
,
dt
m
d~p
= F~ (~r, p~, t).
dt
Note that these are first order equations, which means that the motion of
the point representing the system in phase space is completely determined10
by where the phase point is. This is to be distinguished from the trajectory
in configuration space, where in order to know the trajectory you must have
not only an initial point (position) but also its initial time derivative.

1.4.1

Dynamical Systems

We have spoken of the coordinates of phase space for a single particle as ~r and
p~, but from a mathematical point of view these together give the coordinates
of the phase point in phase space. We might describe these coordinates in
terms of a six dimensional vector ~Œ∑ = (r1 , r2 , r3 , p1 , p2 , p3 ). The physical laws
determine at each point a velocity function for the phase point as it moves
through phase space,
d~Œ∑
= V~ (~Œ∑ , t),
(1.13)
dt
which gives the velocity at which the phase point representing the system
moves through phase space. Only half of this velocity is the ordinary velocity,
while the other half represents the rapidity with which the momentum is
changing, i.e. the force. The path traced by the phase point as it travels
through phase space is called the phase curve.
For a system of n particles in three dimensions, the complete set of initial
conditions requires 3n spatial coordinates and 3n momenta, so phase space is
6n dimensional. While this certainly makes visualization difficult, the large
10

We will assume throughout that the force function is a well defined continuous function
of its arguments.

22

CHAPTER 1. PARTICLE KINEMATICS

dimensionality is no hindrance for formal developments. Also, it is sometimes
possible to focus on particular dimensions, or to make generalizations of ideas
familiar in two and three dimensions. For example, in discussing integrable
systems (7.1), we will find that the motion of the phase point is confined
to a 3n-dimensional torus, a generalization of one and two dimensional tori,
which are circles and the surface of a donut respectively.
Thus for a system composed of a finite number of particles, the dynamics
is determined by the first order ordinary differential equation (1.13), formally
a very simple equation. All of the complication of the physical situation is
hidden in the large dimensionality of the dependent variable ~Œ∑ and in the
functional dependence of the velocity function V (~Œ∑ , t) on it.
There are other systems besides Newtonian mechanics which are controlled by equation (1.13), with a suitable velocity function. Collectively
these are known as dynamical systems. For example, individuals of an
asexual mutually hostile species might have a fixed birth rate b and a death
rate proportional to the population, so the population would obey the logistic equation11 dp/dt = bp‚àícp2 , a dynamical system with a one-dimensional
space for its dependent variable. The populations of three competing species
could be described by eq. (1.13) with ~Œ∑ in three dimensions.
The dimensionality d of ~Œ∑ in (1.13) is called the order of the dynamical
system. A d‚Äôth order differential equation in one independent variable may
always be recast as a first order differential equation in d variables, so it is one
example of a d‚Äôth order dynamical system. The space of these dependent variables is called the phase space of the dynamical system. Newtonian systems
always give rise to an even-order system, because each spatial coordinate is
paired with a momentum. For n particles unconstrained in D dimensions, the
order of the dynamical system is d = 2nD. Even for constrained Newtonian
systems, there is always a pairing of coordinates and momenta, which gives
a restricting structure, called the symplectic structure12 , on phase space.
If the force function does not depend explicitly on time, we say the system
is autonomous. The velocity function has no explicit dependance on time,
V~ = V~ (~Œ∑ ), and is a time-independent vector field on phase space, which we
can indicate by arrows just as we might the electric field in ordinary space,
or the velocity field of a fluid in motion. This gives a visual indication of
11

This is not to be confused with the simpler logistic map, which is a recursion relation
with the same form but with solutions displaying a very different behavior.
12
This will be discussed in sections (6.3) and (6.6).

1.4. PHASE SPACE

23

the motion of the system‚Äôs point. For example, consider a damped harmonic
oscillator with F~ = ‚àíkx ‚àí Œ±p, for which the velocity function is
dx dp
,
dt dt

!



=

p
, ‚àíkx ‚àí Œ±p .
m


A plot of this field for the undamped (Œ± = 0) and damped oscillators is
p

p

x

x

Undamped
Damped
Figure 1.1: Velocity field for undamped and damped harmonic oscillators,
and one possible phase curve for each system through phase space.

shown in Figure 1.1. The velocity field is everywhere tangent to any possible
path, one of which is shown for each case. Note that qualitative features of
the motion can be seen from the velocity field without any solving of the
differential equations; it is clear that in the damped case the path of the
system must spiral in toward the origin.
The paths taken by possible physical motions through the phase space of
an autonomous system have an important property. Because the rate and
direction with which the phase point moves away from a given point of phase
space is completely determined by the velocity function at that point, if the
system ever returns to a point it must move away from that point exactly as
it did the last time. That is, if the system at time T returns to a point in
phase space that it was at at time t = 0, then its subsequent motion must be
just as it was, so ~Œ∑ (T + t) = ~Œ∑ (t), and the motion is periodic with period
T . This almost implies that the phase curve the object takes through phase
space must be nonintersecting13 .
In the non-autonomous case, where the velocity field is time dependent,
it may be preferable to think in terms of extended phase space, a 6n + 1
13

An exception can occur at an unstable equilibrium point, where the velocity function
vanishes. The motion can just end at such a point, and several possible phase curves can
terminate at that point.

24

CHAPTER 1. PARTICLE KINEMATICS

dimensional space with coordinates (~Œ∑ , t). The velocity field can be extended
to this space by giving each vector a last component of 1, as dt/dt = 1. Then
the motion of the system is relentlessly upwards in this direction, though
still complex in the others. For the undamped one-dimensional harmonic
oscillator, the path is a helix in the three dimensional extended phase space.
Most of this book is devoted to finding analytic methods for exploring the
motion of a system. In several cases we will be able to find exact analytic
solutions, but it should be noted that these exactly solvable problems, while
very important, cover only a small set of real problems. It is therefore important to have methods other than searching for analytic solutions to deal with
dynamical systems. Phase space provides one method for finding qualitative
information about the solutions. Another approach is numerical. Newton‚Äôs
Law, and more generally the equation (1.13) for a dynamical system, is a set
of ordinary differential equations for the evolution of the system‚Äôs position
in phase space. Thus it is always subject to numerical solution given an
initial configuration, at least up until such point that some singularity in the
velocity function is reached. One primitive technique which will work for all
such systems is to choose a small time interval of length ‚àÜt, and use d~Œ∑ /dt at
the beginning of each interval to approximate ‚àÜ~Œ∑ during this interval. This
gives a new approximate value for ~Œ∑ at the end of this interval, which may
then be taken as the beginning of the next.14

14

This is a very unsophisticated method. The errors made in each step for ‚àÜ~r and ‚àÜ~
p
are typically O(‚àÜt)2 . As any calculation of the evolution from time t0 to tf will involve
a number ([tf ‚àí t0 ]/‚àÜt) of time steps which grows inversely to ‚àÜt, the cumulative error
can be expected to be O(‚àÜt). In principle therefore we can approach exact results for a
finite time evolution by taking smaller and smaller time steps, but in practise there are
other considerations, such as computer time and roundoff errors, which argue strongly in
favor of using more sophisticated numerical techniques, with errors of higher order in ‚àÜt.
Increasingly sophisticated methods can be generated which give cumulative errors of order
O((‚àÜt)n ), for any n. A very common technique is called fourth-order Runge-Kutta, which
gives an error O((‚àÜt)5 ). These methods can be found in any text on numerical methods.

1.4. PHASE SPACE

25

As an example, we show the
meat of a calculation for the
damped harmonic oscillator. This
while (t < tf) {
same technique will work even with
dx = (p/m) * dt;
a very complicated situation. One
dp = -(k*x+alpha*p)*dt;
need only add lines for all the comx = x + dx;
ponents of the position and mop = p + dp;
mentum, and change the force law
t = t + dt;
appropriately.
print t, x, p;
This is not to say that numeri}
cal solution is a good way to solve
this problem. An analytical solu- Integrating the motion, for a
tion, if it can be found, is almost damped harmonic oscillator.
always preferable, because

‚Ä¢ It is far more likely to provide insight into the qualitative features of
the motion.
‚Ä¢ Numerical solutions must be done separately for each value of the parameters (k, m, Œ±) and each value of the initial conditions (x0 and p0 ).
‚Ä¢ Numerical solutions have subtle numerical problems in that they are
only exact as ‚àÜt ‚Üí 0, and only if the computations are done exactly. Sometimes uncontrolled approximate solutions lead to surprisingly large errors.
Nonetheless, numerical solutions are often the only way to handle a real problem, and there has been extensive development of techniques for efficiently
and accurately handling the problem, which is essentially one of solving a
system of first order ordinary differential equations.

1.4.2

Phase Space Flows

As we just saw, Newton‚Äôs equations for a system of particles can be cast in
the form of a set of first order ordinary differential equations in time on phase
space, with the motion in phase space described by the velocity field. This
could be more generally discussed as a d‚Äôth order dynamical system, with a
phase point representing the system in a d-dimensional phase space, moving

26

CHAPTER 1. PARTICLE KINEMATICS

with time t along the velocity field, sweeping out a path in phase space called
the phase curve. The phase point ~Œ∑ (t) is also called the state of the system
at time t. Many qualitative features of the motion can be stated in terms of
the phase curve.
Fixed Points
There may be points ~Œ∑k , known as fixed points, at which the velocity function vanishes, V~ (~Œ∑k ) = 0. This is a point of equilibrium for the system, for if
the system is at a fixed point at one moment, ~Œ∑ (t0 ) = ~Œ∑k , it remains at that
point. At other points, the system does not stay put, but there may be sets
of states which flow into each other, such as the elliptical orbit for the undamped harmonic oscillator. These are called invariant sets of states. In
a first order dynamical system15 , the fixed points divide the line into intervals
which are invariant sets.
Even though a first-order system is smaller than any Newtonian system, it
is worthwhile discussing briefly the phase flow there. We have been assuming
the velocity function is a smooth function ‚Äî generically its zeros will be first
order, and near the fixed point Œ∑0 we will have V (Œ∑) ‚âà c(Œ∑ ‚àí Œ∑0 ). If the
constant c < 0, dŒ∑/dt will have the opposite sign from Œ∑ ‚àí Œ∑0 , and the system
will flow towards the fixed point, which is therefore called stable. On the
other hand, if c > 0, the displacement Œ∑ ‚àí Œ∑0 will grow with time, and the
fixed point is unstable. Of course there are other possibilities: if V (Œ∑) = cŒ∑ 2 ,
the fixed point Œ∑ = 0 is stable from the left and unstable from the right. But
this kind of situation is somewhat artificial, and such a system is structually
unstable. What that means is that if the velocity field is perturbed by a
small smooth variation V (Œ∑) ‚Üí V (Œ∑) + w(Œ∑), for some bounded smooth
function w, the fixed point at Œ∑ = 0 is likely to either disappear or split
into two fixed points, whereas the fixed points discussed earlier will simply
be shifted by order  in position and will retain their stability or instability.
Thus the simple zero in the velocity function is structurally stable. Note
that structual stability is quite a different notion from stability of the fixed
point.
In this discussion of stability in first order dynamical systems, we see that
generically the stable fixed points occur where the velocity function decreases
through zero, while the unstable points are where it increases through zero.
15

Note that this is not a one-dimensional Newtonian system, which is a two dimensional
~Œ∑ = (x, p) dynamical system.

1.4. PHASE SPACE

27

Thus generically the fixed points will alternate in stability, dividing the phase
line into open intervals which are each invariant sets of states, with the points
in a given interval flowing either to the left or to the right, but never leaving
the open interval.
The state never
reaches the stable fixed point because the
R
R
time t = dŒ∑/V (Œ∑) ‚âà (1/c) dŒ∑/(Œ∑ ‚àí Œ∑0 ) diverges. On the other hand, in
the case V (Œ∑) = cŒ∑ 2 , a system starting at Œ∑0 at t = 0 has a motion given by
Œ∑ = (Œ∑0‚àí1 ‚àí ct)‚àí1 , which runs off to infinity as t ‚Üí 1/Œ∑0 c. Thus the solution
terminates at t = 1/Œ∑0 c, and makes no sense thereafter. This form of solution
is called terminating motion.
For higher order dynamical systems, the d equations Vi (~Œ∑ ) = 0 required
for a fixed point will generically determine the d variables Œ∑j , so the generic
P
form of the velocity field near a fixed point Œ∑0 is Vi (~Œ∑ ) = j Mij (Œ∑j ‚àí Œ∑0j )
with a nonsingular matrix M . The stability of the flow will be determined
by this d-dimensional square matrix M . Generically the eigenvalue equation,
a d‚Äôth order polynomial in Œª, will have d distinct solutions. Because M
is a real matrix, the eigenvalues must either be real or come in complex
conjugate pairs. For the real case, whether the eigenvalue is positive or
negative determines the instability or stability of the flow along the direction
of the eigenvector. For a pair of complex conjugate eigenvalues Œª = u + iv
and Œª‚àó = u ‚àí iv, with eigenvectors ~e and ~e ‚àó respectively, we may describe
the flow in the plane Œ¥~Œ∑ = ~Œ∑ ‚àí ~Œ∑0 = x(~e + ~e ‚àó ) + iy(~e ‚àí ~e ‚àó ), so
~Œ∑Àô = M ¬∑ Œ¥~Œ∑ = x(Œª~e + Œª‚àó~e ‚àó ) + iy(Œª~e ‚àí Œª‚àó~e ‚àó )
= (ux ‚àí vy)(~e + ~e ‚àó ) + (vx + uy)(~e ‚àí ~e ‚àó )
so


xÃá
yÃá





=

u ‚àív
v u



x
,
y




or

x = Aeut cos(vt + œÜ)
.
y = Aeut sin(vt + œÜ)

Thus we see that the motion spirals in towards the fixed point if u is negative,
and spirals away from the fixed point if u is positive. Stability in these
directions is determined by the sign of the real part of the eigenvalue.
In general, then, stability in each subspace around the fixed point ~Œ∑0
depends on the sign of the real part of the eigenvalue. If all the real parts
are negative, the system will flow from anywhere in some neighborhood of
~Œ∑0 towards the fixed point, so limt‚Üí‚àû ~Œ∑ (t) = ~Œ∑0 provided we start in that
neighborhood. Then ~Œ∑0 is an attractor and is a strongly stable fixed point.
On the other hand, if some of the eigenvalues have positive real parts, there
are unstable directions. Starting from a generic point in any neighborhood

28

CHAPTER 1. PARTICLE KINEMATICS

of ~Œ∑0 , the motion will eventually flow out along an unstable direction, and
the fixed point is considered unstable, although there may be subspaces
along which the flow may be into ~Œ∑0 . An example is the line x = y in the
hyperbolic fixed point case shown in Figure 1.2.
Some examples of two dimensional flows in the neighborhood of a generic
fixed point are shown in Figure 1.2. Note that none of these describe the
fixed point of the undamped harmonic oscillator of Figure 1.1. We have
discussed generic situations as if the velocity field were chosen arbitrarily
from the set of all smooth vector functions, but in fact Newtonian mechanics
imposes constraints on the velocity fields in many situations, in particular if
there are conserved quantities.

xÃá = ‚àíx + y, xÃá = ‚àí3x ‚àí y,
yÃá = ‚àí2x ‚àí y. yÃá = ‚àíx ‚àí 3y.

xÃá = 3x + y,
yÃá = x + 3y.

xÃá = ‚àíx ‚àí 3y,
yÃá = ‚àí3x ‚àí y.

Strongly stable Strongly stable
spiral point.
fixed point,
‚àö
Œª = ‚àí1 ¬± 2i.
Œª = ‚àí1, ‚àí2.

Unstable fixed
point,

Hyperbolic fixed
point,

Œª = 1, 2.

Œª = ‚àí2, 1.

Figure 1.2: Four generic fixed points for a second order dynamical system.

Effect of conserved quantities on the flow
If the system has a conserved quantity Q(q, p) which is a function on phase
space only, and not of time, the flow in phase space is considerably changed.
This is because the equations Q(q, p) = K gives a set of subsurfaces or
contours in phase space, and the system is confined to stay on whichever
contour it is on initially. Unless this conserved quantity is a trivial function,

1.4. PHASE SPACE

29

i.e. constant, in the vicinity of a fixed point, it is not possible for all points
to flow into the fixed point, and thus it is not strongly stable.
For the case of a single particle in a potential, the total energy E =
p /2m + U (~r) is conserved, and so the motion of the system is confined to
one surface of a given energy. As p~/m is part of the velocity function, a
fixed point must have p~ = 0. The vanishing of the other half of the velocity
field gives ‚àáU (~r0 ) = 0, which is the condition for a stationary point of the
potential energy, and for the force to vanish. If this point is a maximum or
a saddle of U , the motion along a descending path will be unstable. If the
fixed point is a minimum of the potential, the region E(~r, p~) < E(~r0 , 0) + ,
for sufficiently small , gives a neighborhood around ~Œ∑0 = (~r0 , 0) to which the
motion is confined if it starts within this region. Such a fixed point is called
stable16 , but it is not strongly stable, as the flow does not settle down to ~Œ∑0 .
This is the situation we saw for the undamped harmonic oscillator. For that
situation F = ‚àíkx, so the potential energy may be taken to be
2

U (x) =

Z 0

1
‚àíkx dx = kx2 ,
2
x

and so the total energy E = p2 /2m + 21 kx2 is conserved. The curves of
constant E in phase space are ellipses, and each motion orbits the appropriate
ellipse, as shown in Fig. 1.1 for the undamped oscillator. This contrasts to
the case of the damped oscillator, for which there is no conserved energy, and
for which the origin is a strongly stable fixed point.

16

A fixed point is stable if it is in arbitrarity small neighborhoods, each with the
property that if the system is in that neighborhood at one time, it remains in it at all later
times.

30

CHAPTER 1. PARTICLE KINEMATICS

As an example of a conservative system with both
stable and unstable fixed
0.3
points, consider a particle in
U
one dimension with a cubic
0.2
U(x)
2
3
potential U (x) = ax ‚àí bx ,
0.1
as shown in Fig. 1.3. There
0
-0.4 -0.2
0.2 0.4 0.6 0.8
1
1.2
is a stable equilibrium at
x
-0.1
xs = 0 and an unstable one
-0.2
at xu = 2a/3b. Each has an
-0.3
associated fixed point in phase
space, an elliptic fixed point
p
1
Œ∑s = (xs , 0) and a hyperbolic
fixed point Œ∑u = (xu , 0). The
velocity field in phase space
and several possible orbits
are shown. Near the stable
x
equilibrium, the trajectories
are approximately ellipses, as
they were for the harmonic os-1
cillator, but for larger energies
they begin to feel the asymmetry of the potential, and Figure 1.3. Motion in a cubic potenthe orbits become egg-shaped. tial.
If the system has total energy precisely U (xu ), the contour line crosses
itself. This contour actually consists of three separate orbits. One starts at
t ‚Üí ‚àí‚àû at x = xu , completes one trip though the potential well, and returns
as t ‚Üí +‚àû to x = xu . The other two are orbits which go from x = xu to
x = ‚àû, one incoming and one outgoing. For E > U (xu ), all the orbits start
and end at x = +‚àû. Note that generically the orbits deform continuously
as the energy varies, but at E = U (xu ) this is not the case ‚Äî the character
of the orbit changes as E passes through U (xu ). An orbit with this critical
value of the energy is called a separatrix, as it separates regions in phase
space where the orbits have different qualitative characteristics.
Quite generally hyperbolic fixed points are at the ends of separatrices. In
our case the contour E = U (xu ) consists of four invariant sets of states, one
of which is the point Œ∑u itself, and the other three are the orbits which are

1.4. PHASE SPACE

31

the disconnected pieces left of the contour after removing Œ∑u .

Exercises
1.1 (a) Find the potential energy function U (~r) for a particle in the gravitational field of the Earth, for which the force law is F~ (~r) = ‚àíGME m~r/r3 .
(b) Find the escape velocity from the Earth, that is, the minimum velocity a
particle near the surface can have for which it is possible that the particle will
eventually coast to arbitrarily large distances without being acted upon by any
force other than gravity. The Earth has a mass of 6.0 √ó 1024 kg and a radius of
6.4 √ó 106 m. Newton‚Äôs gravitational constant is 6.67 √ó 10‚àí11 N ¬∑ m2 /kg2 .
1.2 In the discussion of a system of particles, it is important that the particles
included in the system remain the same. There are some situations in which we
wish to focus our attention on a set of particles which changes with time, such as
a rocket ship which is emitting gas continuously. The equation of motion for such
a problem may be derived by considering an infinitesimal time interval, [t, t + ‚àÜt],
and choosing the system to be the rocket with the fuel still in it at time t, so that
at time t + ‚àÜt the system consists of the rocket with its remaining fuel and also
the small amount of fuel emitted during the infinitesimal time interval.
Let M (t) be the mass of the rocket and remaining fuel at time t, assume that the
fuel is emitted with velocity ~u with respect to the rocket, and call the velocity
of the rocket ~v (t) in an inertial coordinate system. If the external force on the
rocket is F~ (t) and the external force on the infinitesimal amount of exhaust is
infinitesimal, the fact that F (t) is the rate of change of the total momentum gives
the equation of motion for the rocket.
(a) Show that this equation is
M

d~v
dM
= F~ (t) + ~u
.
dt
dt

(b) Suppose the rocket is in a constant gravitational field F~ = ‚àíM geÃÇz for the
period during which it is burning fuel, and that it is fired straight up with constant
exhaust velocity (~u = ‚àíueÃÇz ), starting from rest. Find v(t) in terms of t and M (t).
(c) Find the maximum fraction of the initial mass of the rocket which can escape
the Earth‚Äôs gravitational field if u = 2000m/s.
1.3 For a particle in two dimensions, we might use polar coordinates (r, Œ∏) and
use basis unit vectors eÃÇr and eÃÇŒ∏ in the radial and tangent directions respectively to
describe more general vectors. Because this pair of unit vectors differ from point

32

CHAPTER 1. PARTICLE KINEMATICS

to point, the eÃÇr and eÃÇŒ∏ along the trajectory of a moving particle are themselves
changing with time.
(a) Show that
d
d
eÃÇr = Œ∏ÃáeÃÇŒ∏ ,
eÃÇŒ∏ = ‚àíŒ∏ÃáeÃÇr .
dt
dt
(b) Thus show that the derivative of ~r = reÃÇr is
~v = rÃáeÃÇr + rŒ∏ÃáeÃÇŒ∏ ,
which verifies the discussion of Sec. (1.3.4).
(c) Show that the derivative of the velocity is
~a =

d
~v = (rÃà ‚àí rŒ∏Ãá2 )eÃÇr + (rŒ∏Ãà + 2rÃáŒ∏Ãá)eÃÇŒ∏ .
dt

(d) Thus Newton‚Äôs Law says for the radial and tangential components of the
force are Fr = eÃÇr ¬∑ F = m(rÃà ‚àí rŒ∏Ãá2 ), FŒ∏ = eÃÇŒ∏ ¬∑ F = m(rŒ∏Ãà + 2rÃáŒ∏Ãá). Show that the
generalized forces are Qr = Fr and QŒ∏ = rFŒ∏ .
1.4 Analyze the errors in the integration of Newton‚Äôs Laws in the simple Euler‚Äôs
approach described in section 1.4.1, where we approximated the change for x and p
in each time interval ‚àÜt between ti and ti+1 by xÃá(t) ‚âà xÃá(ti ), pÃá(t) ‚âà F (x(ti ), v(ti )).
Assuming F to be differentiable, show that the error which accumulates in a finite
time interval T is of order (‚àÜt)1 .
1.5 Write a simple program to integrate the equation of the harmonic oscillator
through one period of oscillation, using Euler‚Äôs method with a step size ‚àÜt. Do
this for several ‚àÜt, and see whether the error accumulated in one period meets the
expectations of problem 1.4.
1.6 Describe the one dimensional phase space for the logistic equation pÃá = bp ‚àí
cp2 , with b > 0, c > 0. Give the fixed points, the invariant sets of states, and
describe the flow on each of the invariant sets.
1.7 Consider a pendulum consisting of a mass at the end of a massless rod of
length L, the other end of which is fixed but free to rotate. Ignore one of the
horizontal directions, and describe the dynamics in terms of the angle Œ∏ between
the rod and the downwards direction, without making a small angle approximation.
(a) Find the generalized force QŒ∏ and find the conserved quantity on phase space.
(b) Give a sketch of the velocity function, including all the regions of phase
space. Show all fixed points, separatrices, and describe all the invariant sets of
states. [Note: the variable Œ∏ is defined only modulo 2œÄ, so the phase space is the

1.4. PHASE SPACE

33

Cartesian product of an interval of length 2œÄ in Œ∏ with the real line for pŒ∏ . This
can be plotted on a strip, with the understanding that the left and right edges are
identified. To avoid having important points on the boundary, it would be well to
plot this with Œ∏ ‚àà [‚àíœÄ/2, 3œÄ/2].
1.8 Consider again the pendulum of mass m on a massless rod of length L,
with motion restricted to a fixed vertical plane, with Œ∏, the angle made with the
downward direction, the generalized coordinate. Using the fact that the energy E
is a constant,
(a) Find dŒ∏/dt as a function of Œ∏.
(b) Assuming the energy is such that the mass comes to rest at Œ∏ = ¬±Œ∏0 , find an
integral expression for the period
q of the pendulum.
(c) Show that the answer is 4 Lg K(sin2 (Œ∏0 /2), where
Z œÄ/2

K(m) :=

dœÜ
q

0

1 ‚àí m sin2 œÜ

is the complete elliptic integral of the first kind.
(Note: the circumference of an ellipse is 4aK(e2 ), where a is the semi-major axis
and e the eccentricity.)
(d) Show that K(m) is given by the power series expansion
‚àû
œÄX
(2n ‚àí 1)!!
K(m) =
2 n=0
(2n)!!



2

mn ,

and give an estimate for the ratio of the period for Œ∏0 = 60‚ó¶ to that for small
angles.
1.9 As mentioned in the footnote in section 1.3, a current i1 flowing through a
wire segment d~s1 at ~s1 exerts a force
¬µ0
d~s2 √ó (d~s1 √ó ~r )
F~12 =
i1 i2
4œÄ
|r|3
on a current i2 flowing through a wire segment d~s2 at ~s2 , where ~r = ~s2 ‚àí ~s1 .
(a) Show, as stated in that footnote, that the sum of this force and its Newtonian
reaction force is
¬µ0 i1 i2
F~12 + F~21 =
[d~s1 (d~s2 ¬∑ ~r) ‚àí d~s2 (d~s1 ¬∑ ~r)] ,
4œÄ |r|3
which is not generally zero.
HH
(b) Show that if the currents each flow around closed loops, the total force
F12 +
F21 vanishes.
[Note: Eq. (A.7) of appendix (A.1) may be useful, along with Stokes‚Äô theorem.]

34

CHAPTER 1. PARTICLE KINEMATICS

Chapter 2
Lagrange‚Äôs and Hamilton‚Äôs
Equations
In this chapter, we consider two reformulations of Newtonian mechanics, the
Lagrangian and the Hamiltonian formalism. The first is naturally associated
with configuration space, extended by time, while the latter is the natural
description for working in phase space.
Lagrange developed his approach in 1764 in a study of the libration of
the moon, but it is best thought of as a general method of treating dynamics
in terms of generalized coordinates for configuration space. It so transcends
its origin that the Lagrangian is considered the fundamental object which
describes a quantum field theory.
Hamilton‚Äôs approach arose in 1835 in his unification of the language of
optics and mechanics. It too had a usefulness far beyond its origin, and
the Hamiltonian is now most familiar as the operator in quantum mechanics
which determines the evolution in time of the wave function.
We begin by deriving Lagrange‚Äôs equation as a simple change of coordinates in an unconstrained system, one which is evolving according to Newton‚Äôs laws with force laws given by some potential. Lagrangian mechanics
is also and especially useful in the presence of constraints, so we will then
extend the formalism to this more general situation.
35

36

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

2.1

Lagrangian for unconstrained systems

For a collection of particles with conservative forces described by a potential,
we have in inertial cartesian coordinates
mxÃài = Fi .
The left hand side of this equation is determined by the kinetic energy function as the time derivative of the momentum pi = ‚àÇT /‚àÇ xÃái , while the right
hand side is a derivative of the potential energy, ‚àí‚àÇU/‚àÇxi . As T is independent of xi and U is independent of xÃái in these coordinates, we can write both
sides in terms of the Lagrangian L = T ‚àí U , which is then a function of
both the coordinates and their velocities. Thus we have established
‚àÇL
d ‚àÇL
‚àí
= 0,
dt ‚àÇ xÃái ‚àÇxi
which, once we generalize it to arbitrary coordinates, will be known as Lagrange‚Äôs equation. Note that we are treating L as a function of the 2N
independent variables xi and xÃái , so that ‚àÇL/‚àÇ xÃái means vary one xÃái holding
all the other xÃáj and all the xk fixed. Making this particular combination
of T (~rÀô) with U (~r) to get the more complicated L(~r, ~rÀô) seems an artificial
construction for the inertial cartesian coordinates, but it has the advantage
of preserving the form of Lagrange‚Äôs equations for any set of generalized
coordinates.
As we did in section 1.3.3, we assume we have a set of generalized coordinates {qj } which parameterize all of coordinate space, so that each point
may be described by the {qj } or by the {xi }, i, j ‚àà [1, N ], and thus each set
may be thought of as a function of the other, and time:
qj = qj (x1 , ...xN , t)

xi = xi (q1 , ...qN , t).

(2.1)

We may consider L as a function1 of the generalized coordinates qj and qÃáj ,
1

Of course we are not saying that L(x, xÃá, t) is the same function of its coordinates as
L(q, qÃá, t), but rather that these are two functions which agree at the corresponding physical
points. More precisely, we are defining a new function LÃÉ(q, qÃá, t) = L(x(q, t), xÃá(q, qÃá, t), t),
but we are being physicists and neglecting the tilde. We are treating the Lagrangian here
as a scalar under coordinate transformations, in the sense used in general relativity, that
its value at a given physical point is unchanged by changing the coordinate system used
to define that point.

2.1. LAGRANGIAN FOR UNCONSTRAINED SYSTEMS

37

and ask whether the same expression in these coordinates
d ‚àÇL
‚àÇL
‚àí
dt ‚àÇ qÃáj
‚àÇqj
also vanishes. The chain rule tells us
X ‚àÇL ‚àÇqk
X ‚àÇL ‚àÇ qÃák
‚àÇL
=
+
.
‚àÇ xÃáj
‚àÇq
‚àÇ
xÃá
‚àÇ
qÃá
‚àÇ
xÃá
k
j
k
j
k
k

(2.2)

The first term vanishes because qk depends only on the coordinates xk and
t, but not on the xÃák . From the inverse relation to (1.10),
‚àÇqj
,
‚àÇt

(2.3)

X ‚àÇL ‚àÇqj
‚àÇL
=
.
‚àÇ xÃái
j ‚àÇ qÃáj ‚àÇxi

(2.4)

qÃáj =

X ‚àÇqj
i

we have

‚àÇxi

xÃái +

‚àÇqj
‚àÇ qÃáj
=
.
‚àÇ xÃái
‚àÇxi

Using this in (2.2),

Lagrange‚Äôs equation involves the time derivative of this. Here what is
meant is not a partial derivative ‚àÇ/‚àÇt, holding the point in configuration
space fixed, but rather the derivative along the path which the system takes as
it moves through configuration space. It is called the stream derivative, a
name which comes from fluid mechanics, where it gives the rate at which some
property defined throughout the fluid, f (~r, t), changes for a fixed element of
fluid as the fluid as a whole flows. We write it as a total derivative to indicate
that we are following the motion rather than evaluating the rate of change
at a fixed point in space, as the partial derivative does.
For any function f (x, t) of extended configuration space, this total time
derivative is
X ‚àÇf
df
‚àÇf
=
xÃáj +
.
(2.5)
dt
‚àÇt
j ‚àÇxj
Using Leibnitz‚Äô rule on (2.4) and using (2.5) in the second term, we find
X d ‚àÇL
d ‚àÇL
=
dt ‚àÇ xÃái
dt ‚àÇ qÃáj
j

!

‚àÇqj X ‚àÇL X ‚àÇ 2 qj
‚àÇ 2 qj
+
xÃák +
.
‚àÇxi
‚àÇxi ‚àÇt
j ‚àÇ qÃáj
k ‚àÇxi ‚àÇxk
!

(2.6)

38

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

On the other hand, the chain rule also tells us
X ‚àÇL ‚àÇqj
X ‚àÇL ‚àÇ qÃáj
‚àÇL
=
+
,
‚àÇxi
j ‚àÇqj ‚àÇxi
j ‚àÇ qÃáj ‚àÇxi

where the last term does not necessarily vanish, as qÃáj in general depends on
both the coordinates and velocities. In fact, from 2.3,
X ‚àÇ 2 qj
‚àÇ 2 qj
‚àÇ qÃáj
=
xÃák +
,
‚àÇxi
‚àÇxi ‚àÇt
k ‚àÇxi ‚àÇxk

so

X ‚àÇL ‚àÇqj
X ‚àÇL X ‚àÇ 2 qj
‚àÇL
‚àÇ 2 qj
.
=
+
xÃák +
‚àÇxi
‚àÇxi ‚àÇt
j ‚àÇqj ‚àÇxi
j ‚àÇ qÃáj
k ‚àÇxi ‚àÇxk
!

(2.7)

Lagrange‚Äôs equation in cartesian coordinates says (2.6) and (2.7) are equal,
and in subtracting them the second terms cancel2 , so
0 =

X
j

‚àÇL
d ‚àÇL
‚àí
dt ‚àÇ qÃáj
‚àÇqj

!

‚àÇqj
.
‚àÇxi

The matrix ‚àÇqj /‚àÇxi is nonsingular, as it has ‚àÇxi /‚àÇqj as its inverse, so we
have derived Lagrange‚Äôs Equation in generalized coordinates:
‚àÇL
d ‚àÇL
‚àí
= 0.
dt ‚àÇ qÃáj
‚àÇqj
Thus we see that Lagrange‚Äôs equations are form invariant under changes of
the generalized coordinates used to describe the configuration of the system.
It is primarily for this reason that this particular and peculiar combination
of kinetic and potential energy is useful. Note that we implicity assume the
Lagrangian itself transformed like a scalar, in that its value at a given physical point of configuration space is independent of the choice of generalized
coordinates that describe the point. The change of coordinates itself (2.1) is
called a point transformation.
2

This is why we chose the particular combination we did for the Lagrangian, rather
than L = T ‚àí Œ±U for some Œ± 6= 1. Had we done so, Lagrange‚Äôs equation in cartesian
coordinates would have been Œ± d(‚àÇL/‚àÇ xÃáj )/dt ‚àí ‚àÇL/‚àÇxj = 0, and in the subtraction of
(2.7) from Œ±√ó(2.6), the terms proportional to ‚àÇL/‚àÇ qÃái (without a time derivative) would
not have cancelled.

2.2. LAGRANGIAN FOR CONSTRAINED SYSTEMS

2.2

39

Lagrangian for Constrained Systems

We now wish to generalize our discussion to include contraints. At the same
time we will also consider possibly nonconservative forces. As we mentioned
in section 1.3.2, we often have a system with internal forces whose effect is
better understood than the forces themselves, with which we may not be
concerned. We will assume the constraints are holonomic, expressible as k
real functions Œ¶Œ± (~r1 , ..., ~rn , t) = 0, which are somehow enforced by constraint
forces F~iC on the particles {i}. There may also be other forces, which we
will call FiD and will treat as having a dynamical effect. These are given by
known functions of the configuration and time, possibly but not necessarily
in terms of a potential.
This distinction will seem artificial without examples, so it would be well
to keep these two in mind. In each of these cases the full configuration
space is R3 , but the constraints restrict the motion to an allowed subspace
of extended configuration space.
1. In section 1.3.2 we discussed a mass on a light rigid rod, the other end
of which is fixed at the origin. Thus the mass is constrained to have
|~r| = L, and the allowed subspace of configuration space is the surface
of a sphere, independent of time. The rod exerts the constraint force
to avoid compression or expansion. The natural assumption to make is
that the force is in the radial direction, and therefore has no component
in the direction of allowed motions, the tangential directions. That is,
for all allowed displacements, Œ¥~r, we have F~ C ¬∑Œ¥~r = 0, and the constraint
force does no work.
2. Consider a bead free to slide without friction on the spoke of a rotating
bicycle wheel3 , rotating about a fixed axis at fixed angular velocity œâ.
That is, for the polar angle Œ∏ of inertial coordinates, Œ¶ := Œ∏ ‚àí œât = 0 is
a constraint4 , but the r coordinate is unconstrained. Here the allowed
subspace is not time independent, but is a helical sort of structure in
extended configuration space. We expect the force exerted by the spoke
on the bead to be in the eÃÇŒ∏ direction. This is again perpendicular to
any virtual displacement, by which we mean an allowed change in
3

Unlike a real bicycle wheel, we are assuming here that the spoke is directly along a
radius of the circle, pointing directly to the axle.
4
There is also a constraint z = 0.

40

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS
configuration at a fixed time. It is important to distinguish this virtual
displacement from a small segment of the trajectory of the particle. In
this case a virtual displacement is a change in r without a change in Œ∏,
and is perpendicular to eÃÇŒ∏ . So again, we have the ‚Äúnet virtual work‚Äù of
the constraint forces is zero. It is important to note that this does not
mean that the net real work is zero. In a small time interval, the displacement ‚àÜ~r includes a component rœâ‚àÜt in the tangential direction,
and the force of constraint does do work!

We will assume that the constraint forces in general satisfy this restriction
that no net virtual work is done by the forces of constraint for any possible
virtual displacement. Newton‚Äôs law tells us that p~Àôi = Fi = FiC + FiD . We
can multiply by an arbitrary virtual displacement

X
X
F~iD ‚àí p~Àôi ¬∑ Œ¥~ri = ‚àí
F~iC ¬∑ Œ¥~ri = 0,
i

i

where the first equality would be true even if Œ¥~ri did not satisfy the constraints, but the second requires Œ¥~ri to be an allowed virtual displacement.
Thus

X
F~iD ‚àí p~Àôi ¬∑ Œ¥~ri = 0,
(2.8)
i

which is known as D‚ÄôAlembert‚Äôs Principle. This gives an equation which
determines the motion on the constrained subspace and does not involve the
unspecified forces of constraint F C . We drop the superscript D from now on.
Suppose we know generalized coordinates q1 , . . . , qN which parameterize
the constrained subspace, which means ~ri = ~ri (q1 , . . . , qN , t), for i = 1, . . . , n,
are known functions and the N q‚Äôs are independent. There are N = 3n ‚àí
k of these independent coordinates, where k is the number of holonomic
constraints. Then ‚àÇ~ri /‚àÇqj is no longer an invertable, or even square, matrix,
but we still have
X ‚àÇ~
‚àÇ~ri
ri
‚àÜqj +
‚àÜt.
‚àÜ~ri =
‚àÇt
j ‚àÇqj
For the velocity of the particle, divide this by ‚àÜt, giving
~vi =

X ‚àÇ~
ri
j

‚àÇqj

qÃáj +

‚àÇ~ri
,
‚àÇt

but for a virtual displacement ‚àÜt = 0 we have
Œ¥~ri =

X ‚àÇ~
ri
j

‚àÇqj

Œ¥qj .

(2.9)

2.2. LAGRANGIAN FOR CONSTRAINED SYSTEMS

41

Differentiating (2.9) we note that,

and also

‚àÇ~vi
‚àÇ~ri
=
,
‚àÇ qÃáj
‚àÇqj

(2.10)

‚àÇ 2~ri
d ‚àÇ~ri
‚àÇ~vi X ‚àÇ 2~ri
=
qÃák +
=
,
‚àÇqj
‚àÇqj ‚àÇt
dt ‚àÇqj
k ‚àÇqj ‚àÇqk

(2.11)

where the last equality comes from applying (2.5), with coordinates qj rather
than xj , to f = ‚àÇ~ri /‚àÇqj . The first term in the equation (2.8) stating
D‚ÄôAlembert‚Äôs principle is
X

F~i ¬∑ Œ¥~ri =

i

‚àÇ~ri
Œ¥qj =
F~i ¬∑
‚àÇqj
i

XX

X

j

j

Qj ¬∑ Œ¥qj .

The generalized force Qj has the same form as in the unconstrained case, as
given by (1.9), but there are only as many of them as there are unconstrained
degrees of freedom.
The second term of (2.8) involves
X

p~Àôi ¬∑ Œ¥~ri =

X dpi ‚àÇ~
ri

i

dt ‚àÇqj

i

=

X d

dt

j

=

X d

dt

j

=

‚àÇ~ri
p~i ¬∑
‚àÇqj
i

!

X

d ‚àÇ~ri
Œ¥qj ‚àí
pi ¬∑
dt ‚àÇqj
ij

!

X

!

X
‚àÇ~vi
‚àÇ~vi
p~i ¬∑
pi ¬∑
Œ¥qj ‚àí
Œ¥qj
‚àÇ qÃáj
‚àÇqj
i
ij

‚àÇ~vi X
‚àÇ~vi
d X
mi~vi ¬∑
‚àí
mi vi ¬∑
Œ¥qj
dt i
‚àÇ qÃáj
‚àÇqj
i

"

d ‚àÇT
‚àÇT
‚àí
Œ¥qj ,
dt ‚àÇ qÃáj
‚àÇqj

X

X
j

Œ¥qj

X

"
j

=

Œ¥qj

#

#

where we used (2.10) and (2.11) to get the third line. Plugging in the expressions we have found for the two terms in D‚ÄôAlembert‚Äôs Principle,
"
X
j

#

‚àÇT
d ‚àÇT
‚àí
‚àí Qj Œ¥qj = 0.
dt ‚àÇ qÃáj
‚àÇqj

42

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

We assumed we had a holonomic system and the q‚Äôs were all independent,
so this equation holds for arbitrary virtual displacements Œ¥qj , and therefore
d ‚àÇT
‚àÇT
‚àí
‚àí Qj = 0.
dt ‚àÇ qÃáj
‚àÇqj

(2.12)

Now let us restrict ourselves to forces given by a potential, with F~i =
~ i U ({~r}, t), or
‚àí‚àá
Qj = ‚àí

X ‚àÇ~
ri
i

‚àÇqj

~ iU = ‚àí
¬∑‚àá

‚àÇ UÃÉ ({q}, t)
.
‚àÇqj
t

Notice that Qj depends only on the value of U on the constrained surface.
Also, U is independent of the qÃái ‚Äôs, so
d ‚àÇT
‚àÇT
‚àÇU
d ‚àÇ(T ‚àí U ) ‚àÇ(T ‚àí U )
‚àí
+
=0=
‚àí
,
dt ‚àÇ qÃáj
‚àÇqj ‚àÇqj
dt
‚àÇ qÃáj
‚àÇqj
or
d ‚àÇL
‚àÇL
‚àí
= 0.
dt ‚àÇ qÃáj
‚àÇqj

(2.13)

This is Lagrange‚Äôs equation, which we have now derived in the more general
context of constrained systems.

2.2.1

Some examples of the use of Lagrangians

Atwood‚Äôs machine
Atwood‚Äôs machine consists of two blocks of mass m1 and m2 attached by an
inextensible cord which suspends them from a pulley of moment of inertia I
with frictionless bearings. The kinetic energy is
1
1
1
m1 xÃá2 + m2 xÃá2 + Iœâ 2
2
2
2
U = m1 gx + m2 g(K ‚àí x) = (m1 ‚àí m2 )gx + const
T =

where we have used the fixed length of the cord to conclude that the sum of
the heights of the masses is a constant K. We assume the cord does not slip
on the pulley, so the angular velocity of the pulley is œâ = xÃá/r, and
1
L = (m1 + m2 + I/r2 )xÃá2 + (m2 ‚àí m1 )gx,
2

2.2. LAGRANGIAN FOR CONSTRAINED SYSTEMS

43

and Lagrange‚Äôs equation gives
d ‚àÇL ‚àÇL
‚àí
= 0 = (m1 + m2 + I/r2 )xÃà ‚àí (m2 ‚àí m1 )g.
dt ‚àÇ xÃá
‚àÇx
Notice that we set up our system in terms of only one degree of freedom, the
height of the first mass. This one degree of freedom parameterizes the line
which is the allowed subspace of the unconstrained configuration space, a
three dimensional space which also has directions corresponding to the angle
of the pulley and the height of the second mass. The constraints restrict
these three variables because the string has a fixed length and does not slip
on the pulley. Note that this formalism has permitted us to solve the problem
without solving for the forces of constraint, which in this case are the tensions
in the cord on either side of the pulley.
Bead on spoke of wheel
As a second example, reconsider the bead on the spoke of a rotating bicycle
wheel. In section (1.3.4) we saw that the kinetic energy is T = 21 mrÃá2 +
1
mr2 œâ 2 . If there are no forces other than the constraint forces, U (r, Œ∏) ‚â° 0,
2
and the Lagrangian is
1
1
L = mrÃá2 + mr2 œâ 2 .
2
2
The equation of motion for the one degree of freedom is easy enough:
d ‚àÇL
‚àÇL
= mrÃà =
= mrœâ 2 ,
dt ‚àÇ rÃá
‚àÇr
which looks like a harmonic oscillator with a negative spring constant, so the
solution is a real exponential instead of oscillating,
r(t) = Ae‚àíœât + Beœât .
The velocity-independent term in T acts just like a potential would, and can
in fact be considered the potential for the centrifugal force. But we see that
the total energy T is not conserved but blows up as t ‚Üí ‚àû, T ‚àº mB 2 œâ 2 e2œât .
This is because the force of constraint, while it does no virtual work, does do
real work.

44

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

Mass on end of gimballed rod
Finally, let us consider the mass on the end of the gimballed rod. The
allowed subspace is the surface of a sphere, which can be parameterized by
an azimuthal angle œÜ and the polar angle with the upwards direction, Œ∏, in
terms of which
z = ` cos Œ∏,

x = ` sin Œ∏ cos œÜ,

y = ` sin Œ∏ sin œÜ,

and T = 21 m`2 (Œ∏Ãá2 + sin2 Œ∏œÜÃá2 ). With an arbitrary potential U (Œ∏, œÜ), the Lagrangian becomes
1
L = m`2 (Œ∏Ãá2 + sin2 Œ∏œÜÃá2 ) ‚àí U (Œ∏, œÜ).
2
From the two independent variables Œ∏, œÜ there are two Lagrange equations of
motion,
1
‚àÇU
+ sin(2Œ∏)œÜÃá2 ,
‚àÇŒ∏
2
d  2 2 
‚àÇU
m` sin Œ∏œÜÃá = ‚àí
.
dt
‚àÇœÜ
m`2 Œ∏Ãà = ‚àí

(2.14)
(2.15)

Notice that this is a dynamical system with two coordinates, similar to ordinary mechanics in two dimensions, except that the mass matrix, while diagonal, is coordinate dependent, and the space on which motion occurs is not
an infinite flat plane, but a curved two dimensional surface, that of a sphere.
These two distinctions are connected‚Äîthe coordinates enter the mass matrix because it is impossible to describe a curved space with unconstrained
cartesian coordinates.
Often the potential U (Œ∏, œÜ) will not actually depend on œÜ, in which case
Eq. 2.15 tells us m`2 sin2 Œ∏œÜÃá is constant in time. We will discuss this further
in Section 2.4.1.

2.3

Hamilton‚Äôs Principle

The configuration of a system at any moment is specified by the value of the
generalized coordinates qj (t), and the space coordinatized by these q1 , . . . , qN
is the configuration space. The time evolution of the system is given by

2.3. HAMILTON‚ÄôS PRINCIPLE

45

the trajectory, or motion of the point in configuration space as a function of
time, which can be specified by the functions qi (t).
One can imagine the system taking many paths, whether they obey Newton‚Äôs Laws or not. We consider only paths for which the qi (t) are differentiable. Along any such path, we define the action as
S=

Z t2

L(q(t), qÃá(t), t)dt.

(2.16)

t1

The action depends on the starting and ending points q(t1 ) and q(t2 ), but
beyond that, the value of the action depends on the path, unlike the work
done by a conservative force on a point moving in ordinary space. In fact,
it is exactly this dependence on the path which makes this concept useful
‚Äî Hamilton‚Äôs principle states that the actual motion of the particle from
q(t1 ) = qi to q(t2 ) = qf is along a path q(t) for which the action is stationary.
That means that for any small deviation of the path from the actual one,
keeping the initial and final configurations fixed, the variation of the action
vanishes to first order in the deviation.
To find out where a differentiable function of one variable has a stationary
point, we differentiate and solve the equation found by setting the derivative
to zero. If we have a differentiable function f of several variables xi , the
P
first-order variation of the function is ‚àÜf = i (xi ‚àí x0i ) ‚àÇf /‚àÇxi |x0 , so unless
‚àÇf /‚àÇxi |x0 = 0 for all i, there is some variation of the {xi } which causes a
first order variation of f , and then x0 is not a stationary point.
But our action is a functional, a function of functions, which represent
an infinite number of variables, even for a path in only one dimension. Intuitively, at each time q(t) is a separate variable, though varying q at only
one point makes qÃá hard to interpret. A rigorous mathematician might want
to describe the path q(t) on t ‚àà [0, 1] in terms of Fourier series, for which
P
q(t) = q0 + q1 t + n=1 an sin(nœÄt). Then the functional S(f ) given by
S=

Z

f (q(t), qÃá(t), t)dt

becomes a function of the infinitely many variables q0 , q1 , a1 , . . .. The endpoints fix q0 and q1 , but the stationary condition gives an infinite number of
equations ‚àÇS/‚àÇan = 0.
It is not really necessary to be so rigorous, however. Under a change
q(t) ‚Üí q(t) + Œ¥q(t), the derivative will vary by Œ¥ qÃá = d Œ¥q(t)/dt, and the

46

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

functional S will vary by
Œ¥S =

Z

!

‚àÇf
‚àÇf
Œ¥q +
Œ¥ qÃá dt
‚àÇq
‚àÇ qÃá
f

=

Z
‚àÇf
Œ¥q +
‚àÇ qÃá i

"

#

‚àÇf
d ‚àÇf
‚àí
Œ¥qdt,
‚àÇq
dt ‚àÇ qÃá

where we integrated the second term by parts. The boundary terms each have
a factor of Œ¥q at the initial or final point, which vanish because Hamilton tells
us to hold the qi and qf fixed, and therefore the functional is stationary if
and only if
‚àÇf
d ‚àÇf
‚àí
= 0 for t ‚àà (ti , tf )
(2.17)
‚àÇq
dt ‚àÇ qÃá
We see that if f is the Lagrangian, we get exactly Lagrange‚Äôs equation. The
above derivation is essentially unaltered if we have many degrees of freedom
qi instead of just one.

2.3.1

Examples of functional variation

In this section we will work through some examples of functional variations
both in the context of the action and for other examples not directly related
to mechanics.
The falling particle
As a first example of functional variation, consider a particle thrown up in
a uniform gravitional field at t = 0, which lands at the same spot at t = T .
The Lagrangian is L = 12 m(xÃá2 + yÃá 2 + zÃá 2 ) ‚àí mgz, and the boundary conditions
are x(t) = y(t) = z(t) = 0 at t = 0 and t = T . Elementary mechanics tells
us the solution to this problem is x(t) = y(t) ‚â° 0, z(t) = v0 t ‚àí 21 gt2 with
v0 = 21 gT . Let us evaluate the action for any other path, writing z(t) in
terms of its deviation from the suspected solution,
1
1
z(t) = ‚àÜz(t) + gT t ‚àí gt2 .
2
2
We make no assumptions about this path other than that it is differentiable
and meets the boundary conditions x = y = ‚àÜz = 0 at t = 0 and at t = T .

2.3. HAMILTON‚ÄôS PRINCIPLE

47

The action is
S =

Z T(
0

Ô£Æ

1 Ô£∞ 2
d‚àÜz
m xÃá + yÃá 2 +
2
dt

!2

Ô£π

d‚àÜz 1 2
+ g(T ‚àí 2t)
+ g (T ‚àí 2t)2 Ô£ª
dt
4

)

1
‚àímg‚àÜz ‚àí mg 2 t(T ‚àí t) dt.
2
The fourth term can be integrated by parts,
Z T
0

Z T
T
1
d‚àÜz
1
mg‚àÜz(t) dt.
mg(T ‚àí 2t)
dt = mg(T ‚àí 2t)‚àÜz +
2
dt
2
0
0

The boundary term vanishes because ‚àÜz = 0 where it is evaluated, and the
other term cancels the sixth term in S, so
S =

Z T

1 2 1
mg
(T ‚àí 2t)2 ‚àí t(T ‚àí t) dt
4Ô£Æ
0 2
!2 Ô£π
Z T
1 Ô£∞ 2
d‚àÜz
Ô£ª.
+
m xÃá + yÃá 2 +
dt
0 2




The first integral is independent of the path, so the minimum action requires
the second integral to be as small as possible. But it is an integral of a nonnegative quantity, so its minimum is zero, requiring xÃá = yÃá = d‚àÜz/dt = 0.
As x = y = ‚àÜz = 0 at t = 0, this tells us x = y = ‚àÜz = 0 at all times, and
the path which minimizes the action is the one we expect from elementary
mechanics.
Is the shortest path a straight line?
The calculus of variations occurs in other contexts, some of which are more
intuitive. The classic example is to find the shortest path between two points
in the plane. The length ` of a path y(x) from (x1 , y1 ) to (x2 , y2 ) is given5 by
`=

Z x2
x1

5

ds =

v
Z x2 u
u
t
x1

dy
1+
dx

!2

dx.

Here we are assuming the path is monotone in x, without moving somewhere to the
left and somewhere to the right. To prove that the straight line is shorter than other paths
which might not obey this restriction, do Exercise 2.2.

48

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

We see that length ` is playing the role of the action, and x is playing‚àöthe role
of t. Using yÃá to represent dy/dx, we have the integrand f (y, yÃá, x) = 1 + yÃá 2 ,
and ‚àÇf /‚àÇy = 0, so Eq. 2.17 gives
d ‚àÇf
d
yÃá
‚àö
=
= 0,
dx ‚àÇ yÃá
dx 1 + yÃá 2

so yÃá = const.

and the path is a straight line.

2.4

Conserved Quantities

2.4.1

Ignorable Coordinates

If the Lagrangian does not depend on one coordinate, say qk , then we say
it is an ignorable coordinate. Of course, we still want to solve for it, as
its derivative may still enter the Lagrangian and effect the evolution of other
coordinates. By Lagrange‚Äôs equation
‚àÇL
d ‚àÇL
=
= 0,
dt ‚àÇ qÃák
‚àÇqk
so if in general we define
‚àÇL
,
‚àÇ qÃák
as the generalized momentum, then in the case that L is independent of
qk , Pk is conserved, dPk /dt = 0.
Pk :=

Linear Momentum
As a very elementary example, consider a particle under a force given by a
potential which depends only on y and z, but not x. Then

1 
L = m xÃá2 + yÃá 2 + zÃá 2 ‚àí U (y, z)
2

is independent of x, x is an ignorable coordinate and
Px =

‚àÇL
= mxÃá
‚àÇ xÃá

is conserved. This is no surprize, of course, because the force is F = ‚àí‚àáU
and Fx = ‚àí‚àÇU/‚àÇx = 0.

2.4. CONSERVED QUANTITIES

49

Note that, using the definition of the generalized momenta
Pk =

‚àÇL
,
‚àÇ qÃák

Lagrange‚Äôs equation can be written as
d
‚àÇL
‚àÇT
‚àÇU
Pk =
=
‚àí
.
dt
‚àÇqk
‚àÇqk ‚àÇqk
Only the last term enters the definition of the generalized force, so if the
kinetic energy depends on the coordinates, as will often be the case, it is
not true that dPk /dt = Qk . In that sense we might say that the generalized
momentum and the generalized force have not been defined consistently.
Angular Momentum
As a second example of a system with an ignorable coordinate, consider an
axially symmetric system described with inertial polar coordinates (r, Œ∏, z),
with z along the symmetry axis. Extending the form of the kinetic energy
we found in sec (1.3.4) to include the z coordinate, we have T = 12 mrÃá2 +
1
mr2 Œ∏Ãá2 + 21 mzÃá 2 . The potential is independent of Œ∏, because otherwise the
2
system would not be symmetric about the z-axis, so the Lagrangian
1
1
1
L = mrÃá2 + mr2 Œ∏Ãá2 + mzÃá 2 ‚àí U (r, z)
2
2
2
does not depend on Œ∏, which is therefore an ignorable coordinate, and
PŒ∏ :=

‚àÇL
= mr2 Œ∏Ãá = constant.
‚àÇ Œ∏Ãá

We see that the conserved momentum PŒ∏ is in fact the z-component of the
angular momentum, and is conserved because the axially symmetric potential
can exert no torque in the z-direction:


~
œÑz = ‚àí ~r √ó ‚àáU





z

~
= ‚àír ‚àáU


Œ∏

= ‚àír2

‚àÇU
= 0.
‚àÇŒ∏

Finally, consider a particle in a spherically symmetric potential in spherical coordinates. In section (3.1.2) we will show that the kinetic energy in

50

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

spherical coordinates is T = 21 mrÃá2 + 21 mr2 Œ∏Ãá2 + 21 mr2 sin2 Œ∏œÜÃá2 , so the Lagrangian with a spherically symmetric potential is
1
1
1
L = mrÃá2 + mr2 Œ∏Ãá2 + mr2 sin2 Œ∏œÜÃá2 ‚àí U (r).
2
2
2
Again, œÜ is an ignorable coordinate and the conjugate momentum PœÜ is
conserved. Note, however, that even though the potential is independent of
Œ∏ as well, Œ∏ does appear undifferentiated in the Lagrangian, and it is not an
ignorable coordinate, nor is PŒ∏ conserved6 .
If qj is an ignorable coordinate, not appearing undifferentiated in the
Lagrangian, any possible motion qj (t) is related to a different trajectory
qj0 (t) = qj (t) + c, in the sense that they have the same action, and if one
is an extremal path, so will the other be. Thus there is a symmetry of the
system under qj ‚Üí qj + c, a continuous symmetry in the sense that c can
take on any value. As we shall see in Section 8.3, such symmetries generally
lead to conserved quantities. The symmetries can be less transparent than
an ignorable coordinate, however, as in the case just considered, of angular
momentum for a spherically symmetric potential, in which the conservation
of Lz follows from an ignorable coordinate œÜ, but the conservation of Lx and
Ly follow from symmetry under rotation about the x and y axes respectively,
and these are less apparent in the form of the Lagrangian.

2.4.2

Energy Conservation

We may ask what happens to the Lagrangian along the path of the motion.
X ‚àÇL dqi
X ‚àÇL dqÃái
‚àÇL
dL
=
+
+
dt
‚àÇt
i ‚àÇqi dt
i ‚àÇ qÃái dt

In the first term the first factor is
d ‚àÇL
dt ‚àÇ qÃái
6

It seems curious that we are finding straightforwardly one of the components of the
conserved momentum, but not the other two, Ly and Lx , which are also conserved. The
fact that not all of these emerge as conjugates to ignorable coordinates is related to the fact
that the components of the angular momentum do not commute in quantum mechanics.
This will be discussed further in section (6.6.1).

2.4. CONSERVED QUANTITIES

51

by the equations of motion, so
!

dL
d X ‚àÇL
‚àÇL
=
qÃái +
.
dt
dt i ‚àÇ qÃái
‚àÇt
We expect energy conservation when the potential is time invariant and there
is not time dependence in the constraints, i.e. when ‚àÇL/‚àÇt = 0, so we rewrite
this in terms of
H(q, qÃá, t) =

X
i

qÃái

X
‚àÇL
‚àíL=
qÃái Pi ‚àí L
‚àÇ qÃái
i

Then for the actual motion of the system,
dH
‚àÇL
=‚àí .
dt
‚àÇt
If ‚àÇL/‚àÇt = 0, H is conserved.
H is essentially the Hamiltonian, although strictly speaking that name
is reserved for the function H(q, p, t) on extended phase space rather than
the function with arguments (q, qÃá, t). What is H physically? In the case
of Newtonian mechanics with a potential function, L is an inhomogeneous
quadratic function of the velocities qÃái . If we write the Lagrangian L = L2 +
L1 + L0 as a sum of pieces purely quadratic, purely linear, and independent
of the velocities respectively, then
X
i

qÃái

‚àÇ
‚àÇ qÃái

is an operator which multiplies each term by its order in velocities,
X
i

qÃái

‚àÇLn
= nLn ,
‚àÇ qÃái

X
i

qÃái

‚àÇL
= 2L2 + L1 ,
‚àÇ qÃái

and
H = L2 ‚àí L0 .
For a system of particles described by their cartesian coordinates, L2 is
just the kinetic energy T , while L0 is the negative of the potential energy
L0 = ‚àíU , so H = T + U is the ordinary energy. There are, however, constrained systems, such as the bead on a spoke of Section 2.2.1, for which the
Hamiltonian is conserved but is not the ordinary energy.

52

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

2.5

Hamilton‚Äôs Equations

We have written the Lagrangian as a function of qi , qÃái , and t, so it is a
function of N + N + 1 variables. For a free particle we can write the kinetic
energy either as 12 mxÃá2 or as p2 /2m. More generally, we can7 reexpress the
dynamics in terms of the 2N + 1 variables qk , Pk , and t.
The motion of the system sweeps out a path in the space (q, qÃá, t) or a
path in (q, P, t). Along this line, the variation of L is
!

‚àÇL
‚àÇL
‚àÇL
dqÃák +
dqk +
dt
dL =
‚àÇ qÃák
‚àÇqk
‚àÇt
k

X
‚àÇL
dt
=
Pk dqÃák + PÃák dqk +
‚àÇt
k
X

where for the first term we used the definition of the generalized momentum
and in the second we have used the equations of motion PÃák = ‚àÇL/‚àÇqk . Then
P
examining the change in the Hamiltonian H = k Pk qÃák ‚àí L along this actual
motion,
dH =

X

(Pk dqÃák + qÃák dPk ) ‚àí dL

k

=

X



qÃák dPk ‚àí PÃák dqk ‚àí

k

‚àÇL
dt.
‚àÇt

If we think of qÃák and H as functions of q and P , and think of H as a function
of q, P , and t, we see that the physical motion obeys
qÃák =

‚àÇH
,
‚àÇPk q,t

PÃák = ‚àí

‚àÇH
,
‚àÇqk P,t

‚àÇH
‚àÇL
=‚àí
‚àÇt q,P
‚àÇt q,qÃá

The first two constitute Hamilton‚Äôs equations of motion, which are first
order equations for the motion of the point representing the system in phase
space.
Let‚Äôs work out a simple example, the one dimensional harmonic oscillator.
Here the kinetic energy is T = 21 mxÃá2 , the potential energy is U = 12 kx2 , so
7

In field theory there arise situations in which the set of functions Pk (qi , qÃái ) cannot be
inverted to give functions qÃái = qÃái (qj , Pj ). This gives rise to local gauge invariance, and
will be discussed in Chapter 8, but until then we will assume that the phase space (q, p),
or cotangent bundle, is equivalent to the tangent bundle, i.e. the space of (q, qÃá).

2.5. HAMILTON‚ÄôS EQUATIONS

53

L = 21 mxÃá2 ‚àí 12 kx2 , the only generalized momentum is P = ‚àÇL/‚àÇ xÃá = mxÃá, and
the Hamiltonian is H = P xÃá ‚àí L = P 2 /m ‚àí (P 2 /2m ‚àí 21 kx2 ) = P 2 /2m + 21 kx2 .
Note this is just the sum of the kinetic and potential energies, or the total
energy.
Hamilton‚Äôs equations give
xÃá =

‚àÇH
P
= ,
‚àÇP x m

PÃá = ‚àí

‚àÇH
= ‚àíkx = F.
‚àÇx P

These two equations verify the usual connection of the momentum and velocity and give Newton‚Äôs second law.
The identification of H with the total energy is more general than our
particular example. If T is purely quadratic in velocities, we can write T =
1P
ij Mij qÃái qÃáj in terms of a symmetric mass matrix Mij . If in addition U is
2
independent of velocities,
L =

1X
Mij qÃái qÃáj ‚àí U (q)
2 ij

Pk =

X
‚àÇL
=
Mki qÃái
‚àÇ qÃák
i

which as a matrix equation in a n-dimensional space is P = M ¬∑ qÃá. Assuming
M is invertible,8 we also have qÃá = M ‚àí1 ¬∑ P , so
H = P T ¬∑ qÃá ‚àí L
1 T
qÃá ¬∑ M ¬∑ qÃá ‚àí U (q)
= P ¬∑M ¬∑P ‚àí
2
1
= P T ¬∑ M ‚àí1 ¬∑ P ‚àí P T ¬∑ M ‚àí1 ¬∑ M ¬∑ M ‚àí1 ¬∑ P + U (q)
2
1 T
=
P ¬∑ M ‚àí1 ¬∑ P + U (q) = T + U
2
T

‚àí1





so we see that the Hamiltonian is indeed the total energy under these circumstances.
8

If M were not invertible, there would be a linear combination of velocities which
does not affect the Lagrangian. The degree of freedom corresponding to this combination
would have a Lagrange equation without time derivatives, so it would be a constraint
equation rather than an equation of motion. But we are assuming that the q‚Äôs are a set
of independent generalized coordinates that have already been pruned of all constraints.

54

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

2.6

Don‚Äôt plug Equations of Motion into the
Lagrangian!

When we have a Lagrangian with an ignorable coordinate, say Œ∏, and therefore a conjugate momentum PŒ∏ which is conserved and can be considered
a constant, we are able to reduce the problem to one involving one fewer
degrees of freedom. That is, one can substitute into the other differential
equations the value of Œ∏Ãá in terms of PŒ∏ and other degrees of freedom, so
that Œ∏ and its derivatives no longer appear in the equations of motion. For
example, consider the two dimensional isotropic harmonic oscillator,


1 
1  2
m xÃá + yÃá 2 ‚àí k x2 + y 2
2
2

1  2
1
=
m rÃá + r2 Œ∏Ãá2 ‚àí kr2
2
2

L =

in polar coordinates. The equations of motion are
PÃáŒ∏ = 0, where PŒ∏ = mr2 Œ∏Ãá,
.
mrÃà = ‚àíkr + mrŒ∏Ãá2 =‚áí mrÃà = ‚àíkr + PŒ∏2 mr3 .
The last equation is now a problem in the one degree of freedomÔ£º r.
One might be tempted to substitute for Œ∏Ãá into the LagrangianÔ£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
and then have a Lagrangian involving one fewer degrees of free-Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
dom. In our example, we would get
Ô£¥
Ô£¥
PŒ∏2

1
1
‚àí kr2 ,
L = mrÃá2 +
2
2
2mr
2
which gives the equation of motion
mrÃà = ‚àí

PŒ∏2
‚àí kr.
mr3

Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£Ω

This is
Ô£¥
Ô£¥
wrong
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£æ

Notice that the last equation has the sign of the PŒ∏2 term reversed from
the correct equation. Why did we get the wrong answer? In deriving the
Lagrange equation which comes from varying r, we need
‚àÇL
d ‚àÇL
=
.
dt ‚àÇ rÃá r,Œ∏,Œ∏Ãá
‚àÇr rÃá,Œ∏,Œ∏Ãá

2.7. VELOCITY-DEPENDENT FORCES

55

But we treated PŒ∏ as fixed, which means that when we vary r on the right
hand side, we are not holding Œ∏Ãá fixed, as we should be. While we often
write partial derivatives without specifying explicitly what is being held fixed,
they are not defined without such a specification, which we are expected to
understand implicitly. However, there are several examples in Physics, such
as thermodynamics, where this implicit understanding can be unclear, and
the results may not be what was intended.

2.7

Velocity-dependent forces

We have concentrated thus far on Newtonian mechanics with a potential
given as a function of coordinates only. As the potential is a piece of the
Lagrangian, which may depend on velocities as well, we should also entertain
the possibility of velocity-dependent potentials. Only by considering such a
potential can we possibly find velocity-dependent forces, and one of the most
important force laws in physics is of that form. This is the Lorentz force9
~ r, t) and
on a particle of charge q in the presence of electromagnetic fields E(~
~ r, t),
B(~
!
~
v
~ .
~ + √óB
(2.18)
F~ = q E
c
If the motion of a charged particle is described by Lagrangian mechanics with
a potential U (~r, ~v , t), Lagrange‚Äôs equation says
0=

d ‚àÇL ‚àÇL
d ‚àÇU
‚àÇU
‚àí
= mrÃài ‚àí
+
,
dt ‚àÇvi ‚àÇri
dt ‚àÇvi ‚àÇri

so Fi =

d ‚àÇU
‚àÇU
‚àí
.
dt ‚àÇvi ‚àÇri

We want a force linear in ~v and proportional to q, so let us try




~ r, t) .
U = q œÜ(~r, t) + ~v ¬∑ C(~
Then we need to have
~ + ~v √ó B
~ = dC
~ ‚àí ‚àáœÜ
~ ‚àí
~ j.
E
vj ‚àáC
c
dt
j
X

9

(2.19)

We have used Gaussian units here, but those who prefer S. I. units (rationalized MKS)
can simply set c = 1.

56

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

The first term is a stream derivative evaluated at the time-dependent position
of the particle, so, as in Eq. (2.5),
~ X ‚àÇC
~
d ~
‚àÇC
+
.
C=
vj
dt
‚àÇt
‚àÇxj
j
The last term looks like the last term of (2.19), except that the indices on the
~ have been reversed. This suggests that these
derivative operator and on C
two terms combine to form a cross product. Indeed, noting (A.17) that




~ √óC
~ =
~v √ó ‚àá

X

~ j‚àí
vj ‚àáC

X

j

vj

~
‚àÇC
,
‚àÇxj

we see that (2.19) becomes


~
~
~
X
X ‚àÇC
‚àÇC
~ + ~v √ó B
~ = ‚àÇ C ‚àí ‚àáœÜ
~ ‚àí
~ j+
~ ‚àí ~v √ó ‚àá
~ √óC
~ .
E
vj ‚àáC
vj
‚àí ‚àáœÜ
=
c
‚àÇt
‚àÇxj
‚àÇt
j
j

We have successfully generated the term linear in ~v if we can show that
~ r, t) such that B
~ = ‚àíc‚àá
~ √ó C.
~ A curl is always
there exists a vector field C(~
~ ¬∑B
~ = 0, but this is indeed one of Maxwell‚Äôs
divergenceless, so this requires ‚àá
10
~ known as the magequations, and it ensures there exists a vector field A,
~ =‚àá
~ √ó A.
~ Thus with C
~ = ‚àíA/c,
~
netic vector potential, such that B
we
need only to find a œÜ such that
~
~ = ‚àí‚àáœÜ
~ ‚àí 1 ‚àÇA .
E
c ‚àÇt
Once again, one of Maxwell‚Äôs laws,
~
~ √óE
~ + 1 ‚àÇ B = 0,
‚àá
c ‚àÇt
guarantees the existence of œÜ, the electrostatic potential, because after
~ =‚àá
~ √ó A,
~ this is a statement that E
~ + (1/c)‚àÇ A/‚àÇt
~
inserting B
has no curl,
and is the gradient of something.
10

This is but one of many consequences of the PoincareÃÅ lemma, discussed in section 6.5
~ ¬∑B
~ = 0 and
(well, it should be). The particular forms we are using here state that if ‚àá
3
~
~
~
‚àá √ó F = 0 in all of R , then there exist a scalar function œÜ and a vector field A such that
~ =‚àá
~ √óA
~ and F~ = ‚àáœÜ.
~
B

2.7. VELOCITY-DEPENDENT FORCES

57

Thus we see that the Lagrangian which describes the motion of a charged
particle in an electromagnetic field is given by a velocity-dependent potential




~ r, t) .
U (~r, ~v ) = q œÜ(r, t) ‚àí (~v /c) ¬∑ A(~
Note, however, that this Lagrangian describes only the motion of the charged
particle, and not the dynamics of the field itself.
Arbitrariness in the Lagrangian In this discussion of finding the Lagrangian to describe the Lorentz force, we used the lemma that guaranteed
~ can be written in terms of some
that the divergenceless magnetic field B
~ with B
~ =‚àá
~ √ó A.
~ But A
~ is not uniquely specmagnetic vector potential A,
~
~
~
~
~ is unchanged
ified by B; in fact, if a change is made, A ‚Üí A + ‚àáŒª(~r, t), B
~ will be changed
because the curl of a gradient vanishes. The electric field E
~
by ‚àí(1/c)‚àÇ A/‚àÇt,
however, unless we also make a change in the electrostatic
potential, œÜ ‚Üí œÜ ‚àí (1/c)‚àÇŒª/‚àÇt. If we do, we have completely unchanged
electromagnetic fields, which is where the physics lies. This change in the
potentials,
~‚ÜíA
~ + ‚àáŒª(~
~ r, t),
A
œÜ ‚Üí œÜ ‚àí (1/c)‚àÇŒª/‚àÇt,
(2.20)
is known as a gauge transformation, and the invariance of the physics
under this change is known as gauge invariance. Under this change, the
potential U and the Lagrangian are not unchanged,
!

~v
~ = L + q ‚àÇŒª + q ~v ¬∑ ‚àáŒª(~
~ r, t) = L + q dŒª .
L ‚Üí L ‚àí q Œ¥œÜ ‚àí ¬∑ Œ¥ A
c
c ‚àÇt
c
c dt
We have here an example which points out that there is not a unique
Lagrangian which describes a given physical problem, and the ambiguity is
more that just the arbitrary constant we always knew was involved in the
potential energy. This ambiguity is quite general, not depending on the gauge
transformations of Maxwell fields. In general, if
L(2) (qj , qÃáj , t) = L(1) (qj , qÃáj , t) +

d
f (qj , t)
dt

(2.21)

then L(1) and L(2) give the same equations of motion, and therefore the same
physics, for qj (t). While this can be easily checked by evaluating the Lagrange
equations, it is best understood in terms of the variation of the action. For

58

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

any path qj (t) between qjI at t = tI to qjF at t = tF , the two actions are
related by
S

(2)

=

!

Z tF

d
L (qj , qÃáj , t) + f (qj , t) dt
dt
(1)

tI

= S (1) + f (qjF , tF ) ‚àí f (qjI , tI ).
The variation of path that one makes to find the stationary action does not
change the endpoints qjF and qjI , so the difference S (2) ‚àí S (1) is a constant
independent of the trajectory, and a stationary trajectory for S (2) is clearly
stationary for S (1) as well.
The conjugate momenta are affected by the change in Lagrangian, howP
ever, because L(2) = L(1) + j qÃáj ‚àÇf /‚àÇqj + ‚àÇf /‚àÇt, so
(2)

pj =

‚àÇf
‚àÇL(2)
(1)
= pj +
.
‚àÇ qÃáj
‚àÇqj

This ambiguity is not usually mentioned in elementary mechanics, because if we restict our attention to Lagrangians consisting of canonical kinetic
energy and potentials which are velocity-independent, a change (2.21) to a
Lagrangian L(1) of this type will produce an L(2) which is not of this type, unless f is independent of position q and leaves the momenta unchanged. That
is, the only f which leaves U velocity independent is an arbitrary constant.
Dissipation Another familiar force which is velocity dependent is friction.
Even the ‚Äúconstant‚Äù sliding friction met with in elementary courses depends
on the direction, if not the magnitude, of the velocity. Friction in a viscous
medium is often taken to be a force proportional to the velocity, F~ = ‚àíŒ±~v .
We saw above that a potential linear in velocities produces a force perpendicular to ~v , and a term higher order in velocities will contribute a force
that depends on acceleration. This situation cannot handled by Lagrange‚Äôs
equations. More generally, a Lagrangian can produce a force Qi = Rij qÃáj with
antisymmetric Rij , but not for a symmetric matrix. An extension to the Lagrange formalism, involving Rayleigh‚Äôs dissipation function, can handle such
a case. These dissipative forces are discussed in Ref. [6].

Exercises

2.7. VELOCITY-DEPENDENT FORCES

59

2.1 (Galelean relativity): Sally is sitting in a railroad car observing a system of
particles, using a Cartesian coordinate system so that the particles are at positions
(S)
(S)
~ri (t), and move under the influence of a potential U (S) ({~ri }). Thomas is in
another railroad car, moving with constant velocity ~u with respect to Sally, and so
(T )
(S)
he describes the position of each particle as ~ri (t) = ~ri (t) ‚àí ~ut. Each takes the


P
(S) 2
kinetic energy to be of the standard form in his system, i.e. T (S) = 1 mi ~rÀô
2

P
and T (T ) = 12 mi

i


(T ) 2
~rÀôi
.



(a) Show that if Thomas assumes the potential function U (T ) (~r (T ) ) to be the same
as Sally‚Äôs at the same physical points,
U (T ) (~r (T ) ) = U (S) (~r (T ) + ~ut),

(2.22)

then the equations of motion derived by Sally and Thomas describe the same
(S)
(T )
(S)
physics. That is, if ri (t) is a solution of Sally‚Äôs equations, ri (t) = ri (t) ‚àí ~ut
is a solution of Thomas‚Äô.
(b) show that if U (S) ({~ri }) is a function only of the displacements of one particle
from another, {~ri ‚àí ~rj }, then U (T ) is the same function of its arguments as U (S) ,
U (T ) ({~ri }) = U (S) ({~ri }). This is a different statement than Eq. 2.22, which states
that they agree at the same physical configuration. Show it will not generally be
true if U (S) is not restricted to depend only on the differences in positions.
(c) If it is true that U (S) (~r) = U (T ) (~r), show that Sally and Thomas derive the
same equations of motion, which we call ‚Äúform invariance‚Äù of the equations.
(d) Show that nonetheless Sally and Thomas disagree on the energy of a particular
physical motion, and relate the difference to the total momentum. Which of these
quantities are conserved?
2.2 In order to show that the shortest path in two dimensional Euclidean space
is a straight line without making the assumption that ‚àÜx does not change sign
along the path, we can consider using a parameter Œª and describing the path by
two functions x(Œª) and y(Œª), say with Œª ‚àà [0, 1]. Then
Z 1

`=

q

dŒª xÃá2 (Œª) + yÃá 2 (Œª),

0

where xÃá means dx/dŒª. This is of the form of a variational integral with two
variables. Show that the variational equations do not determine the functions
x(Œª) and y(Œª), but do determine that the path is a straight line. Show that the
pair of functions (x(Œª), y(Œª)) gives the same action as another pair (xÃÉ(Œª), yÃÉ(Œª)),
where xÃÉ(Œª) = x(t(Œª)) and yÃÉ(Œª) = y(t(Œª)), where t(Œª) is any monotone function
mapping [0, 1] onto itself. Explain why this equality of the lengths is obvious

60

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

in terms of alternate parameterizations of the path. [In field theory, this is an
example of a local gauge invariance, and plays a major role in string theory.]

2.3 Consider a circular hoop of radius R rotating about a vertical diameter at
a fixed angular velocity ‚Ñ¶. On the hoop there is a bead of mass m, which slides
without friction on the hoop. The only external force is gravity. Derive the
Lagrangian and the Lagrange equation using the polar angle Œ∏ as the unconstrained
generalized coordinate. Find a conserved quantity, and find the equilibrium points,
for which Œ∏Ãá = 0. Find the condition on ‚Ñ¶ such that there is an equilibrium point
away from the axis.

2.4 Early steam engines had a feedback device, called a governor, to automatically control the speed. The engine rotated a vertical shaft with an angular
velocity ‚Ñ¶ proportional to its speed. On opposite sides of this shaft, two hinged rods each
held a metal weight, which was attached to
another such rod hinged to a sliding collar, as
shown.
As the shaft rotates faster, the balls move
outwards, the collar rises and uncovers a hole,
releasing some steam. Assume all hinges are
frictionless, the rods massless, and each ball
has mass m1 and the collar has mass m2 .
(a) Write the Lagrangian in terms of the generalized coordinate Œ∏.
(b) Find the equilibrium angle Œ∏ as a function of the shaft angular velocity ‚Ñ¶. Tell
whether the equilibrium is stable or not.

‚Ñ¶

L

m

m

1

1

L
m

2

Governor for a steam engine.

2.5 A transformer consists of two coils of conductor each of which has an inductance, but which also have a coupling, or mutual inductance.

2.7. VELOCITY-DEPENDENT FORCES

61

If the current flowing into the upper posts of coils
A and B are IA (t) and IB (t) respectively, the voltage difference or EMF across each coil is VA and VB
respectively, where

VB

VA

dIA
dIB
+M
dt
dt
dIB
dIA
= LB
+M
dt
dt

IA A

B

0

0

IB

VA = LA
VB

Consider the circuit shown, two
capacitors coupled by a such a transformer, where the capacitances are
CA and CB respectively, with the
charges q1 (t) and q2 (t) serving as the
generalized coordinates for this problem. Write down the two second order differential equations of ‚Äúmotion‚Äù
for q1 (t) and q2 (t), and write a Lagrangian for this system.

q1

A

B

q2
‚àíq2

‚àíq1

2.6 A cylinder of radius R is held horizontally in a fixed position, and a smaller
uniform cylindrical disk of radius a is placed on top of the first cylinder, and is
released from rest. There is a coefficient of
static friction ¬µs and a coefficient of kinetic
friction ¬µk < ¬µs for the contact between the
cylinders. As the equilibrium at the top is
unstable, the top cylinder will begin to roll on
the bottom cylinder.
(a) If ¬µs is sufficiently large, the small disk
will roll until it separates from the fixed
cylinder. Find the angle Œ∏ at which the
separation occurs, and find the minimum value of ¬µs for which this situation
holds.

a
Œ∏

R

(b) If ¬µs is less than the minimum value
found above, what happens differently,
and at what angle Œ∏ does this different A small cylinder rolling on
behavior begin?
a fixed larger cylinder.
2.7 (a) Show that if Œ¶(q1 , ..., qn , t) is an arbitrary differentiable function on extended configuration space, and L(1) ({qi }, {qÃáj }, t) and L(2) ({qi }, {qÃáj }, t) are two

62

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS

Lagrangians which differ by the total time derivative of Œ¶,
L(1) ({qi }, {qÃáj }, t) = L(2) ({qi }, {qÃáj }, t) +

d
Œ¶(q1 , ..., qn , t),
dt

show by explicit calculations that the equations of motion determined by L(1) are
the same as the equations of motion determined by L(2) .
(1)
(2)
(b) What is the relationship between the momenta pi and pi determined by
these two Lagrangians respectively.
2.8 A particle of mass m1 moves in two dimensions on a frictionless horizontal
table with a tiny hole in it. An inextensible massless string attached to m1 goes
through the hole and is connected to another particle of mass m2 , which moves
vertically only. Give a full set of generalized unconstrained coordinates and write
the Lagrangian in terms of these. Assume the string remains taut at all times
and that the motions in question never have either particle reaching the hole, and
there is no friction of the string sliding at the hole.
Are there ignorable coordinates? Reduce the problem to a single second order
differential equation. Show this is equivalent to single particle motion in one
dimension with a potential V (r), and find V (r).
2.9 Consider a mass m on the end of a massless rigid rod of length `, the other
end of which is free to rotate about a fixed point. This is a spherical pendulum.
Find the Lagrangian and the equations of motion.
2.10 (a) Find a differential equation for Œ∏(œÜ) for the shortest path on the surface
of a sphere between two arbitrary points on that surface, by minimizing the length
of the path, assuming it to be monotone in œÜ.
(b) By geometrical argument (that it must be a great circle) argue that the path
should satisfy
cos(œÜ ‚àí œÜ0 ) = K cot Œ∏,
and show that this is indeed the solution of the differential equation you derived.
2.11 Consider some intelligent bugs who live on a turntable which, according
to inertial observers, is spinning at angular velocity œâ about its center. At any
one time, the inertial observer can describe the points on the turntable with polar
coordinates r, œÜ. If the bugs measure distances between two objects at rest with
respect to them, at infinitesimally close points, they will find

2.7. VELOCITY-DEPENDENT FORCES
d`2 = dr2 +

63

r2
dœÜ2 ,
1 ‚àí œâ 2 r2 /c2

because their metersticks shrink in the
tangential direction and it takes more of
them to cover the distance we think of
as rdœÜ, though their metersticks agree
with ours when measuring radial displacements.
The bugs will declare a curve to be
a geodesic, or Rthe shortest path between
two points, if d` is a minimum. Show
that this requires that r(œÜ) satisfies
p
dr
r
Œ±2 r2 ‚àí 1,
=¬±
dœÜ
1 ‚àí œâ 2 r2 /c2

Straight lines to us and to the bugs,
between the same two points.

where Œ± is a constant.
2.12 Hamilton‚Äôs Principle tells us that the motion of a particle is determined
by the action functional being stationary under small variations of the path Œì in
extended configuration space (t, ~x). The unsymmetrical treatment of t and ~x(t)
is not suitable for relativity, but we may still associate an action with each path,
which we can parameterize with Œª, so Œì is the trajectory Œª ‚Üí (t(Œª), ~x(Œª)).
In the general relativistic treatment of a particle‚Äôs motion in a gravitational Rfield,
the action is given by mc2 ‚àÜœÑ , where ‚àÜœÑ is the elapsed proper time, ‚àÜœÑ = dœÑ .
But distances and time intervals are measured with a spatial varying metric g¬µŒΩ ,
with ¬µ and ŒΩ ranging from 0 to 3, with the zeroth component referring to time.
The four components of extended configuration space are written x¬µ , with a superscript rather than a subscript, and x0 = ct. The gravitational field is described by the space-time dependence of the metric g¬µŒΩ (xœÅ ). In this language,
an infinitesimal
qP element of the path of a particle corresponds to a proper time
¬µ
ŒΩ
dœÑ = (1/c)
¬µŒΩ g¬µŒΩ dx dx , so
S = mc2 ‚àÜœÑ = mc

Z

v
uX
u
dx¬µ dxŒΩ
dŒªt g¬µŒΩ (xœÅ )
.
¬µŒΩ

dŒª dŒª

(a) Find the four Lagrange equations which follow from varying xœÅ (Œª).
(b) Show that if we multiply these four equations by xÃáœÅ and sum on œÅ, we get an
identity rather than a differential equation helping to determine the functions

64

CHAPTER 2. LAGRANGE‚ÄôS AND HAMILTON‚ÄôS EQUATIONS
x¬µ (Œª). Explain this as a consequence of the fact that any path has a length
unchanged by a reparameterization of the path, Œª ‚Üí œÉ(Œª), x0 ¬µ (Œª) = x¬µ (œÉ(Œª)

(c) Using this freedom to choose Œª to be œÑ , the proper time from the start of the
path to the point in question, show that the equations of motion are
d2 xŒª X Œª dxœÅ dxœÉ
+
Œì œÅœÉ
= 0,
dœÑ 2
dœÑ dœÑ
œÅœÉ
and find the expression for ŒìŒªœÅœÉ .
2.13 (a): Find the canonical momenta for a charged particle moving in an electromagnetic field and also under the influence of a non-electromagnetic force described
by a potential U (~r).
~ = B0 eÃÇz , with no
(b): If the electromagnetic field is a constant magnetic field B
electric field and with U (~r) = 0, what conserved quantities are there?

Chapter 3
Two Body Central Forces
Consider two particles of masses m1 and m2 , with the only forces those of
their mutual interaction, which we assume is given by a potential which is a
function only of the distance between them, U (|~r1 ‚àí ~r2 |). In a mathematical
sense this is a very strong restriction, but it applies very nicely to many
physical situations. The classical case is the motion of a planet around the
Sun, ignoring the effects mentioned at the beginning of the book. But it
also applies to electrostatic forces and to many effective representations of
nonrelativistic interparticle forces.

3.1

Reduction to a one dimensional problem

Our original problem has six degrees of freedom, but because of the symmetries in the problem, many of these can be simply separated and solved
for, reducing the problem to a mathematically equivalent problem of a single
particle moving in one dimension. First we reduce it to a one-body problem,
and then we reduce the dimensionality.

3.1.1

Reduction to a one-body problem

As there are no external forces, we expect the center of mass coordinate to
be in uniform motion, and it behoves us to use
~ = m1~r1 + m2~r2
R
m1 + m2
65

66

CHAPTER 3. TWO BODY CENTRAL FORCES

as three of our generalized coordinates. For the other three, we first use the
cartesian components of the relative coordinate
~r := ~r2 ‚àí ~r1 ,
although we will soon change to spherical coordinates for this vector. In
~ and ~r, the particle positions are
terms of R
~ ‚àí m2 ~r,
~r1 = R
M

~ + m1 ~r,
~r2 = R
M

where M = m1 + m2 .

The kinetic energy is
1
1
m1 rÃá12 + m2 rÃá22
2
2




1
Àô~ m2 Àô 2 1
Àô m1 Àô 2
~
m1 R ‚àí
=
~r + m2 R +
~r
2
M
2
M
2
1
~Àô + 1 m1 m2 ~rÀô 2
=
(m1 + m2 )R
2
2 M
1 ~Àô 2 1 Àô 2
=
M R + ¬µ~r ,
2
2

T =

where
¬µ :=

m1 m2
m1 + m2

is called the reduced mass. Thus the kinetic energy is transformed to the
form for two effective particles of mass M and ¬µ, which is neither simpler
nor more complicated than it was in the original variables.
For the potential energy, however, the new variables are to be preferred,
~ whose three components are
for U (~r1 ‚àí ~r2 ) = U (~r) is independent of R,
therefore ignorable coordinates, and their conjugate momenta


P~cm


i

=

‚àÇ(T ‚àí U )
= M RÃái
‚àÇ RÃái

are conserved. This reduces half of the motion to triviality, leaving an effective one-body problem with T = 12 ¬µrÃá2 , and the given potential U (~r).
We have not yet made use of the fact that U only depends on the magnitude of ~r. In fact, the above reduction applies to any two-body system
without external forces, as long as Newton‚Äôs Third Law holds.

3.1. REDUCTION TO A ONE DIMENSIONAL PROBLEM

3.1.2

67

Reduction to one dimension

In the problem under discussion, however, there is the additional restriction
that the potential depends only on the magnitude of ~r, that is, on the distance
between the two particles, and not on the direction of ~r. Thus we now convert
from cartesian to spherical coordinates (r, Œ∏, œÜ) for ~r. In terms of the cartesian
coordinates (x, y, z)
1

r= (x2 + y 2 + z 2 ) 2
Œ∏= cos‚àí1 (z/r)
œÜ= tan‚àí1 (y/x)

x= r sin Œ∏ cos œÜ
y= r sin Œ∏ sin œÜ
z= r cos Œ∏

Plugging into the kinetic energy is messy but eventually reduces to a rather
simple form
i
1 h 2
¬µ xÃá1 + xÃá22 + xÃá23
2
1 h
¬µ (rÃá sin Œ∏ cos œÜ + Œ∏Ãár cos Œ∏ cos œÜ ‚àí œÜÃár sin Œ∏ sin œÜ)2
=
2
+(rÃá sin Œ∏ sin œÜ + Œ∏Ãár cos Œ∏ sin œÜ + œÜÃár sin Œ∏ cos œÜ)2

T =

+(rÃá cos Œ∏ ‚àí Œ∏Ãár sin Œ∏)2
=

i

i
1 h 2
¬µ rÃá + r2 Œ∏Ãá2 + r2 sin2 Œ∏œÜÃá2
2

(3.1)

Notice that in spherical coordinates T is a funtion of r and Œ∏ as well as rÃá, Œ∏Ãá,
and œÜÃá, but it is not a function of œÜ, which is therefore an ignorable coordinate,
and
PœÜ =

‚àÇL
= ¬µr2 sin2 Œ∏œÜÃá = constant.
‚àÇ œÜÃá

Note that r sin Œ∏ is the distance of the particle from the z-axis, so PœÜ is just
~ = ~r √ó p~
the z-component of the angular momentum, Lz . Of course all of L
is conserved, because in our effective one body problem there is no torque
~ is a constant1 , and the motion must remain in a
about the origin. Thus L
~ and passing through the origin, as a consequence
plane perpendicular to L
~ = 0, p~ and ~r are in the same direction, to which the motion is then confined.
If L
In this case it is more appropriate to use Cartesian coordinates with this direction as x,
reducing the problem to a one-dimensional problem with potential U (x) = U (r = |x|). In
~ 6= 0.
the rest of this chapter we assume L
1

68

CHAPTER 3. TWO BODY CENTRAL FORCES

~ It simplifies things if we choose our coordinates so
of the fact that ~r ‚ä• L.
~
that L is in the z-direction. Then Œ∏ = œÄ/2, Œ∏Ãá = 0, L = ¬µr2 œÜÃá. The r equation
of motion is then
¬µrÃà ‚àí ¬µrœÜÃá2 + dU/dr = 0 = ¬µrÃà ‚àí

L2
+ dU/dr.
¬µr3

This is the one-dimensional motion of body in an effective potential
Ueff (r) = U (r) +

L2
.
2¬µr2

Thus we have reduced a two-body three-dimensional problem to one with
a single degree of freedom, without any additional complication except the
addition of a centrifugal barrier term L2 /2¬µr2 to the potential.
Before we proceed, a comment may be useful in retrospect about the reduction in variables in going from the three dimensional one-body problem
to a one dimensional problem. Here we reduced the phase space from six
~ and
variables to two, in a problem which had four conserved quantities, L
H. But we have not yet used the conservation of H in this reduction, we
~ Where have these dimenhave only used the three conserved quantities L.
~
~ k z, the
sions gone? From L conservation, by choosing our axes with L
two constraints Lx = 0 and Ly = 0 ( with Lz 6= 0) do imply z = pz = 0,
thereby eliminating two of the coordinates of phase space. The conservation
of Lz , however, is a consequence of an ignorable coordinate œÜ, with conserved
conjugate momentum PœÜ = Lz . In this case, not only is the corresponding
momentum restricted to a constant value, eliminating one dimension of variation in phase space, but the corresponding coordinate, œÜ, while not fixed,
drops out of consideration because it does not appear in the remaining one
dimensional problem. This is generally true for an ignorable coordinate ‚Äî
the corresponding momentum becomes a time-constant parameter, and the
coordinate disappears from the remaining problem.

3.2

Integrating the motion

We can simplify the problem even more by using the one conservation law
left, that of energy. Because the energy of the effective motion is a constant,
1
E = ¬µrÃá2 + Ueff = constant
2

3.2. INTEGRATING THE MOTION

69

we can immediately solve for
)1/2

(

dr
2
=¬±
(E ‚àí Ueff (r))
dt
¬µ

.

This can be inverted and integrated over r, to give
t = t0 ¬±

dr

Z
q

2 (E ‚àí Ueff (r)) /¬µ

,

(3.2)

which is the inverse function of the solution to the radial motion problem
r(t). We can also find the orbit because
œÜÃá
L dt
dœÜ
=
= 2
dr
dr/dt
¬µr dr
so
œÜ = œÜ0 ¬± L

Z r
r0 r 2

dr
q

2¬µ (E ‚àí Ueff (r))

.

(3.3)

The sign ambiguity from the square root is only because r may be increasing
or decreasing, but time, and usually œÜ/L, are always increasing.
Qualitative features of the motion are largely determined by the range
over which the argument of the square root is positive, as for other values of
r we would have imaginary velocities. Thus the motion is restricted to this
allowed region. Unless L = 0 or the potential U (r) is very strongly attractive
for small r, the centrifugal barrier will dominate there, so Ueff ‚àí‚Üí +‚àû, and
r‚Üí0
there must be a smallest radius rp > 0 for which E ‚â• Ueff . Generically the
force will not vanish there, so E ‚àíUeff ‚âà c(r ‚àírp ) for r ‚âà rp , and the integrals
in (3.2) and (3.3) are convergent. Thus an incoming orbit reaches r = rp at a
finite time and finite angle, and the motion then continues with r increasing
and the ¬± signs reversed. The radius rp is called a turning point of the
motion. If there is also a maximum value of r for which the velocity is real,
it is also a turning point, and an outgoing orbit will reach this maximum and
then r will start to decrease, confining the orbit to the allowed values of r.
If there are both minimum and maximum values, this interpretation of
Eq. (3.3) gives œÜ as a multiple valued function of r, with an ‚Äúinverse‚Äù r(œÜ)
which is a periodic function of œÜ. But there is no particular reason for this

70

CHAPTER 3. TWO BODY CENTRAL FORCES

period to be the geometrically natural periodicity 2œÄ of œÜ, so that different
values of r may be expected in successive passes through the same angle in
the plane of the motion. There would need to be something very special
about the attractive potential for the period to turn out to be just 2œÄ, but
indeed that is the case for Newtonian gravity.
We have reduced the problem of the motion to doing integrals. In general
that is all we can do explicitly, but in some cases we can do the integral
analytically, and two of these special cases are very important physically.

3.2.1

The Kepler problem

Consider first the force of Newtonian gravity, or equivalently the Coulomb
attraction of unlike charged particles. The force F (r) = ‚àíK/r2 has a potential
K
U (r) = ‚àí .
r
Then the œÜ integral is
L
2E 2K
L2
œÜ = œÜ0 ¬±
dr
+
‚àí 2 2
¬µr2
¬µ
r
¬µr
Z
du
= œÜ0 ¬± ‚àö
Œ≥ + Œ±u ‚àí u2
Z

(

)‚àí1/2

(3.4)

where we have made the variable substitution u = 1/r which simplifies the
form, and have introduced abbreviations Œ≥ = 2¬µE/L2 , Œ± = 2K¬µ2 /L2 .
As dœÜ/dr must be real the motion will clearly be confined to regions for
which the argument of the square root is nonnegative, and the motion in
r will reverse at the turning points where the argument vanishes. The argument is clearly negative as u ‚Üí ‚àû, which is r = 0. We have assumed
L 6= 0, so the angular momentum barrier dominates over the Coulomb attraction, and always prevents the particle from reaching the origin. Thus
there is always at least one turning point, umax , corresponding to the minimum distance rp . Then the argument of the square root must factor into
[‚àí(u ‚àí umax )(u ‚àí umin )], although if umin is negative it is not really the minimum u, which can never get past zero. The integral (3.4) can be done2 with
2

Of course it can also be done by looking in a good table of integrals. For example, see
2.261(c) of Gradshtein and Ryzhik[7].

3.2. INTEGRATING THE MOTION

71

the substitution sin2 Œ≤ = (umax ‚àí u)/(umax ‚àí umin ). This shows œÜ = œÜ0 ¬± 2Œ≤,
where œÜ0 is the angle at r = rmin , u = umax . Then
u‚â°

1
= A cos(œÜ ‚àí œÜ0 ) + B
r

where A and B are constants which could be followed from our sequence of
substitutions, but are better evaluated in terms of the conserved quantities
E and L directly. œÜ = œÜ0 corresponds to the minimum r, r = rp , the point
of closest approach, or perigee3 , so rp‚àí1 = A + B, and A > 0. Let Œ∏ = œÜ ‚àí œÜ0
be the angle from this minimum, with the x axis along Œ∏ = 0. Then
1
1
1 1 + e cos Œ∏
e
= A cos Œ∏ + B =
(1 ‚àí cos Œ∏) =
1‚àí
r
rp
1+e
rp 1 + e




where e = A/B.
What is this orbit? Clearly rp just sets the scale of the whole orbit. From
rp (1 + e) = r + er cos Œ∏ = r + ex, if we subtract ex and square, we get
rp2 + 2rp e(rp ‚àí x) + e2 (rp ‚àí x)2 = r2 = x2 + y 2 , which is clearly quadratic in
x and y. It is therefore a conic section,
y 2 + (1 ‚àí e2 )x2 + 2e(1 + e)xrp ‚àí (1 + e)2 rp2 = 0.
The nature of the curve depends on the coefficient of x2 . For
‚Ä¢ |e| < 1, the coefficient is > 0, and we have an ellipse.
‚Ä¢ e = ¬±1, the coefficient vanishes and y 2 = ax + b is a parabola.
‚Ä¢ |e| > 1, the coefficient is < 0, and we have a hyperbola.
All of these are possible motions. The bound orbits are ellipses, which
describe planetary motion and also the motion of comets. But objects which
have enough energy to escape from the sun, such as Voyager 2, are in hyperbolic orbit, or in the dividing case where the total energy is exactly zero, a
parabolic orbit. Then as time goes to ‚àû, œÜ goes to a finite value, œÜ ‚Üí œÄ for
a parabola, or some constant less than œÄ for a hyperbolic orbit.
3

Perigee is the correct word if the heavier of the two is the Earth, perihelion if it is
the sun, periastron for some other star. Pericenter is also used, but not as generally as it
ought to be.

72

CHAPTER 3. TWO BODY CENTRAL FORCES

Let us return to the elliptic case. The closest approach, or perigee,
is r = rp , while the furthest apart the objects get is at Œ∏ = œÄ, r = ra =
rp (1 + e)/(1 ‚àí e), which is called the apogee or aphelion. e is the eccentricity of the ellipse. An ellipse is a circle stretched uniformly in one direction;
the diameter in that direction becomes the major axis of the ellipse, while
the perpendicular diameter becomes the minor axis.
One half the length of the major
axis is the semi-major axis and
is denoted by a.
d
r

1+e
rp
1
rp + rp
=
,
2
1‚àíe
1‚àíe


a =



ra

ea

rp

a

so

a

rp = (1 ‚àí e)a,

ra = (1 + e)a.

Properties of an ellipse. The large
Notice that the center of the el- dots are the foci. The eccentricity
lipse is ea away from the Sun.
is e and a is the semi-major axis.
Kepler tells us not only that the orbit is an ellipse, but also that the
sun is at one focus. To verify that, note the other focus of an ellipse is
symmetrically located, at (‚àí2ea, 0), and work out the sum of the distances
of any point on the ellipse from the two foci. This will verify that d + r = 2a
is a constant, showing that the orbit is indeed an ellipse with the sun at one
focus.
How are a and e related to the total energy E and the angular momentum
L? At apogee and perigee, dr/dœÜ vanishes, and so does rÃá, so E = U (r) +
L2 /2¬µr2 = ‚àíK/r + L2 /2¬µr2 , which holds at r = rp = a(1 ‚àí e) and at
r = ra = a(1 + e). Thus Ea2 (1 ¬± e)2 + Ka(1 ¬± e) ‚àí L2 /2¬µ = 0. These two
equations are easily solved for a and e in terms of the constants of the motion
E and L
K
a=‚àí ,
2E

2EL2
e =1+
.
¬µK 2
2

As expected for a bound orbit, we have found r as a periodic function
of œÜ, but it is surprising that the period is the natural period 2œÄ. In other
words, as the planet makes its revolutions around the sun, its perihelion is
always in the same direction. That didn‚Äôt have to be the case ‚Äî one could

3.2. INTEGRATING THE MOTION

73

imagine that each time around, the minimum distance occurred at a slightly
different (or very different) angle. Such an effect is called the precession
of the perihelion. We will discuss this for nearly circular orbits in other
potentials in section (3.2.2).
What about Kepler‚Äôs Third Law? The area of a triange with ~r as one
edge and the displacement during a small time interval Œ¥~r = ~v Œ¥t is A =
1
|~r √ó ~v |Œ¥t = |~r √ó p~|Œ¥t/2¬µ, so the area swept out per unit time is
2
dA
L
=
.
dt
2¬µ
which is constant. The area of an ellipse made by stretching a circle is
stretched by the same amount, so A is œÄ times the semimajor axis times the
semiminor axis.‚àö The endpoint of the semiminor axis is a away from each
focus, so it is a 1 ‚àí e2 from the center, and
v

u
‚àö
u
2EL2
2
2t
2
A = œÄa 1 ‚àí e = œÄa 1 ‚àí 1 +
¬µK 2

L
= œÄa2
K

s

!

‚àí2E
.
¬µ

Recall that for bound orbits E < 0, so A is real. The period is just the area
swept out in one revolution divided by the rate it is swept out, or
2L

T = œÄa

s

‚àí2E 2¬µ
¬µ L

K
œÄ
2œÄa2 q
=
‚àí2¬µE = K(2¬µ)1/2 (‚àíE)‚àí3/2
K
2
2œÄa2 q
=
¬µK/a = 2œÄa3/2 (K)‚àí1/2 ¬µ1/2 ,
K

(3.5)
(3.6)

independent of L. The fact that T and a depend only on E and not on
L is another fascinating manifestation of the very subtle symmetries of the
Kepler/Coulomb problem.

3.2.2

Nearly Circular Orbits

For a general central potential we cannot find an analytic form for the motion,
which involves solving the effective one-dimensional problem with Ueff (r) =

74

CHAPTER 3. TWO BODY CENTRAL FORCES

U (r)+L2 /2¬µr2 . If Ueff (r) has a minimum at r = a, one solution is certainly a
circular orbit of radius a. The minimum requires dUeff (r)/dr = 0 = ‚àíF (r) ‚àí
L2 /¬µr3 , so
F (a) = ‚àí

L2
.
¬µa3

We may also ask about trajectories which differ only slightly from this orbit,
for which |r ‚àí a| is small. Expanding Ueff (r) in a Taylor series about a,
1
Ueff (r) = Ueff (a) + (r ‚àí a)2 k,
2
where
k =

d2 Ueff
dr2 a

3L2
dF
3F
dF
+ 4 =‚àí
+
= ‚àí
dr
¬µa
dr
a

!

.

For r = a to be a minimum and the nearly circular orbits to be stable, the
second derivative and k must be positive, and therefore F 0 + 3F/a < 0. As
4
always when we treat a problem as small deviations from a stable
q equilibrium
we have harmonic oscillator motion, with a period Tosc = 2œÄ ¬µ/k.
As a simple class of examples, consider the case where the force law
depends on r with a simple power, F = ‚àícrn . Then k = (n + 3)can‚àí1 , which
is positive and the orbit stable only if n > ‚àí3. For gravity, n = ‚àí2, c =
K, k = K/a3 , and
s

Tosc = 2œÄ

¬µa3
K

agreeing with what we derived for the more general motion, not restricted to
small deviations from circularity. But for more general n, we find
Tosc
4

v
u
u
= 2œÄ t

¬µa1‚àín
.
c(n + 3)

This statement has an exception if the second derivative vanishes, k = 0.

3.2. INTEGRATING THE MOTION

75

The period of revolution Trev can be calculated for the circular orbit, as
L = ¬µa2 œÜÃá = ¬µa2

q
2œÄ
= ¬µa3 |F (a)|,
Trev

so
s

¬µa
|F (a)|

s

¬µa1‚àín
.
c

Trev = 2œÄ
which for the power law case is
Trev = 2œÄ

Thus the two periods Tosc and Trev are not equal unless n = ‚àí2, as in the
gravitational case. Let us define the apsidal angle œà as the angle between
‚àö
an apogee and the next perigee. It is therefore œà = œÄTosc /Trev = œÄ/ 3 + n.
For the gravitational case œà = œÄ, the apogee and perigee are on opposite sides
of the orbit. For a two- or three-dimensional harmonic oscillator F (r) = ‚àíkr
we have n = 1, œà = 12 œÄ, and now an orbit contains two apogees and two
perigees, and is again an ellipse, but now with the center-of-force at the
center of the ellipse rather than at one focus.
Note that if œà/œÄ is not rational, the orbit never closes, while if œà/œÄ = p/q,
the orbit will close after p revolutions, having reached q apogees and perigees.
The orbit will then be closed, but unless p = 1 it will be self-intersecting.
This exact closure is also only true in the small deviation approximation;
more generally, Bertrand‚Äôs Theorem states that only for the n = ‚àí2 and
n = 1 cases are the generic orbits closed.
In the treatment of planetary motion, the precession of the perihelion is
the angle though which the perihelion slowly moves, so it is 2œà ‚àí2œÄ per orbit.
We have seen that it is zero for the pure inverse force law. There is actually
some precession of the planets, due mostly to perturbative effects of the other
planets, but also in part due to corrections to Newtonian mechanics found
from Einstein‚Äôs theory of general relativity. In the late nineteenth century
discrepancies in the precession of Mercury‚Äôs orbit remained unexplained, and
the resolution by Einstein was one of the important initial successes of general
relativity.

76

CHAPTER 3. TWO BODY CENTRAL FORCES

3.3

The Laplace-Runge-Lenz Vector

The remarkable simplicity of the motion for the Kepler and harmonic oscillator central force problems is in each case connected with a hidden symmetry.
We now explore this for the Kepler problem.
For any central force problem F~ = p~Àô = f (r)eÃÇr we have a conserved
~ = ¬µ(~r √ó ~rÀô), for L
~Àô = ¬µ~rÀô √ó ~rÀô + (f (r)/r)~r √ó ~r = 0. The
angular momentum L
~ and the vector
motion is therefore confined to a plane perpendicular to L,
~
p~ √ó L is always in the plane of motion, as are ~r and p~. Consider the evolution
~ with time5
of p~ √ó L

d 
~ = p~Àô √ó L
~ = F~ √ó L
~ = ¬µf (r)eÃÇr √ó (~r √ó ~rÀô)
p~ √ó L
dt


= ¬µf (r) ~reÃÇr ¬∑ ~rÀô ‚àí ~rÀôeÃÇr ¬∑ ~r = ¬µf (r)(rÃá~r ‚àí r~rÀô)

On the other hand, the time variation of the unit vector eÃÇr = ~r/r is
d ~r
rÃá~r ‚àí r~rÀô
d
~rÀô rÃá~r
eÃÇr =
= ‚àí 2 =‚àí
.
dt
dt r
r r
r2
For the Kepler case, where f (r) = ‚àíK/r2 , these are proportional to each
other with a constant ratio, so we can combine them to form a conserved
~ = p~ √ó L
~ ‚àí ¬µK eÃÇr , called6 the Laplace-Runge-Lenz vector,
quantity A
~
dA/dt = 0.
While we have just found three conserved quantities in addition to the
~ these cannot all
conserved energy and the three conserved components of L,
~
be independent. Indeed we have already noted that A lies in the plane of
~ so A
~ ¬∑L
~ = 0. If we dot A
~ into the position
motion and is perpendicular to L,
vector,
~ ¬∑ ~r = ~r ¬∑ (~p √ó (~r √ó p~)) ‚àí ¬µKr = (~r √ó p~)2 ‚àí ¬µKr = L2 ‚àí ¬µKr,
A
~ and ~r, we have Ar cos Œ∏ + ¬µKr = L2 , or
so if Œ∏ is the angle between A
!

¬µK
A
1
= 2 1+
cos Œ∏ ,
r
L
¬µK
~ B√ó
~ C)
~ = B(
~ A¬∑
~ C)‚àí
~ C(
~ A¬∑
~ B),
~ and eÃÇr ¬∑~rÀô = (1/r)~r ¬∑~rÀô = (1/2r)d(r2 )/dt =
Some hints: A√ó(
rÃá. The first equation, known as the bac-cab equation, is shown in Appendix A.1.
6
by Goldstein, at least. While others often use only the last two names, Laplace clearly
has priority.
5

3.4. THE VIRIAL THEOREM

77

which is an elegant way of deriving the formula we found previously by
~ is a constant
integration, with A = ¬µKe. Note Œ∏ = 0 is the perigee, so A
vector pointing towards the perigee.
~ is given in terms of e, which we have
We also see that the magnitude of A
previously related to L and E, so A2 = ¬µ2 K 2 + 2¬µEL2 is a further relation
among the seven conserved quantities, showing that only five are independent. There could not be more than five independent conserved functions
depending analytically on the six variables of phase space (for the relative
motion only), for otherwise the point representing the system in phase space
would be unable to move. In fact, the five independent conserved quantities
on the six dimensional dimensional phase space confine a generic invariant
set of states, or orbit, to a one dimensional subspace. For power laws other
than n = ‚àí2 and n = 1, as the orbits do not close, they are dense in a two
dimensional region of phase space, indicating that there cannot be more than
four independent conserved analytic functions on phase space. So we see the
~ in the Kepler case and
connection between the existence of the conserved A
the fact that the orbits are closed.

3.4

The virial theorem

Consider a system of particles and the quantity G =
at which this changes is

~i ¬∑ ~ri . Then the rate
ip

P

dG X ~
Fi ¬∑ ~ri + 2T.
=
dt
If the system returns to a region in phase space where it had been, after some
time, G returns to what it was, and the average value of dG/dt vanishes,
*

dG
dt

+

=

DX

E

F~i ¬∑ ~ri + 2 hT i = 0.

This average will also be zero if the region stays in some bounded part of
phase space for which G can only take bounded values, and the averaging time
is taken to infinity. This is appropriate for a system in thermal equilibrium,
for example.
Consider a gas of particles which interact only with the fixed walls of the
container, so that the force acts only on the surface, and the sum becomes
~ where p is the uniform pressure and dA
~ is
an integral over dF~ = ‚àípdA,

78

CHAPTER 3. TWO BODY CENTRAL FORCES

an outward pointing vector representing a small piece of the surface of the
volume. Then
DX

E

F~i ¬∑ ~ri = ‚àí

Z

~ = ‚àíp
p~r ¬∑ dA

Z

Œ¥V

‚àá ¬∑ ~rdV = ‚àí3pV

V

so h2T i = 3pV . In thermodynamics we have the equipartition theorem
which states that hT i = 32 N kB œÑ , where N is the number of particles, kB is
Boltzmann‚Äôs constant and œÑ the temperature, so pV = N kB œÑ .
A very different application occurs for a power law central force between
pairs of particles, say for a potential U (~ri , ~rj ) = c|~ri ‚àí ~rj |n+1 . Then this
action and reaction contribute F~ij ¬∑ ~rj + F~ji ¬∑ ~ri = F~ji ¬∑ (~ri ‚àí ~rj ) =
‚àí(n + 1)c|~ri ‚àí ~rj |n+1 = ‚àí(n + 1)U (~ri , ~rj ). So summing over all the particles
P
and using h2T i = ‚àíh F~ ¬∑ ~ri, we have
hT i =

n+1
hU i.
2

For Kepler, n = ‚àí2, so hT i = ‚àí 12 hU i = ‚àíhT +U i = ‚àíE must hold for closed
orbits or for large systems of particles which remain bound and uncollapsed.
It is not true, of course, for unbound systems which have E > 0.
The fact that the average value of the kinetic energy in a bound system
gives a measure of the potential energy is the basis of the measurements
of the missing mass, or dark matter, in galaxies and in clusters of galaxies.
This remains a useful tool despite the fact that a multiparticle gravitationally
bound system can generally throw off some particles by bringing others closer
together, so that, strictly speaking, G does not return to its original value or
remain bounded.

3.5

Rutherford Scattering

We have discussed the 1/r potential in terms of Newtonian gravity, but of
course it is equally applicable to Coulomb‚Äôs law of electrostatic forces. The
force between nonrelativistic charges Q and q is given7 by
F~ =
7

1 Qq
~r,
4œÄ0 r3

Here we use S. I. or rationalized MKS units. For Gaussian units drop the 4œÄ0 , or for
Heaviside-Lorentz units drop only the 0 .

3.5. RUTHERFORD SCATTERING

79

and the potential energy is U (r) = ‚àíK/r with K = ‚àíQq/4œÄ0 .
Unlike gravity, the force is not always attractive (K > 0), and for
like sign charges we have K < 0,
and therefore U and the total energy are always positive, and there
are no bound motions. Whatever
the relative signs, we are going to
consider scattering here, and therefore positive energy solutions with
the initial state of finite speed v0
and r ‚Üí ‚àû. Thus the relative motion is a hyperbola, with

Œ∏

r

Œ±

œÜ

Œ±

1+e
1 + e cos œÜ
s
2EL2
e = ¬± 1+
.
¬µK 2

r = rp

b

This starts and ends with r ‚Üí ‚àû,
at œÜ ‚Üí ¬±Œ± = ¬± cos‚àí1 (‚àí1/e), and
the angle Œ∏ through which the velocity changes is called the scattering angle. For simplicity we
will consider the repulsive case,
with e < 0 so that Œ± < œÄ/2.
We see that Œ∏ = œÄ ‚àí 2Œ±, so

Rutherford scattering. An Œ± particle approaches a heavy nucleus
with an impact parameter b, scattering through an angle Œ∏. The
cross sectional area dœÉ of the incident beam is scattered through angles ‚àà [Œ∏, Œ∏ + dŒ∏].

cos Œ±
|e|‚àí1
1
Œ∏
q
=
=‚àö 2
=
tan = cot Œ± = ‚àö
2
2
1 ‚àí cos Œ±
e ‚àí1
1 ‚àí |e|‚àí2

s

¬µK 2
.
2EL2

We have K = Qq/4œÄ0 . We need to evaluate E and L. At r = ‚àû, U ‚Üí 0,
E = 21 ¬µv02 , L = ¬µbv0 , where b is the impact parameter, the distance by
which the asymptotic line of the initial motion misses the scattering center.
Thus
¬µ
Œ∏
|K|
tan = |K|
=
.
2
2
2
¬µv0 (¬µbv0 )
¬µbv02
s

(3.7)

80

CHAPTER 3. TWO BODY CENTRAL FORCES

The scattering angle therefore depends on b, the perpendicular displacement from the axis parallel to the beam through the nucleus. Particles
passing through a given area will be scattered through a given angle, with
a fixed angle Œ∏ corresponding to a circle centered on the axis, having radius
b(Œ∏) given by 3.7. The area of the beam dœÉ in an annular ring of impact
parameters ‚àà [b, b + db] is dœÉ = 2œÄb|db|. To relate db to dŒ∏, we differentiate
the scattering equation for fixed v0 ,
Œ∏
‚àíK
1
sec2 dŒ∏ = 2 2 db,
2
2
¬µv0 b
¬µv02 b2
œÄ¬µv02 b3
dœÉ
= 2œÄb
=
dŒ∏
2K cos2 (Œ∏/2)
K cos2 (Œ∏/2)
œÄ¬µv02
=
K cos2 (Œ∏/2)
œÄ
=
2

K
¬µv02

!2

K
¬µv02

!3

cos Œ∏/2
sin Œ∏/2

!3

K
=œÄ
¬µv02

!2

cos Œ∏/2
sin3 Œ∏/2

sin Œ∏
.
sin4 Œ∏/2

(The last expression is useful because sin Œ∏dŒ∏ is the ‚Äúnatural measure‚Äù for Œ∏,
in the sense that integrating over volume in spherical coordinates is d3 V =
r2 dr sin Œ∏dŒ∏dœÜ.)
How do we measure dœÉ/dŒ∏? There is a beam of N particles shot at
random impact parameters onto a foil with n scattering centers per unit
area, and we confine the beam to an area A. Each particle will be significantly
scattered only by the scattering center to which it comes closest, if the foil
is thin enough. The number of incident particles per unit area is N/A, and
the number of scatterers being bombarded is nA, so the number which get
scattered through an angle ‚àà [Œ∏, Œ∏ + dŒ∏] is
dœÉ
dœÉ
N
√ó nA √ó
dŒ∏ = N n dŒ∏.
A
dŒ∏
dŒ∏
We have used the cylindrical symmetry of this problem to ignore the œÜ
dependance of the scattering. More generally, the scattering would not be
uniform in œÜ, so that the area of beam scattered into a given region of (Œ∏,œÜ)
would be
dœÉ
dœÉ =
sin Œ∏dŒ∏dœÜ,
d‚Ñ¶

3.5. RUTHERFORD SCATTERING

81

where dœÉ/d‚Ñ¶ is called the differential cross section. For Rutherford scattering we have
!2
dœÉ
1 K
Œ∏
=
csc4 .
2
d‚Ñ¶
4 ¬µv0
2
Scattering in other potentials
We see that the cross section depends on the angle through which the incident
particle is scattered for a given impact parameter. In Rutherford scattering
Œ∏ increases monotonically as b decreases, which is possible only because the
force is ‚Äúhard‚Äù, and a particle aimed right at the center will turn around
rather than plowing through. This was a surprize to Rutherford, for the
concurrent model of the nucleus, Thompson‚Äôs plum pudding model, had the
nuclear charge spread out over some atomic-sized spherical region, and the
Coulomb force would have decreased once the alpha particle entered this
region. So sufficiently energetic alpha particles aimed at the center should
have passed through undeflected instead of scattered backwards. In fact, of
course, the nucleus does have a finite size, and this is still true, but at a much
smaller distance, and therefore a much larger energy.
If the scattering angle Œ∏(b) does run smoothly from 0 at b = 0 to 0 at
b ‚Üí ‚àû, as shown, then there is an extremal value for which dŒ∏/db|b0 = 0,
and for Œ∏ < Œ∏(b0 ), dœÉ/dŒ∏ can get contributions from several different b‚Äôs,
X bi db
dœÉ
=
.
d‚Ñ¶
i sin Œ∏ dŒ∏ i

It also means that the cross section becomes infinite as Œ∏ ‚Üí Œ∏(b0 ),
and vanishes above that value of Œ∏
Œ∏ (b0 )
Œ∏. This effect is known as rainbow scattering, and is the cause
of rainbows, because the scattering
for a given color light off a water
b0
droplet is very strongly peaked at
b
the maximum angle of scattering.
Another unusual effect occurs when Œ∏(b) becomes 0 or œÄ for some nonzero
value of b, with db/dŒ∏ finite. Then dœÉ/d‚Ñ¶
blows up due to the sin Œ∏ in the
R
denominator, even though the integral (dœÉ/d‚Ñ¶) sin Œ∏dŒ∏dœÜ is perfectly finite.

82

CHAPTER 3. TWO BODY CENTRAL FORCES

This effect is called glory scattering, and can be seen around the shadow
of a plane on the clouds below.

Exercises
3.1 A space ship is in circular orbit at radius R and speed v1 , with the period
of revolution œÑ1 . The crew wishes to go to planet X, which is in a circular orbit
of radius 2R, and to revolve around the Sun staying near planet X. They propose
to do this by firing two blasts, one putting them in an orbit with perigee R and
apogee 2R, and the second, when near X, to change their velocity so they will have
the same speed as X.
‚Ä¢ (a) By how much must the first blast change their velocity? Express your
answer in terms of v1 .
‚Ä¢ (b) How long will it take until they reach the apogee? Express your answer
in terms of œÑ1
‚Ä¢ (c) By how much must the second blast change their speed? Will they need
to slow down or speed up, relative to the sun.
3.2 Consider a spherical droplet of water in the sunlight. A ray of light with
impact parameter b is refracted, so by Snell‚Äôs Law n sin Œ≤ = sin Œ±. It is then
internally reflected once and refracted again on the way out.
(a) Express the scattering angle Œ∏ in terms of Œ± and Œ≤.
(b) Find the scattering cross section
dœÉ/d‚Ñ¶ as a function of Œ∏, Œ± and Œ≤
(which is implicitly a function of Œ∏
from (a) and Snell‚Äôs Law).
(c) The smallest value of Œ∏ is called
the rainbow scattering angle. Why?
Œ±
Find it numerically to first order in
b
Œ≤
Œ¥ if the index of refraction is n =
1.333 + Œ¥
(d) The visual spectrum runs from violet, where n = 1.343, to red, where
n = 1.331. Find the angular radius
of the rainbow‚Äôs circle, and the anŒ∏
gular width of the rainbow, and tell
whether the red or blue is on the out- One way light can scatter from a
side.
spherical raindrop.

3.5. RUTHERFORD SCATTERING

83

3.3 Consider a particle constrained to move on the surface described in cylindrical
coordinates by z = Œ±r3 , subject to a constant gravitational force F~ = ‚àímgeÃÇz .
Find the Lagrangian, two conserved quantities, and reduce the problem to a one
dimensional problem. What is the condition for circular motion at constant r?
3.4 From the general expression for œÜ as an integral over r, applied to a three
dimensional symmetrical harmonic oscillator U (~r) = 21 kr2 , integrate the equation,
and show that the motion is an ellipse, with the center of force
‚àö at the center of
the ellipse. Consider the three complex quantities Qi = pi ‚àí i kmri , and show
that each has a very simple equation of motion, as a consequence of which the
nine quantities Q‚àói Qk are conserved. Identify as many as possible of these with
previously known conserved quantities.
3.5 Show that if a particle under the influence of a central force has an orbit
which is a circle passing through the point of attraction, then the force is a power
law with |F | ‚àù r‚àí5 . Assuming the potential is defined so that U (‚àû) = 0, show
that for this particular orbit E = 0. In terms of the diameter and the angular
momentum, find the period, and by expressing xÃá, yÃá and the speed as a function of
the angle measured from the center of the circle, and its derivative, show that xÃá, yÃá
and the speed all go to infinity as the particle passes through the center of force.

3.6 For the Kepler problem we have the relative position tracing out an ellipse.
What is the curve traced out by the momentum in momentum space? Show that
~ √ó A/L
~ 2 , where L
~ and A
~ are the angular momentum and
it is a circle centered at L
Runge-Lenz vectors respectively.
3.7 The Rutherford cross section implies all incident projectiles will be scattered
and emerge at some angle Œ∏, but a real planet has a finite radius, and a projectile
that hits the surface is likely to be captured rather than scattered.
What is the capture cross section for an airless planet of radius R and mass M
for a projectile with a speed v0 ? How is the scattering differential cross section
modified from the Rutherford prediction?
3.8 In problem 2.12 we learned that the general-relativistic motion of a particle
in a gravitational field is given by Hamilton‚Äôs variational principle on the path
x¬µ (Œª) with the action
Z

S=

dŒªL

with

v
uX
u
dx¬µ dxŒΩ
L = mct g¬µŒΩ (xœÅ )
,
¬µŒΩ

dŒª dŒª

84

CHAPTER 3. TWO BODY CENTRAL FORCES

where we may freely choose the path parameter Œª to be the proper time (after
‚àö
doing the variation), so that the
is c, the speed of light.
The gravitational field of a static point mass M is given by the
Schwartzschild metric
g00 = 1 ‚àí

2GM
,
rc2



grr = ‚àí1

1‚àí

2GM
rc2



,

gŒ∏Œ∏ = ‚àír2 ,

gœÜœÜ = ‚àír2 sin2 Œ∏,

where all other components of g¬µŒΩ are zero. Treating the four x¬µ (Œª) as the coordinates, with Œª playing the role of time, find the four conjugate momenta p¬µ , show
that p0 and pœÜ = L are constants, and use the freedom to choose
1
Œª=œÑ =
c
to show m2 c2 =
show that

P

¬µŒΩ g

¬µŒΩ p

dr
=
dœÑ

v
Z uX
u
dx¬µ dxŒΩ
t
g¬µŒΩ (xœÅ )

¬µ pŒΩ , where g

s

¬µŒΩ

dŒª dŒª

¬µŒΩ is the inverse matrix to g . Use this to
Œ±Œ≤

2GM
L2
2GM L2
Œ∫‚àí ‚àí
+ 2 2‚àí 2 3 2 ,
r
m r
m r c




where Œ∫ is a constant. For an almost circular orbit at the minimum r = a of
the effective potential this implies, show that the precession of the perihelion is
6œÄGM/ac2 .
Find the rate of precession for Mercury, with G = 6.67 √ó 10‚àí11 Nm2 /kg2 , M =
1.99 √ó 1030 kg and a = 5.79 √ó 1010 m, per revolution, and also per century, using
the period of the orbit as 0.241 years.

Chapter 4
Rigid Body Motion
In this chapter we develop the dynamics of a rigid body, one in which all
interparticle distances are fixed by internal forces of constraint. This is,
of course, an idealization which ignores elastic and plastic deformations to
which any real body is susceptible, but it is an excellent approximation for
many situations, and vastly simplifies the dynamics of the very large number
of constituent particles of which any macroscopic body is made. In fact, it
reduces the problem to one with six degrees of freedom. While the ensuing
motion can still be quite complex, it is tractible. In the process we will be
dealing with a configuration space which is a group, and is not a Euclidean
space. Degrees of freedom which lie on a group manifold rather than Euclidean space arise often in applications in quantum mechanics and quantum
field theory, in addition to the classical problems we will consider such as
gyroscopes and tops.

4.1

Configuration space for a rigid body

A macroscopic body is made up of a very large number of atoms. Describing
the motion of such a system without some simplifications is clearly impossible. Many objects of interest, however, are very well approximated by the
assumption that the distances between the atoms in the body are fixed1 ,
|~rŒ± ‚àí ~rŒ≤ | = cŒ±Œ≤ = constant.
1

(4.1)

In this chapter we will use Greek letters as subscripts to represent the different particles
within the body, reserving Latin subscripts to represent the three spatial directions.

85

86

CHAPTER 4. RIGID BODY MOTION

This constitutes a set of holonomic constraints, but not independent ones, as
we have here 21 n(n ‚àí 1) constraints on 3n coordinates. Rather than trying to
solve the constraints, we can understand what are the generalized coordinates
by recognizing that the possible motions which leave the interparticle lengths
fixed are combinations of
~
‚Ä¢ translations of the body as a whole, ~rŒ± ‚Üí ~rŒ± + C,
‚Ä¢ rotations of the body about some fixed, or ‚Äúmarked‚Äù, point.
We will need to discuss how to represent the latter part of the configuration,
(including what a rotation is), and how to reexpress the kinetic and potential
energies in terms of this configuration space and its velocities.
The first part of the configuration, describing the translation, can be
specified by giving the coordinates of the marked point fixed in the body,
e
R(t).
Often, but not always, we will choose this marked point to be the
~
center of mass R(t)
of the body. In order to discuss other points which are
part of the body, we will use an orthonormal coordinate system fixed in the
body, known as the body coordinates, with the origin at the fixed point
e The constraints mean that the position of each particle of the body has
R.
fixed coordinates in terms of this coordinate system. Thus the dynamical
configuration of the body is completely specified by giving the orientation of
e This orientation needs to be described
these coordinate axes in addition to R.
relative to a fixed inertial coordinate system, or inertial coordinates, with
orthonormal basis eÃÇi .
Let the three orthogonal unit vectors defining the body coordinates be
0
eÃÇi , for i = 1, 2, 3. Then the position of any particle Œ± in the body which has
e+
coordinates b0Œ±i in the body coordinate system is at the position ~rŒ± = R
P 0 0
P
rŒ± = i rŒ±i eÃÇi
i bŒ±i eÃÇi . In order to know its components in the inertial frame ~
0
we need to know the coordinates of the three vectors eÃÇi in terms of the inertial
coordinates,
X
eÃÇ0i =
Aij eÃÇj .
(4.2)
j

e =
The nine quantities Aij , together with the three components of R
specify the position of every particle,

rŒ±i = RÃÉi +

X
j

b0Œ±j Aji ,

P e

Ri eÃÇi ,

4.1. CONFIGURATION SPACE FOR A RIGID BODY

87

e (t) and
and the configuration of the system is completely specified by R
i
Aij (t).
The nine real quantities in the matrix Aij are not independent, for the
basis vectors eÃÇ0i of the body-fixed coordinate system are orthonormal,

eÃÇ0i ¬∑ eÃÇ0k = Œ¥ik =

X

Aij Ak` eÃÇj ¬∑ eÃÇ` =

j`

X

Aij Ak` Œ¥j` =

X

Aij Akj ,

j

j`

or in matrix languag AAT = 1I. Such a matrix of real values, whose transpose
is equal to its inverse, is called orthogonal, and is a transformation of basis
vectors which preserves orthonormality of the basis vectors. Because they
play such an important role in the study of rigid body motion, we need to
explore the properties of orthogonal transformations in some detail.

4.1.1

Orthogonal Transformations

There are two ways of thinking about an orthogonal transformation A and
its action on an orthonormal basis, (Eq. 4.2). One way is to consider that
{eÃÇi } and {eÃÇ0i } are simply different basis vectors used to describe the same
physical vectors in the same vector space. A vector V~ is the same vector
P
P
whether it is expanded in one basis V~ = j Vj eÃÇj or the other V~ = i Vi0 eÃÇ0i .
Thus
V~ =

X
j

Vj eÃÇj =

X

Vi0 eÃÇ0i =

i

X

Vi0 Aij eÃÇj ,

ij

and we may conclude from the fact that the eÃÇj are linearly independent
P
that Vj = i Vi0 Aij , or in matrix notation that V = AT V 0 . Because A is
orthogonal, multiplying by A (from the left) gives V 0 = AV , or
Vi0 =

X

Aij Vj .

(4.3)

j

Thus A is to be viewed as a rule for giving the primed basis vectors in terms
of the unprimed ones (4.2), and also for giving the components of a vector in
the primed coordinate system in terms of the components in the unprimed
one (4.3). This picture of the role of A is called the passive interpretation.
One may also use matrices to represent a real physical transformation
of an object or quantity. In particular, Eq. 4.2 gives A the interpretation
of an operator that rotates each of the coordinate basis eÃÇ1 , eÃÇ2 , eÃÇ3 into the

88

CHAPTER 4. RIGID BODY MOTION

corresponding new vector eÃÇ01 , eÃÇ02 , or eÃÇ03 . For real rotation of the physical
system, all the vectors describing the objects are changed by the rotation
into new vectors V~ ‚Üí V~ (R) , physically different from the original vector, but
having the same coordinates in the primed basis as V has in the unprimed
basis. This is called the active interpretation of the transformation. Both
active and passive views of the transformation apply here, and this can easily
lead to confusion. The transformation A(t) is the physical transformation
which rotated the body from some standard orientation, in which the body
axes eÃÇ0i were parallel to the ‚Äúlab frame‚Äù axes eÃÇi , to the configuration of the
body at time t. But it also gives the relation of the components of the same
position vectors (at time t) expressed in body fixed and lab frame coordinates.
If we first consider rotations in two dimensions, it is clear that they are
generally described by the counterclockwise angle Œ∏ through which the basis
is rotated,

eÃÇ01 = cos Œ∏eÃÇ1 + sin Œ∏eÃÇ2
eÃÇ02 = ‚àí sin Œ∏eÃÇ1 + cos Œ∏eÃÇ2

e^‚Äô2

A=

cos Œ∏
‚àí sin Œ∏

Œ∏
^
e1

corresponding to the matrix


Œ∏ e^2 ^e‚Äô
1

sin Œ∏
.
cos Œ∏


(4.4)

Clearly taking the transpose simply changes the sign of Œ∏, which is just
what is necessary to produce the inverse transformation. Thus each two
dimensional rotation is an orthogonal transformation. The orthogonality
equation A ¬∑ AT = 1 has four matrix elements. It is straightforward to show
that these four equations on the four elements of A determine A to be of
the form (4.4) except that the sign of the bottom row is undetermined. For
example, the transformation eÃÇ01 = eÃÇ1 , eÃÇ02 = ‚àíeÃÇ2 is orthogonal but is not
a rotation. Let us call this transformation P . Thus any two-dimensional
orthogonal matrix is a rotation or is P followed by a rotation. The set of
all real orthogonal matrices in two dimensions is called O(2), and the subset
consisting of rotations is called SO(2).
In three dimensions we need to take some care with what we mean by
a rotation. On the one hand, we might mean that the transformation has

4.1. CONFIGURATION SPACE FOR A RIGID BODY

89

some fixed axis and is a rotation through some angle about that axis. Let
us call that a rotation about an axis. On the other hand, we might mean
all transformations we can produce by a sequence of rotations about various
axes. Let us define rotation in this sense. Clearly if we consider the rotation
R which rotates the basis {eÃÇ} into the basis {eÃÇ0 }, and if we have another
rotation R0 which rotates {eÃÇ0 } into {eÃÇ00 }, then the transformation which first
does R and then does R0 , called the composition of them, RÃÜ = R0 ‚ó¶R, is also
P
P
0 0
0
eÃÇj = ij Rij
Rjk eÃÇk , we see that
a rotation in this latter sense. As eÃÇ00i = j Rij
P
P
00
0
RÃÜik = j Rij Rjk and eÃÇi = k RÃÜik eÃÇk . Thus the composition RÃÜ = R0 R is given
by matrix multiplication. In two dimensions, straightforward evaluation will
verify that if R and R0 are of the form (4.4) with angles Œ∏ and Œ∏0 respectively,
the product RÃÜ is of the same form with angle Œ∏ÃÜ = Œ∏ + Œ∏0 . Thus all rotations
are rotations about an axis there. Rotations in three dimensions are a bit
more complex, because they can take place in different directions as well as
through different angles. We can still represent the composition of rotations
with matrix multiplication, now of 3√ó3 matrices. In general, matrices do not
commute, AB 6= BA, and this is indeed reflected in the fact that the effect
of performing two rotations depends in the order in which they are done.
A graphic illustration is worth trying. Let V be the process of rotating an
object through 90‚ó¶ about the vertical z-axis, and H be a rotation through 90‚ó¶
about the x-axis, which goes goes off to our right. If we start with the book
lying face up facing us on the table, and first apply V and then H, we wind
up with the binding down and the front of the book facing us. If, however,
we start from the same position but apply first H and then V , we wind up
with the book standing upright on the table with the binding towards us.
Clearly the operations H and V do not commute.

It is clear that any composition of rotations must be orthogonal, as any
set of orthonormal basis vectors will remain orthonormal under each transformation. It is also clear that there is a three dimensional version of P , say
eÃÇ01 = eÃÇ1 , eÃÇ02 = eÃÇ2 , eÃÇ03 = ‚àíeÃÇ3 , which is orthogonal but not a composition of
rotations, for it changes a right-handed coordinate system (with eÃÇ1 √ó eÃÇ2 = eÃÇ3 )
to a left handed one, while rotations preserve the handedness. It is straightforward to show, in any dimension N , that any composition of orthogonal
matrices is orthogonal, for if AAT = 1I and BB T = 1I and C = AB, then
CC T = AB(AB)T = ABB T AT = A 1I AT = 1I, and C is orthogonal as well.
So the rotations are a subset of the set O(N ) of orthogonal matrices.

90

CHAPTER 4. RIGID BODY MOTION

H

V

V:
H:

H

V

Figure 4.1: The results of applying the two rotations H and V to a book
depends on which is done first. Thus rotations do not commute. Here we
are looking down at a book which is originally lying face up on a table. V is
a rotation about the vertical z-axis, and H is a rotation about a fixed axis
pointing to the right, each through 90‚ó¶ .

4.1. CONFIGURATION SPACE FOR A RIGID BODY

4.1.2

91

Groups

This set of orthogonal matrices is a group, which means that the set O(N )
satisfies the following requirements, which we state for a general set G.
A set G of elements A, B, C, ... together with a group multiplication
rule ( ) for combining two of them, is a group if
‚Ä¢ Given any two elements A and B in the group, the product A B is
also in the group. One then says that the set G is closed under .
In our case the group multiplication is ordinary matrix multiplication,
the group consists of all N √ó N orthogonal real matrices, and we have
just shown that it is closed.
‚Ä¢ The product rule is associative; for every A, B, C ‚àà G, we have A
(B C) = (A B) C. For matrix multiplication this is simply due
P P
P P
to the commutivity of finite sums, i j = j i .
‚Ä¢ There is an element e in G, called the identity, such that for every
element A ‚àà G, e A = A e = A. In our case e is the unit matrix
1I, 1Iij = Œ¥ij .
‚Ä¢ Every element A ‚àà G has an element A‚àí1 ‚àà G such that A A‚àí1 =
A‚àí1 A = e. This element is called the inverse of A, and in the case of
orthogonal matrices is the inverse matrix, which always exists, because
for orthogonal matrices the inverse is the transpose, which always exists
for any matrix.
While the constraints (4.1) would permit A(t) to be any orthogonal matrix, the nature of Newtonian mechanics of a rigid body requires it to vary
continuously in time. If the system starts with A = 1I, there must be a continuous path in the space of orthogonal matrices to the configuration A(t) at any
later time. But the set of matrices O(3) is not connected in this fashion: there
is no path from A = 1I to A = P . To see it is true, we look at the determinant
of A. From AAT = 1I we see that det(AAT ) = 1 = det(A) det(AT ) = (det A)2
so det A = ¬±1 for all orthogonal matrices A. But the determinant varies continuously as the matrix does, so no continuous variation of the matrix can
lead to a jump in its determinant. Thus the matrices which represent rotations have unit determinant, det A = +1, and are called unimodular.
The set of all unimodular orthogonal matrices in N dimensions is called
SO(N ). It is a subset of O(N ), the set of all orthogonal matrices in N

92

CHAPTER 4. RIGID BODY MOTION

dimensions. Clearly all rotations are in this subset. The subset is closed
under multiplication, and the identity and the inverses of elements in SO(N )
are also in SO(N ), for their determinants are clearly 1. Thus SO(N ) is a
subgroup of O(N ). It is actually the set of rotations, but we shall prove
this statement only for the case N = 3, which is the immediately relevant
one. Simultaneously we will show that every rotation in three dimensions is
a rotation about an axis. We have already proven it for N = 2. We now
show that every A ‚àà SO(3) has one vector it leaves unchanged or invariant,
so that it is effectively a rotation in the plane perpendicular to this direction,
or in other words a rotation about the axis it leaves invariant. The fact that
every unimodular orthogonal matrix in three dimensions is a rotation about
an axis is known as Euler‚Äôs Theorem. To show that it is true, we note that
if A is orthogonal and has determinant 1,
n

o

det (A ‚àí 1I)AT = det(1I ‚àí AT ) = det(1I ‚àí A)
= det(A ‚àí 1I) det(A) = det(‚àí(1I ‚àí A)) = (‚àí1)3 det(1I ‚àí A)
= ‚àí det(1I ‚àí A),
so det(1I ‚àí A) = 0 and 1I ‚àí A is a singular matrix. Then there exists a vector
œâ
~ which is annihilated by it, (1I ‚àí A)~œâ = 0, or A~œâ = œâ
~ , and œâ
~ is invariant
under A. Of course this determines only the direction of œâ
~ , and only up
to sign. If we choose a new coordinate system in which the zÃÉ-axis points
along œâ
~ , we see that the elements AÃÉi3 = (0, 0, 1), and orthogonality gives
P 2
AÃÉ3j = 1 = AÃÉ233 so AÃÉ31 = AÃÉ32 = 0. Thus AÃÉ is of the form
Ô£´

AÃÉ =

Ô£≠ (B )

0 0

0
0Ô£∏
1
Ô£∂

where B is an orthogonal unimodular 2 √ó 2 matrix, which is therefore a
rotation about the z-axis through some angle œâ, which we may choose to be
in the range œâ ‚àà (‚àíœÄ, œÄ]. It is natural to define the vector œâ
~ , whose direction
only was determined above, to be œâ
~ = œâeÃÇzÃÉ . Thus we see that the set of
orthogonal unimodular matrices is the set of rotations, and elements of this
set may be specified by a vector2 of length ‚â§ œÄ.
2

More precisely, we choose œâ
~ along one of the two opposite directions left invariant by
A, so that the the angle of rotation is non-negative and ‚â§ œÄ. This specifies a point in or on
the surface of a three dimensional ball of radius œÄ, but in the case when the angle is exactly
œÄ the two diametrically opposed points both describe the same rotation. Mathematicians
say that the space of SO(3) is three-dimensional real projective space P3 (R)[4].

4.2. KINEMATICS IN A ROTATING COORDINATE SYSTEM

93

Thus we see that the rotation which determines the orientation of a rigid
body can be described by the three degrees of freedom œâ
~ . Together with
e
the translational coordinates R, this parameterizes the configuration space
of the rigid body, which is six dimensional. It is important to recognize that
this is not motion in a flat six dimensional configuration space, however. For
example, the configurations with œâ
~ = (0, 0, œÄ ‚àí ) and œâ
~ = (0, 0, ‚àíœÄ + )
approach each other as  ‚Üí 0, so that motion need not even be continuous
in œâ
~ . The composition of rotations is by multiplication of the matrices, not
by addition of the œâ
~ ‚Äôs. There are other ways of describing the configuration
space, two of which are known as Euler angles and Cayley-Klein parameters,
but none of these make describing the space very intuitive. For some purposes
we do not need all of the complications involved in describing finite rotations,
but only what is necessary to describe infinitesimal changes between the
configuration at time t and at time t + ‚àÜt. We will discuss these applications
first. Later, when we do need to discuss the configuration in section 4.4.2,
we will define Euler angles.

4.2

Kinematics in a rotating coordinate system

We have seen that the rotations form a group. Let us describe the configue
ration of the body coordinate system by the position R(t)
of a given point
0
and the rotation matrix A(t) : eÃÇi ‚Üí eÃÇi which transforms the canonical fixed
basis (inertial frame) into the body basis. A given particle of the body is
fixed in the body coordinates, but this, of course, is not an inertial coordinate
system, but a rotating and possibly accelerating one. We need to discuss the
transformation of kinematics between these two frames. While our current
interest is in rigid bodies, we will first derive a general formula for rotating
(and accelerating) coordinate systems.
P
Suppose a particle has coordinates ~b(t) = i b0i (t)eÃÇ0i (t) in the body system.
We are not assuming at the moment that the particle is part of the rigid
body, in which case the b0i (t) would be independent of time. In the inertial
e
coordinates the particle has its position given by ~r(t) = R(t)
+ ~b(t), but the
coordinates of ~b(t) are different in the space and body coordinates. Thus
e (t) + b (t) = R
e (t) +
ri (t) = R
i
i
i

X
j



A‚àí1 (t)

b0 (t).
ij j

94

CHAPTER 4. RIGID BODY MOTION

The velocity is ~v =
ered stationary, so

P

i rÃái eÃÇi , because the eÃÇi are inertial and therefore consid-

Ô£Æ

Ô£π


 db0 (t)
d ‚àí1
j
eÃá +
Ô£∞
Ô£ª eÃÇi ,
~v = R
A (t) b0j (t) + A‚àí1 (t)
ij
dt
dt
ij
ij
!

X

0
0
0
eÃá +
and not R
i (dbi /dt)eÃÇi , because the eÃÇi are themselves changing with time.
We might define a ‚Äúbody time derivative‚Äù

P

~bÀô

X db0i
d~
b :=
eÃÇ0i ,
dt b
dt
i
!

 

:=
b

!

e
but it is not the velocity of the particle Œ±, even with respect to R(t),
in the
sense that physically a vector is basis independent, and its derivative requires
a notion of which basis vectors are considered time independent (inertial) and
which are not. Converting the inertial evaluation to the body
 frame requires
Àô
‚àí1
~
the velocity to include the dA /dt term as well as the b term.
b

What is the meaning of this extra term
!

V=

X
ij

d ‚àí1
A (t) b0j (t)eÃÇi
dt
ij

?

The derivative is, of course,
i
1 X h ‚àí1
A (t + ‚àÜt)ij ‚àí A‚àí1 (t)ij b0j (t)eÃÇi .
‚àÜt‚Üí0 ‚àÜt
ij

V = lim

This expression has coordinates in the body frame with basis vectors from
the inertial frame. It is better to describe it in terms of the body coordinates
P
P
and body basis vectors by inserting eÃÇi = k (A‚àí1 (t)ik eÃÇ0k (t) = k Aki (t)eÃÇ0k (t).
Then we have
V=

X
kj

i
1 h
A(t)A‚àí1 (t + ‚àÜt) ‚àí A(t)A‚àí1 (t) b0j (t).
kj
‚àÜt‚Üí0 ‚àÜt

eÃÇ0k lim

The second term is easy enough to understand, as A(t)A‚àí1 (t) = 1I, so the
full second term is just ~b expressed in the body frame. The interpretation of
the first term is suggested by its matrix form: A‚àí1 (t + ‚àÜt) maps the body

4.2. KINEMATICS IN A ROTATING COORDINATE SYSTEM

95

basis at t + ‚àÜt to the inertial frame, and A(t) maps this to the body basis
at t. So together this is the infinitesimal rotation eÃÇ0i (t + ‚àÜt) ‚Üí eÃÇ0i (t). This
transformation must be close to an identity, as ‚àÜt ‚Üí 0. Let us expand it:
B := A(t)A‚àí1 (t + ‚àÜt) = 1I ‚àí ‚Ñ¶0 ‚àÜt + O(‚àÜt)2 .

(4.5)

Here ‚Ñ¶0 is a matrix which has fixed (finite) elements as ‚àÜt ‚Üí 0, and is
called the generator of the rotation. Note B ‚àí1 = 1I + ‚Ñ¶0 ‚àÜt to the order we
are working, while the transpose B T = 1I ‚àí ‚Ñ¶0 T ‚àÜt, so because we know B is
orthogonal we must have that ‚Ñ¶0 is antisymmetric, ‚Ñ¶0 = ‚àí‚Ñ¶0 T , ‚Ñ¶0ij = ‚àí‚Ñ¶0ji .
Subtracting 1I from both sides of (4.5) and taking the limit shows that
the matrix
d
‚Ñ¶ (t) = ‚àíA(t) ¬∑ A‚àí1 (t) =
dt
0

!

d
A(t) ¬∑ A‚àí1 (t),
dt

where the latter equality follows from differentiating A ¬∑ A‚àí1 = 1I. The
antisymmetric 3 √ó 3 real matrix ‚Ñ¶0 is determined by the three off-diagonal
elements above the diagonal, ‚Ñ¶023 = œâ10 , ‚Ñ¶013 = ‚àíœâ20 , ‚Ñ¶012 = œâ30 . as the
others are given by antisymmetry. Thus it is effectively a vector. It is very
useful to express this relationship by defining the Levi-Civita symbol ijk ,
a totally antisymmetric rank 3 tensor specified by 123 = 1. Then the above
P
expressions are given by ‚Ñ¶0ij = k ijk œâk0 , and we also have
1X
1X
kij ‚Ñ¶0ij =
kij ij` œâ`0 = œâk0 ,
2 ij
2 ij`
because, as explored in Appendix A.1,
X

kij = ijk ,

i

ijk ipq = Œ¥jp Œ¥kq ‚àí Œ¥jq Œ¥kp ,

so

X

ijk ij` = 2Œ¥k` .

ij

Thus œâk0 and ‚Ñ¶0ij are essentially the same thing.
We have still not answered the question, ‚Äúwhat is V?‚Äù
V =

X
kj

X
X
1
[B ‚àí 1I]kj b0j = ‚àí
eÃÇ0k ‚Ñ¶0kj b0j = ‚àí
eÃÇ0k kj` œâ`0 b0j
‚àÜt‚Üí0 ‚àÜt
kj
kj`

eÃÇ0k lim

= œâ
~ √ó ~b,
where œâ
~ = ` œâ`0 eÃÇ0` . Note we have used Eq. A.4 for the cross-product. Thus
we have shown that
Àô
eÃá + œâ
~v = R
~ √ó ~b + (~b)b ,
(4.6)
P

96

CHAPTER 4. RIGID BODY MOTION

and the second term, coming from V, represents the motion due to the rotating coordinate system.
When differentiating a true vector, which is independent of the origin
of the coordinate system, rather than a position, the first term in (4.6) is
~
absent, so in general for a vector C,
Ô£∂

Ô£´

~
d ~ Ô£≠ dC
~
Ô£∏ + œâ √ó C.
C=
dt
dt

(4.7)

b

eÃá and ~b, the latter because it is the difference
The velocity ~v is a vector, as are R
of two positions. The angular velocity œâ
~ is also a vector3 , and its derivative
is particularly simple, because

d
œâ
~Àô = œâ
~ =
dt

d~œâ
dt

!

+œâ
~ √óœâ
~ =
b

d~œâ
dt

!

.

(4.8)

b

Another way to understand (4.7) is as a simple application of Leibnitz‚Äô
~ = P C 0 eÃÇ0 , noting that
rule to C
i i
X d
X
X
d 0
eÃÇi (t) =
Aij (t)eÃÇj =
(‚Ñ¶0 A)ij eÃÇj =
‚Ñ¶0ik eÃÇ0k ,
dt
dt
j
j
k

which means that the second term from Leibnitz is
X

Ci0

X
X
d 0
~
eÃÇi (t) =
Ci0 ‚Ñ¶0ik eÃÇ0k =
Ci0 ikj œâj0 eÃÇ0k = œâ
~ √ó C,
dt
ik
ijk

Àô
as given in (4.7). This shows that even the peculiar object (~b)b obeys (4.7).
Applying this to the velocity itself (4.6), we find the acceleration
d
d eÃá dœâ ~
d
d Àô
~v = R
+
√ó b + œâ √ó ~b + (~b)b
dt
dt
dt Ô£ÆÔ£´ Ô£∂
dt Ô£πdt Ô£´
Ô£∂
Ô£´ Ô£∂
2~
~b
d
d
b
d~b
eÃà + œâ
= R
~Àô √ó ~b + œâ √ó Ô£∞Ô£≠ Ô£∏ + œâ
~ √ó ~bÔ£ª + Ô£≠ 2 Ô£∏ + œâ √ó Ô£≠ Ô£∏
dt
dt
dt

~a =

b

Ô£´
eÃà + Ô£≠
= R

2~

Ô£∂

Ô£´

b



d bÔ£∏
d~b
Àô √ó ~b + œâ
~b .
Ô£≠ Ô£∏ +œâ
+
2œâ
√ó
~
~
√ó
œâ
√ó
dt2
dt
b

3

b

Ô£∂

b

Actually œâ
~ is a pseudovector, which behaves like a vector under rotations but changes
sign compared to what a vector does under reflection in a mirror.

4.3. THE MOMENT OF INERTIA TENSOR

97

This is a general relation between any orthonormal coordinate system and
an inertial one, and in general can be used to describe physics in noninertial
coordinates, regardless of whether that coordinate system is imbedded in a
rigid body. The full force on the particle is F~ = m~a, but if we use ~r, ~v 0 , and
~a 0 to represent ~b, (d~b/dt)b and (d2~b/dt2 )b respectively, we have an expression
for the apparent force
eÃà ‚àí 2m~
m~a 0 = F~ ‚àí mR
œâ √ó ~v 0 ‚àí mœâ
~Àô √ó ~r ‚àí m~œâ √ó (~œâ √ó ~r).

The additions to the real force are the pseudoforce for an accelerating refereÃà the Coriolus force ‚àí2m~
ence frame ‚àímR,
œâ √ó~v 0 , an unnamed force involving
the angular acceleration of the coordinate system ‚àímœâ
~Àô √ó~r, and the centrifugal force ‚àím~œâ √ó (~œâ √ó ~r) respectively.

4.3

The moment of inertia tensor

Let us return to a rigid body, where the particles are constrained to keep
the distances between them constant. Then the coordinates b0Œ±i in the body
frame are independant of time, and
eÃá + œâ √ó ~b
~vŒ± = R
Œ±

so the individual momenta and the total momentum are
p~Œ± = mŒ± Ve + mŒ± œâ
~ √ó ~bŒ±
X
mŒ±~bŒ±
P~ = M Ve + œâ
~√ó
Œ±

=

~
M Ve + M œâ
~ √óB

e
~ is the center of mass position relative to the marked point R.
where B

4.3.1

Motion about a fixed point

Angular Momentum
~ = PŒ± ~rŒ± √ó pŒ± . We will
We next evaluate the total angular momentum, L
first consider the special case in which the body is rotating about the origin,
e ‚â° 0, and then we will return to the general case. As p
so R
~Œ± = mŒ± œâ
~ √ó ~bŒ±

98

CHAPTER 4. RIGID BODY MOTION

already involves a cross product, we will find a triple product, and will use
the reduction formula4




~ =
L

X









~√ó B
~ √óC
~ =B
~ A
~¬∑C
~ ‚àíC
~ A
~¬∑B
~ .
A
Thus


mŒ±~bŒ± √ó œâ
~ √ó ~bŒ±



(4.9)

Œ±

= œâ
~

X

mŒ±~bŒ±2 ‚àí

X

Œ±





mŒ±~bŒ± ~bŒ± ¬∑ œâ
~ .

(4.10)

Œ±

~ need not be parallel to the angular velocity œâ
We see that, in general, L
~ , but it
~
is always linear in œâ
~ . Thus it is possible to generalize the equation L = I~œâ of
elementary physics courses, but we need to generalize I from a multiplicative
number to a linear operator which maps vectors into vectors, not necessarily
in the same direction. In component language this linear operation is clearly
P
in the form Li = j Iij œâj , so I is a 3 √ó 3 matrix. Rewriting (4.10), we have
Li = œâi

mŒ±~bŒ±2 ‚àí

X

X

Œ±

=
‚â°





~ .
mŒ± bŒ±i ~bŒ± ¬∑ œâ

Œ±

XX









mŒ± ~bŒ±2 Œ¥ij ‚àí bŒ±i bŒ±j

j

Œ±

X

Iij œâj ,

œâj

j

where
Iij =

X

mŒ± ~bŒ±2 Œ¥ij ‚àí bŒ±i bŒ±j

(4.11)

Œ±

e In matrix form, we now have
is the inertia tensor about the fixed point R.
(4.10) as

~ =I¬∑œâ
L
~,

(4.12)

where I ¬∑ œâ
~ means a vector with components (I ¬∑ œâ
~ )i = j Iij œâj .
If we consider the rigid body in the continuum limit, the sum over particles
becomes an integral over space times the density of matter,
P

Iij =
4

Z





d3 b œÅ(~b) ~b 2 Œ¥ij ‚àí bi bj .

(4.13)

This formula is colloquially known as the bac-cab formula. It is proven in Appendix
A.1.

4.3. THE MOMENT OF INERTIA TENSOR

99

Kinetic energy
For a body rotating about the origin

 

1X
1X
T =
mŒ±~vŒ±2 =
mŒ± œâ
~ √ó ~bŒ± ¬∑ œâ
~ √ó ~bŒ± .
2 Œ±
2 Œ±
From the general 3-dimensional identity5

 

~√óB
~ ¬∑ C
~ √óD
~ =A
~¬∑C
~B
~ ¬∑D
~ ‚àíA
~¬∑D
~B
~ ¬∑ C,
~
A
we have

2
1X
~ ¬∑ ~bŒ±
~ 2~bŒ±2 ‚àí œâ
mŒ± œâ
2 Œ±


X
1X
=
œâi œâj
mŒ± ~bŒ±2 Œ¥ij ‚àí ~bŒ±i~bŒ±j
2 ij
Œ±




T =

=

1X
œâi Iij œâj .
2 ij

(4.14)

or

1
T = œâ
~ ¬∑I¬∑œâ
~.
2
P
~ for a rigid body rotating about the
Noting that j Iij œâj = Li , T = 12 œâ
~ ¬∑L
~ measured from that origin.
origin, with L

4.3.2

More General Motion

e is not fixed in space, there is nothing special about
When the marked point R
it, and we might ask whether it would be better to evaluate the moment of
inertia about some other point. Working in the body-fixed coordinates, we
may consider a given point ~b and evaluate the moment of inertia about that
point, rather than about the origin. This means ~bŒ± is replaced by ~bŒ± ‚àí ~b, so
(~b )

Iij

=
=

X

mŒ±





~bŒ± ‚àí ~b 2 Œ¥ij ‚àí (bŒ±i ‚àí bi ) (bŒ±j ‚àí bj )


Œ±

i
h
(0)
~ + b2 Œ¥ij + Bi bj + bi Bj ‚àí bi bj ,
Iij + M ‚àí2~b ¬∑ B

(4.15)

e
~ is the position of the center of mass with respect to R,
where we recall that B
the origin of the body fixed coordinates6 . Subtracting the moment of inertia
5

See Appendix A for a hint on how to derive this.
I is evaluated about the body-fixed position ~b = 0, or about RÃÉ, so it is given by Eq.
4.11.
6 (0)

100

CHAPTER 4. RIGID BODY MOTION

about the center of mass, given by (4.15) with b ‚Üí B, we have
(~b )

~)
(B

Iij ‚àí Iij

= M
= M

h



~ + b2 + B 2 Œ¥ij + Bi bj + bi Bj ‚àí bi bj ‚àí Bi Bj
‚àí2~b ¬∑ B



i



~b ‚àí B
~ 2 Œ¥ij ‚àí (bi ‚àí Bi ) (bj ‚àí Bj ) .


(4.16)

Note the difference is independent of the origin of the coordinate system,
~
depending only on the vector bÃÜ = ~b ‚àí B.
A possible axis of rotation can be specified by a point ~b through which
it passes, together with a unit vector nÃÇ in the direction of the axis7 . The
~
moment of inertia about the axis (~b, nÃÇ) is defined as nÃÇ¬∑I(b ) ¬∑nÃÇ. If we compare
this to the moment about a parallel axis through the center of mass, we see
that
~

h

nÃÇ ¬∑ I(b ) ¬∑ nÃÇ ‚àí nÃÇ ¬∑ I(cm) ¬∑ nÃÇ = M bÃÜ2 nÃÇ2 ‚àí (bÃÜ ¬∑ nÃÇ)2

i

= M (nÃÇ √ó bÃÜ)2 = M bÃÜ2‚ä• ,

(4.17)

where bÃÜ‚ä• is the projection of the vector, from the center of mass to ~b, onto
the plane perpendicular to the axis. Thus the moment of inertia about any
axis is the moment of inertia about a parallel axis through the center of
mass, plus M `2 , where ` = bÃÜ‚ä• is the distance between these two axes. This
is known as the parallel axis theorem.
The general motion of a rigid body involves both a rotation and a transe Then
lation of a given point R.
~rŒ± = RÃÉ + ~bŒ± ,

~rÀôŒ± = Ve + œâ
~ √ó ~bŒ± ,

(4.18)

where Ve and œâ
~ may be functions of time, but they are the same for all
particles Œ±. Then the angular momentum about the origin is
~ =
L

X
Œ±

mŒ±~rŒ± √ó ~rÀôŒ± =

X
Œ±

mŒ±~rŒ± √ó Ve +

X







e + ~b √ó œâ
mŒ± R
~ √ó ~bŒ±
Œ±



Œ±

e √ó (~
~ √ó Ve + I(0) ¬∑ œâ
~
= MR
~ + MR
œâ √ó B),

(4.19)

e even though that is
where the inertia tensor I(0) is still measured8 about R,
~ is the laboratory position of the center of
not a fixed point. Recall that R
7
Actually, this gives more information than is needed to specify an axis, as ~b and ~b 0
specify the same axis if ~b ‚àí ~b 0 ‚àù nÃÇ. In the expression for the moment of inertia about the
axis, (4.17), we see that the component of ~b parallel to nÃÇ does not affect the result.
8
Recall the (~b) superscript in (4.15) refers to the body-fixed coordinate, so I(0) is about
~b = 0, not about the origin in inertial coordinates.

4.3. THE MOMENT OF INERTIA TENSOR

101

~ is its position in the body-fixed system. The kinetic energy is
mass, while B
now
2
1
mŒ±~rÀôŒ± =
mŒ± Ve + œâ
~ √ó ~bŒ± ¬∑ Ve + œâ
~ √ó ~bŒ±
2
2
Œ±
Œ±
!

2
X
X
1
1X
2
=
mŒ± Ve + Ve ¬∑ œâ
~√ó
mŒ± œâ
~ √ó ~bŒ±
mŒ±~bŒ± +
2 Œ±
2 Œ±
Œ±


1 e2
~ + 1œâ
=
M V + M Ve ¬∑ œâ
~ √óB
~ ¬∑ I(0) ¬∑ œâ
~
(4.20)
2
2

T =

X1



X

 



e
and again the inertia tensor I(0) is calculated about the arbitrary point R.
We will see that it makes more sense to use the center of mass.

Simplification Using the Center of Mass
As each ~rÀôŒ± = Ve + œâ
~ √ó ~bŒ± , the center of mass velocity is given by
M V~ =

X

mŒ±~rÀôŒ± =

Œ±

X









~ ,
mŒ± Ve + œâ
~ √ó ~bŒ± = M Ve + œâ
~ √óB

(4.21)

Œ±

~ + 1 M (œâ √ó B)
~ 2 . Comparing with 4.20,
so 21 M V~ 2 = 12 M Ve 2 + M Ve ¬∑ (~œâ √ó B)
2
we see that
1
1
~ 2 + 1œâ
~ ¬∑ I(0) ¬∑ œâ
~.
T = M V~ 2 ‚àí M (~œâ √ó B)
2
2
2
The last two terms can be written in terms of the inertia tensor about the
~ is the center of mass,
center of mass. From 4.16 with ~b = 0, as B
(cm)

Iij


(0)

= Iij ‚àí M B 2 Œ¥ij + M Bi Bj .
 



~√óB
~ ¬∑ C
~ √óD
~ again,
Using the formula for A


1 ~2 1
~2 ‚àí œâ
~ 2 + 1œâ
T =
MV ‚àí M œâ
~ 2B
~ ¬∑B
~ ¬∑ I(0) ¬∑ œâ
~
2
2
2
1 ~2 1
=
MV + œâ
~ ¬∑ I(cm) ¬∑ œâ
~.
2
2




(4.22)

A similar expression holds for the angular momentum. Inserting Ve = V~ ‚àí
~ into (4.19),
œâ
~ √óB
h

i

e √ó (~
~ = MR
~ √ó V~ ‚àí œâ
~ + I(0) ¬∑ œâ
~
L
~ √óB
~ + MR
œâ √ó B)

102

CHAPTER 4. RIGID BODY MOTION
e √ó (~
~ √ó V~ ‚àí M (R
~ ‚àí R)
~ + I(0) ¬∑ œâ
= MR
œâ √ó B)
~
~ √ó V~ ‚àí M B
~ √ó (~œâ √ó B)
~ + I(0) ¬∑ œâ
= MR
~

~ √ó V~ ‚àí M œâ
~œâ
~ + I(0) ¬∑ œâ
= MR
~ B2 + M B
~ ¬∑B
~
(cm)
~
~
= MR √ó V + I
¬∑œâ
~.

(4.23)

These two decompositions, (4.22) and (4.23), have a reasonable interpretation: the total angular momentum is the angular momentum about the
center of mass, plus the angular momentum that a point particle of mass
~
M and position R(t)
would have. Similiarly, the total kinetic energy is the
rotational kinetic energy of the body rotating about its center of mass, plus
the kinetic energy of the fictious point particle moving with the center of
mass.
e is
Note that if we go back to the situation where the marked point R
e
~ = I¬∑œâ
stationary at the origin of the lab coordinates, V = 0, L
~, T =
1
1
~
œâ
~ ¬∑I¬∑œâ
~ = 2œâ
~ ¬∑ L.
2
The angular momentum in Eqs. 4.19 and 4.23 is the angular momentum
~ = PŒ± mŒ±~rŒ± √ó vŒ± . It is
measured about the origin of the lab coordinates, L
useful to consider the angular momentum as measured about the center of
mass,
~ cm =
L

X









~ √ó ~vŒ± ‚àí V~ = L
~ ‚àí MR
~ √ó V~ ,
mŒ± ~rŒ± ‚àí R

(4.24)

Œ±

so we see that the angular momentum, measured about the center of mass,
is just I(cm) ¬∑ œâ
~.
The parallel axis theorem is also of the form of a decomposition. The
inertia tensor about a given point ~r given by (4.16) is
(r)
Iij

=

(cm)
Iij + M





~ 2 Œ¥ij ‚àí (ri ‚àí Ri ) (rj ‚àí Rj ) .
~r ‚àí R


This is, once again, the sum of the quantity, here the inertia tensor, of the
body about the center of mass, plus the value a particle of mass M at the
~ would have, evaluated about ~r.
center of mass R
There is another theorem about moments of inertia, though much less
general ‚Äî it only applies to a planar object ‚Äî let‚Äôs say in the xy plane, so
that zŒ± ‚âà 0 for all the particles constituting the body. As
Izz =

X
Œ±



mŒ± x2Œ± + yŒ±2



4.3. THE MOMENT OF INERTIA TENSOR
Ixx =

X

Iyy =

X

103





X



x2Œ± + zŒ±2



X

mŒ± yŒ±2 + zŒ±2 =

Œ±

mŒ± yŒ±2

Œ±

mŒ±

Œ±

=

mŒ± x2Œ± ,

Œ±

we see that Izz = Ixx +Iyy , the moment of inertia about an axis perpendicular
to the body is the sum of the moments about two perpendicular axes within
the body, through the same point. This is known as the perpendicular
axis theorem. As an example of its usefulness we calculate the moments
for a thin uniform ring lying on the circle x2 + y 2 = R2 ,
y
z = 0, about the origin. As every particle of the ring has
the same distance R from the z-axis, the moment of inertia
x
2
Izz is simply M R . As Ixx = Iyy by symmetry, and as
the two must add up to Izz , we have, by a simple indirect
calculation, Ixx = 21 M R2 .
The parallel axis theorem (4.17) is also a useful calculational tool. Consider the moment of inertia of the ring about an axis parallel to its axis of
symmetry but through a point on the ring. About the axis of
y
symmetry, Izz = M R2 , and b‚ä• = R, so about a point on the
ring, Izz = 2M R2 . If instead, we want the moment about a
(cm)
tangent to the ring in the x direction, Ixx = Ixx
+ M R2 =
1
M R2 + M R2 = 3M R2 /2. Of course for Iyy the b‚ä• = 0, so
x
2
Iyy = 21 M R2 , and we may verify that Izz = Ixx + Iyy about
this point as well.
For an object which has some thickness, with non-zero z components, the
perpendicular axis theorem becomes an inequality, Izz ‚â§ Ixx + Iyy .
Principal axes
If an object has an axial symmetry about z, we may use cylindrical polar
coordinates (œÅ, Œ∏, z). Then its density ¬µ(œÅ, Œ∏, z) must be independent of Œ∏,
and
Iij =
so

Ixz =
Ixy =

Z
Z
Z

h

i

dz œÅ dœÅ dŒ∏ ¬µ(œÅ, z) (œÅ2 + z 2 )Œ¥ij ‚àí ri rj ,
dz œÅ dœÅ dŒ∏ ¬µ(œÅ, z)(‚àízœÅ cos Œ∏) = 0
dz œÅ dœÅ dŒ∏ ¬µ(œÅ, z)(œÅ2 sin Œ∏ cos Œ∏) = 0

104

CHAPTER 4. RIGID BODY MOTION
Ixx =
Iyy =

Z

dz œÅ dœÅ dŒ∏ ¬µ(œÅ, z) (œÅ2 + z 2 ‚àí œÅ2 cos2 Œ∏

Z

dz œÅ dœÅ dŒ∏ ¬µ(œÅ, z) (œÅ2 + z 2 ‚àí œÅ2 sin2 Œ∏

h

i

h

i

= Ixx

Thus the inertia tensor is diagonal and has two equal elements,
Ô£´

Ixx
Ô£¨
I=Ô£≠ 0
0

0
Ixx
0

Ô£∂

0
Ô£∑
0 Ô£∏.
Izz

In general, an object need not have an axis of symmetry, and even a
diagonal inertia tensor need not have two equal ‚Äúeigenvalues‚Äù. Even if a
body has no symmetry, however, there is always a choice of axes, a coordinate
system, such that in this system the inertia tensor is diagonal. This is because
Iij is always a real symmetric tensor, and any such tensor can be brought to
diagonal form by an orthogonal similiarity transformation9
Ô£´

I = OID O‚àí1 ,

I1
Ô£¨
ID = Ô£≠ 0
0

0
I2
0

Ô£∂

0
Ô£∑
0Ô£∏
I3

(4.25)

An orthogonal matrix O is either a rotation or a rotation times P , and the
P ‚Äôs can be commuted through ID without changing its form, so there is a
rotation R which brings the inertia tensor into diagonal form. The axes of
this new coordinate system are known as the principal axes.
Tire balancing
Consider a rigid body rotating on an axle, and therefore about a fixed axis.
~Àô = œâ
~ so
What total force and torque will the axle exert? First, R
~ √ó R,
~¬® = œâ
~ +œâ
~Àô = œâ
~ +œâ
~ =œâ
~ +œâ
~ + Rœâ
~ 2.
R
~Àô √ó R
~ √óR
~Àô √ó R
~ √ó (œâ √ó R)
~Àô √ó R
~ (~œâ ¬∑ R)
If the axis is fixed, œâ
~ and œâ
~Àô are in the same direction, so the first term in the
last expression is perpendicular to the other two. If we want the total force
~¬® = 0, so
to be zero10 , R
~ ¬∑R
~¬® = 0 = 0 + (~œâ ¬∑ R)
~ 2 ‚àí R2 œâ 2 .
R
9

This should be proven in any linear algebra course. For example, see [1], Theorem 6
in Section 6.3.
10
Here we are ignoring any constant force compensating the force exerted by the road
which is holding the car up!

4.3. THE MOMENT OF INERTIA TENSOR

105

~ is 0 or œÄ, and the center of mass must lie
Thus the angle between œâ
~ and R
on the axis of rotation. This is the condition of static balance if the axis of
rotation is horizontal in a gravitational field. Consider a car tire: to be stable
~ must lie on the axis or there will be a gravitational
at rest at any angle, R
torque about the axis, causing rotation in the absense of friction. If the tire
is not statically balanced, this force will rotate rapidly with the tire, leading
to vibrations of the car.
~Àô = d(I ¬∑ œâ
Even if the net force is 0, there might be a torque. ~œÑ = L
~ )/dt.
Àô
~ will rapidly
If I ¬∑ œâ
~ is not parallel to œâ
~ it will rotate with the wheel, and so L
oscillate. This is also not good for your axle. If, however, œâ
~ is parallel to
~
one of the principal axes, I ¬∑ œâ
~ is parallel to œâ
~ , so if œâ
~ is constant, so is L,
and ~œÑ = 0. The process of placing small weights around the tire to cause
one of the principal axes to be aligned with the axle is called dynamical
balancing.
Every rigid body has its principal axes; the problem of finding them
and the moments of inertia about them, given the inertia tensor I in some
coordiate system, is a mathematical question of finding a rotation R and
‚Äúeigenvalues‚Äù I1 , I2 , I3 (not components of a vector)
Ô£´ Ô£∂such that equation 4.25
1
Ô£¨ Ô£∑
holds, with R in place of O. The vector ~v1 = R Ô£≠ 0 Ô£∏ is then an eigenvector,
0
for
Ô£´ Ô£∂

Ô£´ Ô£∂

Ô£´ Ô£∂

1
1
1
Ô£∑
Ô£¨ Ô£∑
Ô£¨ Ô£∑
I ¬∑ ~v1 = RID R‚àí1 R Ô£¨
v1 .
Ô£≠ 0 Ô£∏ = RID Ô£≠ 0 Ô£∏ = I1 R Ô£≠ 0 Ô£∏ = I1~
0
0
0
Similarly I ¬∑ ~v2 = I2~v2 and I ¬∑ ~v3 = I3~v3 , where ~v2 and ~v3 are defined the same
way, starting with eÃÇ2 and eÃÇ3 instead of eÃÇ1 . Note that, in general, I acts simply
as a multiplier only for multiples of these three vectors individually, and not
for sums of them. On a more general vector I will change the direction as
well as the length of the vector it acts on.
Note that the Ii are all ‚â• 0, for given any vector ~n,
~n ¬∑ I ¬∑ ~n =

X
Œ±

mŒ± [rŒ±2 n2 ‚àí (~rŒ± ¬∑ ~n)2 ] =

X

mŒ± rŒ±2 n2 (1 ‚àí cos2 Œ∏Œ± ) ‚â• 0,

Œ±

so all the eigenvalues must be ‚â• 0. It will be equal to zero only if all massive
points of the body are in the ¬±~n directions, in which case the rigid body
must be a thin line.

106

CHAPTER 4. RIGID BODY MOTION

Finding the eigenvalues Ii is easier than finding the rotation R. Consider
the matrix I ‚àí Œª1I, which has the same eigenvectors as I, but with eigenvalues
Ii ‚àí Œª. Then if Œª is one of the eigenvalues Ii , this matrix will annihilate ~vi ,
so I ‚àí Œª1I is a singular matrix with zero determinant. Thus the characteristic
equation det(I ‚àí Œª1I) = 0, which is a cubic equation in Œª, gives as its roots
the eigenvalues of I.

4.4

Dynamics

4.4.1

Euler‚Äôs Equations

So far, we have been working in an inertial coordinate system O. In complicated situations this is rather unnatural; it is more natural to use a coordiate
system O0 fixed in the rigid body. In such a coordinate system, the vector
P
one gets by differentiating the coefficients of a vector ~b = b0i eÃÇ0i differs from
Àô
the inertial derivative ~b as given in Eq. 4.7. Consider two important special
e with ~
~ and
cases: either we have a system rotating about a fixed point R,
œÑ , L,
0
Iij all evaluated about that fixed point, or we are working about the center
~ and Iij0 all evaluated about the center of mass, even if it
of mass, with ~œÑ , L,
~ = I0 ¬∑ œâ
is in motion. In either case, we have L
~ , so for the time derivative of
the angular momentum, we have
Ô£´

Ô£∂

~
~
dL
dL
~
= Ô£≠ Ô£∏ +œâ
~ √óL
~œÑ =
dt
dt
b

=

0 0
X d(Iij
œâj )
ij

dt

eÃÇ0i + œâ
~ √ó (I 0 ¬∑ œâ
~ ),

Now in the O0 frame, all the masses are at fixed positions, so Iij0 is constant,
and the first term is simply I ¬∑ (dœâ/dt)b , which by (4.8) is simply I ¬∑ œâ
~Àô . Thus
we have (in the body coordinate system)
~œÑ = I0 ¬∑ œâ
~Àô + œâ
~ √ó (I0 ¬∑ œâ).

(4.26)

We showed that there is always a choice of cartesian coordinates mounted
on the body along the principal axes. For the rest of this section we will use
this body-fixed coordinate system, so we will drop the primes.

4.4. DYNAMICS

107

The torque not only determines the rate of change of the angular momentum, but also does work in the system. For a system rotating about a fixed
point, we see from the expression (4.14), T = 12 œâ
~ ¬∑I¬∑œâ
~ , that
1Àô
1
1
dT
= œâ
~ ¬∑I¬∑œâ
~+ œâ
~ ¬∑ IÃá ¬∑ œâ
~+ œâ
~ ¬∑I¬∑œâ
~Àô .
dt
2
2
2
The first and last terms are equal because the inertia tensor is symmetric,
Iij = Iji , and the middle term vanishes in the body-fixed coordinate system
~Àô = œâ
because all particle positions are fixed. Thus dT /dt = œâ
~ ¬∑I¬∑œâ
~Àô = œâ
~ ¬∑L
~ ¬∑ ~œÑ .
Thus the kinetic energy changes due to the work done by the external torque.
Therefore, of course, if there is no torque the kinetic energy is constant.
We will write out explicitly the components of Eq. 4.26. In evaluating œÑ1 ,
we need the first component of the second term,
[(œâ1 , œâ2 , œâ3 ) √ó (I1 œâ1 , I2 œâ2 , I3 œâ3 )]1 = (I3 ‚àí I2 )œâ2 œâ3 .
Inserting this and the similar expressions for the other components into
Eq. (4.26), we get Euler‚Äôs equations
œÑ1 = I1 œâÃá1 + (I3 ‚àí I2 )œâ2 œâ3 ,
œÑ2 = I2 œâÃá2 + (I1 ‚àí I3 )œâ1 œâ3 ,
œÑ3 = I3 œâÃá3 + (I2 ‚àí I1 )œâ1 œâ2 .

(4.27)

Using these equations we can address several situations of increasing difficulty.
First, let us ask under what circumstances the angular velocity will be
fixed in the absense of a torque. As ~œÑ = œâ
~Àô = 0, from the 1-component
equation we conclude that (I2 ‚àí I3 )œâ2 œâ3 = 0. Then either the moments
are equal (I2 = I3 ) or one of the two components œâ2 or œâ3 must vanish.
Similarly, if I1 6= I2 , either œâ1 or œâ2 vanishes. So the only way more than one
component of œâ
~ can be nonzero is if two or more of the principal moments
are equal. In this case, the principal axes are not uniquely determined. For
example, if I1 = I2 6= I3 , the third axes is unambiguously required as one
of the principle axes, but any direction in the (12)-plane will serve as the
second principal axis. In this case we see that ~œÑ = œâ
~Àô = 0 implies either œâ
~ is
along the z-axis (œâ1 = œâ2 = 0) or it lies in the (12)-plane, (œâ3 = 0). In any
case, the angular velocity is constant in the absence of torques only if it lies
along a principal axis of the body.

108

CHAPTER 4. RIGID BODY MOTION

As our next example, consider an axially symmetric body with no external
~Àô is a constant, and we will choose to
forces or torques acting on it. Then R
~ is fixed at the origin. Choosing our bodywork in an inertial frame where R
fixed coordinates with z along the axis of symmetry, our axes are principal
ones and I1 = I2 , so we have
I1 œâÃá1 = (I1 ‚àí I3 )œâ2 œâ3 ,
I1 œâÃá2 = (I3 ‚àí I1 )œâ1 œâ3 ,
I3 œâÃá3 = (I1 ‚àí I2 )œâ1 œâ2 = 0.
We see that œâ3 is a constant. Let ‚Ñ¶ = œâ3 (I3 ‚àí I1 )/I1 . Then we see that
œâÃá1 = ‚àí‚Ñ¶œâ2 ,

œâÃá2 = ‚Ñ¶œâ1 .

Differentiating the first and plugging in the second, we find
œâÃà1 = ‚àí‚Ñ¶œâÃá2 = ‚àí‚Ñ¶2 œâ1 ,
which is just the harmonic oscillator equation. So œâ1 = A cos(‚Ñ¶t + œÜ) with
some arbitrary amplitude A and constant phase œÜ, and œâ2 = ‚àíœâÃá1 /‚Ñ¶ =
A sin(‚Ñ¶t + œÜ). We see that, in the body-fixed frame, the angular velocity
rotates about the axis of symmetry in a circle, with arbitrary radius A, and
a period 2œÄ/‚Ñ¶. The angular velocity vector œâ
~ is therefore sweeping out a
cone, called the body cone of precession with a half-angle œÜb = tan‚àí1 A/œâ3 .
Note the length of œâ
~ is fixed.
~ is constant,
~ ¬∑L
What is happening in the lab frame? The kinetic energy 21 œâ
~ itself. As the length of a vector is frame independent, |~œâ |
as is the vector L
is fixed as well. Therefore the angle between them, called the lab angle, is
constant,
~
œâ
~ ¬∑L
2T
cos œÜL =
=
= constant.
(4.28)
~
~
|~œâ ||L|
|~œâ ||L|
~ in a cone, called the laboratory cone.
Thus œâ
~ rotates about L
Note that œÜb is the angle between œâ
~ and the z-axis of the body, while œÜL
~
is the angle between œâ
~ and L, so they are not the same angle in two different
coordinate systems.
The situation is a bit hard to picture. In the body frame it is hard
to visualize œâ
~ , although that is the negative of the angular velocity of the
universe in that system. In the lab frame the body is instantanously rotating

4.4. DYNAMICS

109

about the axis œâ
~ , but this axis is not fixed in the body. At any instant,
the points on this line are not moving, and we may think of the body rolling
without slipping on the lab cone, with œâ
~ the momentary line of contact. Thus
the body cone rolls on the lab cone without slipping.
The Poinsot construction
This idea has an extension to the more general case where the body has no
symmetry. The motion in this case can be quite complex, both for analytic
solution, because Euler‚Äôs equations are nonlinear, and to visualize, because
the body is rotating and bobbing around in a complicated fashion. But as
we are assuming there are no external forces or torques, the kinetic energy
and total angular momentum vectors are constant, and this will help us
understand the motion. To do so we construct an abstract object called the
inertia ellipsoid. Working in the body frame, consider that the equation
2T =

X

œâi Iij œâj = f (~œâ )

ij

is a quadratic equation for œâ
~ , with constant coefficients, which therefore
determines an ellipsoid11 in the space of possible values of œâ
~ . This is called
12
the inertia ellipsoid . It is fixed in the body, and so if we were to scale it
by some constant to change units from angular velocity to position, we could
think of it as a fixed ellipsoid in the body itself, centered at the center of
mass. At every moment the instantanous value of œâ
~ must lie on this ellipsoid,
so œâ
~ (t) sweeps out a path on this ellipsoid called the polhode.
If we go to the lab frame, we see this ellipsoid fixed in and moving with
the body. The instantaneous value of œâ
~ still lies on it. In addition, the
~ direction is fixed, and as the center of mass
component of œâ
~ in the (fixed) L
~ a fixed
is fixed, the point corresponding to œâ
~ lies in a plane perpendicular to L
distance from the center of mass, known as the invariant plane. Finally we
note that the normal to the surface of the ellipsoid f (~œâ ) = 2T is parallel to
~ so the ellipsoid of inertia is tangent to the invariant plane
‚àáf = 2I ¬∑ œâ
~ = 2L,
11

We assume the body is not a thin line, so that I is a positive definite matrix (all its
eigenvalues are strictly > 0), so the surface defined by this equation is bounded.
12
Exactly which ‚àö
quantity forms the inertia ellipsoid varies by author. Goldstein scales
œâ
~ by a constant 1/ 2T to form an object œÅ whose ellipsoid he calls the inertia ellipsoid.
~ values but don‚Äôt give it a name. They then
Landau and Lifshitz discuss an ellipsoid of L
call the corresponding path swept out by œâ
~ the polhode, as we do.

110

CHAPTER 4. RIGID BODY MOTION

at the point œâ
~ (t). The path that œâ
~ (t) sweeps out on the invariant plane is
called the herpolhode. At this particular moment, the point corresponding
to œâ
~ in the body is not moving, so the inertia ellipsoid is rolling, not slipping,
on the invariant plane.
In general, if there is no special symmetry, the inertia ellipsoid will not
be axially symmetric, so that in order to roll on the fixed plane and keep its
center at a fixed point, it will need to bob up and down. But in the special
case with axial symmetry, the inertia ellipsoid will also have this symmetry,
so it can roll about a circle, with its symmetry axis at a fixed angle relative
to the invariant plane. In the body frame, œâ3 is fixed and the polhode moves
~ so
on a circle of radius A = œâ sin œÜb . In the lab frame, œâ
~ rotates about L,
it sweeps out a circle of radius œâ sin œÜL in the invariant plane. One circle is
rolling on the other, and the polhode rotates about its circle at the rate ‚Ñ¶ in
the body frame, so the angular rate at which the herpolhode rotates about
~ ‚Ñ¶L , is
L,
‚Ñ¶L = ‚Ñ¶

I3 ‚àí I1 sin œÜb
circumference of polhode circle
=
œâ3
.
circumference of herpolhode circle
I1
sin œÜL

Stability of rotation about an axis
We have seen that the motion of a isolated rigid body is simple only if the
angular velocity is along one of the principal axes, and can be very complex
otherwise. However, it is worth considering what happens if œâ
~ is very nearly,
but not exactly, along one of the principal axes, say z. Then we may write
œâ
~ = œâ3 eÃÇ3 + ~ in the body coordinates, and assume 3 = 0 and the other
components are small. We treat Euler‚Äôs equations to first order in the small
quantity ~. To this order, œâÃá3 = (I1 ‚àí I2 )1 2 /I3 ‚âà 0, so œâ3 may be considered
a constant. The other two equations give
I2 ‚àí I3
2 œâ3
I1
I3 ‚àí I1
=
1 œâ3
I2

œâÃá1 = Àô1 =
œâÃá2 = Àô2
so
¬®1 =

I2 ‚àí I3 I3 ‚àí I1 2
œâ3 1 .
I1
I2

What happens to ~(t) depends on the sign of the coefficient, or the sign
of (I2 ‚àí I3 )(I3 ‚àí I1 ). If it is negative, 1 oscillates, and indeed ~ rotates

4.4. DYNAMICS

111

about z just as we found for the symmetric top. This will be the case if
I3 is either the largest or the smallest eigenvalue. If, however, it is the
middle eigenvalue, the constant will be positive, and the equation is solved by
exponentials, one damping out and one growing. Unless the initial conditions
are perfectly fixed, the growing piece will have a nonzero coefficient and ~ will
blow up. Thus a rotation about the intermediate principal axis is unstable,
while motion about the axes with the largest and smallest moments are
stable. For the case where two of the moments are equal, the motion will be
stable about the third, and slightly unstable (~ will grow linearly instead of
exponentially with time) about the others.
An interesting way of understanding this stability or instability of rotation
close to a principle axes involves another ellipsoid we can define for the free
rigid body, an ellipsoid of possible angular momentum values. Of course
~ is constant, but in body fixed language the
in the inertial coordinates L
~ is still constant. In
coordinates vary with time, though the length of L
addition, the conservation of kinetic energy
~ ¬∑ I‚àí1 ¬∑ L
~
2T = L
(where I‚àí1 is the inverse of the moment of inertia matrix) gives a quadratic
~ just as we had for œâ
equation for the three components of L,
~ and the ellipsoid
~
of inertia. The path of L(t) on this ellipsoid is on the intersection of the
~ for the length is fixed.
ellisoid with a sphere of radius |L|,
~ lies
If œâ
~ is near the principle axis with the largest moment of inertia, L
near the major axis of the ellipsoid. The sphere is nearly circumscribing the
ellipsoid, so the intersection consists only of two small loops surrounding each
end of the major axis. Similiarly if œâ
~ is near the smallest moment, the sphere
~ lie close
is nearly inscribed in the ellipsoid, and again the possible values of L
to either end of the minor axis. Thus the subsequent motion is confined to
one of these small loops. But if œâ
~ starts near the intermediate principle axis,
~ does likewise, and the intersection consists of two loops which extend from
L
near one end to near the other of the intermediate axis, and the possible
~ is not confined to a small region of the ellipsoid.
continuous motion of L
Because the rotation of the Earth flattens the poles, the Earth is approximately an oblate ellipsoid, with I3 greater than I1 = I2 by about one part
in 300. As œâ3 is 2œÄ per siderial day, if œâ
~ is not perfectly aligned with the
axis, it will precess about the symmetry axis once every 10 months. This
Chandler wobble is not of much significance, however, because the body
angle œÜb ‚âà 10‚àí6 .

112

4.4.2

CHAPTER 4. RIGID BODY MOTION

Euler angles

Up to this point we have managed to describe the motion of a rigid body
without specifying its coordinates. This is not possible for most problems
with external forces, for which the torque will generally depend on the orientation of the body. It is time to face up to the problem of using three
generalized coordinates to describe the orientation.
In section 4.1.1 we described the orientation of a rigid body in terms of a
rotation through a finite angle in a given direction, specified by œâ. This does
not give a simple parameterization of the matrix A, and it is more common
to use an alternate description known as Euler angles. Here we describe
the rotation A as a composition of three simpler rotations about specified
coordinates, so that we are making a sequence of changes of coordinates
Ry1 (Œ∏)
Rz (œÜ)
Rz2 (œà) 0 0 0
(x, y, z) ‚àí‚Üí (x1 , y1 , z1 ) ‚àí‚Üí
(x2 , y2 , z2 ) ‚àí‚Üí
(x , y , z ).
We have chosen three specific directions about which to make the three rotations, namely the original z-axis, the next y-axis, y1 , and then the new
z-axis, which is both z2 and z 0 . This choice is not universal, but is the one
generally used in quantum mechanics. Many of the standard classical mechanics texts13 take the second rotation to be about the x1 -axis instead of
y1 , but quantum mechanics texts14 avoid this because the action of Ry on a
spinor is real, while the action of Rx is not. While this does not concern us
here, we prefer to be compatible with quantum mechanics discussions.
This procedure is pictured in Figure 4.2. To see that any rotation can
be written in this form, and to determine the range of the angles, we first
discuss what fixes the y1 axis. Notice that the rotation about the z-axis
leaves z uneffected, so z1 = z, Similiarly, the last rotation leaves the z2
axis unchanged, so it is also the z 0 axis. The planes orthogonal to these
axes are also left invariant15 . These planes, the xy-plane and the x0 y 0 -plane
respectively, intersect in a line called the line of nodes16 . These planes
are also the x1 y1 and x2 y2 planes respectively, and as the second rotation
13

See [2], [6], [9], [10], [11] and [17].
For example [13] and [20].
15
although the points in the planes are rotated by 4.4.
16
The case where the xy and x0 y 0 are identical, rather than intersecting in a line, is
exceptional, corresponding to Œ∏ = 0 or Œ∏ = œÄ. Then the two rotations about the z-axis
add or subtract, and many choices for the Euler angles (œÜ, œà) will give the same full
rotation.
14

4.4. DYNAMICS

113

z
z‚Äô
Œ∏

y‚Äô

x

œà
y

œÜ

y1
line of nodes

x‚Äô
Figure 4.2: The Euler angles as rotations through œÜ, Œ∏, œà, about the z, y1 ,
and z2 axes sequentially
Ry1 (Œ∏) must map the first into the second plane, we see that y1 , which is
unaffected by Ry1 , must be along the line of nodes. We choose between the
two possible orientations of y1 to keep the necessary Œ∏ angle in [0, œÄ]. The
angles œÜ and œà are then chosen ‚àà [0, 2œÄ) as necessary to map y ‚Üí y1 and
y1 ‚Üí y 0 respectively.
While the rotation about the z-axis leaves z uneffected, it rotates the x
and y components by the matrix (4.4). Thus in three dimensions, a rotation
about the z axis is represented by
Ô£´

Ô£∂

cos œÜ sin œÜ 0
Ô£∑
Rz (œÜ) = Ô£¨
Ô£≠ ‚àí sin œÜ cos œÜ 0 Ô£∏ .
0
0
1

(4.29)

Similarly a rotation through an angle Œ∏ about the current y axis has a similar

114

CHAPTER 4. RIGID BODY MOTION

form

Ô£´

Ô£∂

cos Œ∏ 0 ‚àí sin Œ∏
Ô£¨
Ô£∑
1
0 Ô£∏.
(4.30)
Ry (Œ∏) = Ô£≠ 0
sin Œ∏ 0 cos Œ∏
The reader needs to assure himself, by thinking of the rotations as active
transformations, that the action of the matrix Ry after having applied Rz
produces a rotation about the y1 -axis, not the original y-axis.
The full rotation A = Rz (œà) ¬∑ Ry (Œ∏) ¬∑ Rz (œÜ) can then be found simply by
matrix multiplication:
A(œÜ, Œ∏, œà) =
Ô£´
cos œà sin œà
Ô£¨
Ô£≠ ‚àí sin œà cos œà
0
0
=

Ô£∂Ô£´

0
cos Œ∏
Ô£∑Ô£¨
0Ô£∏Ô£≠ 0
1
sin Œ∏

Ô£´

Ô£∂Ô£´

Ô£∂

0 ‚àí sin Œ∏
cos œÜ sin œÜ 0
Ô£∑Ô£¨
Ô£∑
1
0 Ô£∏ Ô£≠ ‚àí sin œÜ cos œÜ 0 Ô£∏
0 cos Œ∏
0
0
1
(4.31)

‚àí sin œÜ sin œà + cos Œ∏ cos œÜ cos œà
Ô£≠ ‚àí sin œÜ cos œà ‚àí cos Œ∏ cos œÜ sin œà
sin Œ∏ cos œÜ

cos œÜ sin œà + cos Œ∏ sin œÜ cos œà
cos œÜ cos œà ‚àí cos Œ∏ sin œÜ sin œà
sin Œ∏ sin œÜ

Ô£∂

‚àí sin Œ∏ cos œà
sin Œ∏ sin œà Ô£∏ .
cos Œ∏

We need to reexpress the kinetic energy in terms of the Euler angles and
their time derivatives. From the discussion of section 4.2, we have
d ‚àí1
A (t)
dt
The inverse matrix is simply the transpose, so finding ‚Ñ¶0 can be done by
straightforward differentiation and matrix multiplication17 . The result is
‚Ñ¶0 = ‚àíA(t) ¬∑

‚Ñ¶0 =

(4.32)

0
Ô£≠
‚àíœàÃá ‚àí œÜÃá cos Œ∏
Œ∏Ãá cos œà + œÜÃá sin Œ∏ sin œà
Ô£´

œàÃá + œÜÃá cos Œ∏
0
‚àíŒ∏Ãá sin œà + œÜÃá sin Œ∏ cos œà

‚àíŒ∏Ãá cos œà ‚àí œÜÃá sin Œ∏ sin œà
Œ∏Ãá sin œà ‚àí œÜÃá sin Œ∏ cos œà Ô£∏ .
0
Ô£∂

Note ‚Ñ¶0 is antisymmetric as expected, so it can be recast into the axial vector
œâ
œâ10 = ‚Ñ¶023 = Œ∏Ãá sin œà ‚àí œÜÃá sin Œ∏ cos œà,
œâ20 = ‚Ñ¶031 = Œ∏Ãá cos œà + œÜÃá sin Œ∏ sin œà,
œâ30 = ‚Ñ¶012 = œàÃá + œÜÃá cos Œ∏.

(4.33)

Verifying the above expression for A and the following one for ‚Ñ¶0 is a good application for a student having access to a good symbolic algebra computer program. Both
Mathematica and Maple handle the problem nicely.
17

4.4. DYNAMICS

115

This expression for œâ
~ gives the necessary velocities for the kinetic energy
term (4.20 or 4.22) in the Lagrangian, which becomes


1
e Œ∏, œà, œÜ),
~ + 1œâ
~ √óB
~ ¬∑ I (RÃÉ) ¬∑ œâ
~ ‚àí U (R,
L = M Ve 2 + M Ve ¬∑ œâ
2
2

(4.34)

1
1
~ Œ∏, œà, œÜ),
L = M V~ 2 + œâ
~ ¬∑ I (cm) ¬∑ œâ
~ ‚àí U (R,
2
2

(4.35)

or

0 0
i œâi eÃÇi given by (4.33).

with œâ
~ =

P

4.4.3

The symmetric top

Now let us consider an example with external forces which constrain one
point of a symmetrical top to be stationary. Then we choose this to be the
fixed point, at the origin RÃÉ = 0, and we choose the body-fixed z 0 -axis to be
along the axis of symmetry. Of course the center of mass in on this axis,
~ = (0, 0, `) in body-fixed coordinates. We will set up the motion by
so R
writing the Lagrangian from the forms for the kinetic and potential energy,
due entirely to the gravitational field18 .
1 2
1
(œâ1 + œâ22 )I1 + œâ32 I3
2
2

2
1
1 2 2
œÜÃá sin Œ∏ + Œ∏Ãá2 I1 +
œÜÃá cos Œ∏ + œàÃá I3 ,
=
2

 2
‚àí1
= M g` cos Œ∏.
U = M gzcm = M g` A
T =

zz

(4.36)
(4.37)

So L = T ‚àí U is independent of œÜ, œà, and the corresponding momenta




pœÜ = œÜÃá sin2 Œ∏I1 + œÜÃá cos Œ∏ + œàÃá cos Œ∏I3
pœà

= œÜÃá
sin2 Œ∏I1 + cos
Œ∏œâ3 I3 ,


= œÜÃá cos Œ∏ + œàÃá I3 = œâ3 I3

are constants of the motion. Let us use parameters a = pœà /I1 and b = pœÜ /I1 ,
which are more convenient, to parameterize the motion, instead of pœÜ , pœà , or
18

As we did in discussing Euler‚Äôs equations, we drop the primes on œâi and on Iij even
though we are evaluating these components in the body fixed coordinate system. The
coordinate z, however, is still a lab coordinate, with eÃÇz pointing upward.

116

CHAPTER 4. RIGID BODY MOTION

even œâ3 , which is also a constant of the motion and might seem physically a
more natural choice. A third constant of the motion is the energy,

1 
1
E = T + U = I1 Œ∏Ãá2 + œÜÃá2 sin2 Œ∏ + œâ32 I3 + M g` cos Œ∏.
2
2
Solving for œÜÃá from pœÜ = I1 b = œÜÃá sin2 Œ∏I1 + I1 a cos Œ∏,
œÜÃá =

b ‚àí a cos Œ∏
,
sin2 Œ∏

œàÃá = œâ3 ‚àí œÜÃá cos Œ∏ =

(4.38)
I1 a b ‚àí a cos Œ∏
‚àí
cos Œ∏,
I3
sin2 Œ∏

(4.39)

Then E becomes
1
1
E = I1 Œ∏Ãá2 + U 0 (Œ∏) + I3 œâ32 ,
2
2
where
1 (b ‚àí a cos Œ∏)2
+ M g` cos Œ∏.
U 0 (Œ∏) := I1
2
sin2 Œ∏
The term 21 I3 œâ32 is an ignorable constant, so we consider E 0 := E ‚àí 21 I3 œâ32
as the third constant of the motion, and we now have a one dimensional
problem for Œ∏(t), with a first integral of the motion. Once we solve for Œ∏(t),
we can plug back in to find œÜÃá and œàÃá.
Substitute u = cos Œ∏, uÃá = ‚àí sin Œ∏Œ∏Ãá, so
E0 =

I1 uÃá2
1 (b ‚àí au)2
+
I1
+ M g`u,
2(1 ‚àí u2 ) 2
1 ‚àí u2

or
uÃá2 = (1 ‚àí u2 )(Œ± ‚àí Œ≤u) ‚àí (b ‚àí au)2 =: f (u),
with Œ± = 2E 0 /I1 , Œ≤ = 2M g`/I1 .
f (u) is a cubic with a positive u3
term, and is negative at u = ¬±1,
where the first term vanishes, and
which are also the limits of the
physical range of values of u. If
there are to be any allowed values for uÃá2 , f (u) must be nonnegative somewhere in u ‚àà [‚àí1, 1], so
f must look very much like what is
shown.

(4.40)

.2
u

cos Œ∏

-1
cos Œ∏

min
1

max

u

4.4. DYNAMICS

117

To visualize what is happening, note that a point on the symmetry axis moves
on a sphere, with Œ∏ and œÜ representing the usual spherical coordinates, as
can be seen by examining what A‚àí1 does to (0, 0, z 0 ). So as Œ∏ moves back
and forth between Œ∏min and Œ∏max , the top is wobbling closer and further
from the vertical, called nutation. At the same time, the symmetry axis

Œ∏0 = 52‚ó¶

Œ∏0 = 44‚ó¶

Œ∏0 = Œ∏min

Figure 4.3: Possible loci for a point on the symmetry axis of the top. The
axis nutates between Œ∏min = 50‚ó¶ and Œ∏max = 60‚ó¶
is precessing, rotating about the vertical axis, at a rate œÜÃá which is not
constant but a function of Œ∏ (Eq. 4.38). Qualitatively we may distinguish
three kinds of motion, depending on the values of œÜÃá at the turning points in
Œ∏. These in turn depend on the initial conditions and the parameters of the
top, expressed in a, b, and Œ∏min , Œ∏max . If the value of u0 = cos Œ∏0 at which
œÜÃá vanishes is within the range of nutation, then the precession will be in
different directions at Œ∏min and Œ∏max , and the motion is as in Fig. 4.3a. On
the other hand, if Œ∏0 = cos‚àí1 (b/a) 6‚àà [Œ∏min , Œ∏max ], the precession will always
be in the same direction, although it will speed up and slow down. We then
get a motion as in Fig. 4.3b. Finally, it is possible that cos Œ∏min = b/a, so
that the precession stops at the top, as in Fig. 4.3c. This special case is of
interest, because if the top‚Äôs axis is held still at an angle to the vertical, and
then released, this is the motion we will get.

Exercises
4.1 Prove the following properties of matrix algebra:
(a) Matrix multiplication is associative: A ¬∑ (B ¬∑ C) = (A ¬∑ B) ¬∑ C.

118

CHAPTER 4. RIGID BODY MOTION

(b) (A ¬∑ B)T = B T ¬∑ AT , where AT is the transpose of A, that is (AT )ij := Aji .
(c) If A‚àí1 and B ‚àí1 exist, (A ¬∑ B)‚àí1 = B ‚àí1 ¬∑ A‚àí1 .
(d) The complex conjugate of a matrix (A‚àó )ij = A‚àóij is the matrix with every
element complex conjugated. The hermitean conjugate A‚Ä† is the transpose of
that, A‚Ä† := (A‚àó )T = (AT )‚àó , with (A‚Ä† )ij := A‚àóji . Show that (A ¬∑ B)‚àó = A‚àó ¬∑ B ‚àó and
(A ¬∑ B)‚Ä† = B ‚Ä† ¬∑ A‚Ä† .
~ = P Vi eÃÇi in terms of
4.2 In section (4.1) we considered reexpressing a vector V
P i
new orthogonal basis vectors. If the new vectors are ~e 0i = j Aij eÃÇj , we can also
P
write eÃÇi = j Aji~e 0j , because AT = A‚àí1 for an orthogonal transformation.
Consider now using a new basis ~e 0i which are not orthonormal. Then we must
P
choose which of the two above expressions to generalize. Let eÃÇi = j Aji~e 0j , and
find the expressions for (a) ~e 0j in terms of eÃÇi ; (b) Vi0 in terms of Vj ; and (c) Vi in
terms of Vj0 . Then show (d) that if a linear tranformation T which maps vectors
~ ‚Üí W
~ is given in the eÃÇi basis by a matrix Bij , in that Wi = P Bij Vj , then
V
the same transformation T in the ~e 0i basis is given by C = A ¬∑ B ¬∑ A‚àí1 . This
transformation of matrices, B ‚Üí C = A ¬∑ B ¬∑ A‚àí1 , for an arbitrary invertible
matrix A, is called a similarity transformation.
4.3 Two matrices B and C are called similar if there exists an invertible matrix
A such that C = A ¬∑ B ¬∑ A‚àí1 , and this transformation of B into C is called a
similarity transformation, as in the last problem. Show that, if B and C are similar,
(a) Tr B = Tr C; (b) det B = det C; (c) B and C have the same eigenvalues; (d) If
A is orthogonal and B is symmetric (or antisymmetric), then C is symmetric (or
antisymmetric).
4.4 From the fact that AA‚àí1 = 1 for any invertible matrix, show that if A(t) is
a differentiable matrix-valued function of time,
AÃá A‚àí1 = ‚àíA

dA‚àí1
.
dt

4.5 Show that a counterclockwise rotation through an angle Œ∏ about an axis in
the direction of a unit vector nÃÇ passing through the origin is given by the matrix
Aij = Œ¥ij cos Œ∏ + ni nj (1 ‚àí cos Œ∏) ‚àí ijk nk sin Œ∏.

4.4. DYNAMICS

119

4.6 Consider a rigid body in the shape of a right circular cone of height h and a
base which is a circle of radius R, made of matter with a uniform density œÅ.
a) Find the position of the center of
mass. Be sure to specify with respect
to what.
b) Find the moment of inertia tenP
sor in some suitable, well specified coordinate system about the center of
mass.
c) Initially the cone is spinning about
h
its symmetry axis, which is in the z
direction, with angular velocity œâ0 ,
and with no external forces or torques
y
acting on it. At time t = 0 it is hit
with a momentary laser pulse which
R
imparts an impulse P in the x direcx
tion at the apex of the cone, as shown.
Describe the subsequent force-free motion, including, as a function of time, the
angular velocity, angular momentum, and the position of the apex, in any inertial
coordinate system you choose, provided you spell out the relation to the initial
inertial coordinate system.

4.7 We defined the general rotation as A = Rz (œà) ¬∑ Ry (Œ∏) ¬∑ Rz (œÜ). Work out
the full expression for A(œÜ, Œ∏, œà), and verify the last expression in (4.31). [For
this and exercise 4.8, you might want to use a computer algebra program such as
mathematica or maple, if one is available.]

4.8 Find the expression for œâ
~ in terms of œÜ, Œ∏, œà, œÜÃá, Œ∏Ãá, œàÃá. [This can be done simply
with computer algebra programs. If you want to do this by hand, you might find
it easier to use the product form A = R3 R2 R1 , and the rather simpler expressions
for RRÃáT . You will still need to bring the result (for R1 RÃá1T , for example) through
the other rotations, which is somewhat messy.]

4.9 A diamond shaped object is shown in top, front, and side views. It is an
octahedron, with 8 triangular flat faces.

120

CHAPTER 4. RIGID BODY MOTION
A‚Äô
C

B‚Äô

B

a
a

A
b

It is made of solid aluminum of uniform
density, with a total mass M . The dimensions, as shown, satisfy h > b > a.
(a) Find the moment of inertia tensor
about the center of mass, clearly specifying the coordinate system chosen.
(b) About which lines can a stable spinning motion, with fixed œâ
~ , take place,
assuming no external forces act on the
body?

b

a

C

a
C

h

B‚Äô

A

A

B

B

A‚Äô

h

C‚Äô

C‚Äô

4.10 From the expression 4.40 for u = cos Œ∏ for the motion of the symmetric top,
we can derive a function for the time t(u) as an indefinite integral
Z u

t(u) =

f ‚àí1/2 (z) dz.

For values which are physically realizable, the function f has two (generically distinct) roots, uX ‚â§ uN in the interval u ‚àà [‚àí1, 1], and one root uU ‚àà [1, ‚àû), which
does not correspond to a physical value of Œ∏. The integrand is then generically an
analytic function of z with square root branch points at uN , uX , uU , and ‚àû, which
we can represent on a cut Riemann sheet with cuts on the real axis, [‚àí‚àû, uX ] and
[uN , uU ], and f (u) > 0 for u ‚àà (uX , uN ). Taking t = 0 at the time the top is at
the bottom of a wobble, Œ∏ = Œ∏max , u = uX , we can find the time at which it first
reaches another u ‚àà [uX , uN ] by integrating along the real axis. But we could also
use any other path in the upper half plane, as the integral of a complex function
is independent of deformations of the path through regions where the function is
analytic.
(a) Extend this definition to a function t(u) defined for Im u ‚â• 0, with u not on a
cut, and show that the image of this function is a rectangle in the complex t plane,
and identify the pre-images of the sides. Call the width T /2 and the height œÑ /2
(b) Extend this function to the lower half of the same Riemann sheet by allowing
contour integrals passing through [uX , uN ], and show that this extends the image
in t to the rectangle (0, T /2) √ó (‚àíiœÑ /2, iœÑ /2).
(c) If the coutour passes through the cut (‚àí‚àû, uX ] onto the second Riemann sheet,
the integrand has the opposite sign from what it would have at the corresponding
point of the first sheet. Show that if the path takes this path onto the second sheet

4.4. DYNAMICS

121

and reaches the point u, the value t1 (u) thus obtained is t1 (u) = ‚àít0 (u), where
t0 (u) is the value obtained in (a) or (b) for the same u on the first Riemann sheet.
(d) Show that passing to the second Riemann sheet by going through the cut
[uN , uU ] instead, produces a t2 (u) = t1 + T .
(e) Show that evaluating the integral along two contours, Œì1 and Œì2 , which differ
only by Œì1 circling the [uN , uU ] cut clockwise once more than Œì2 does, gives t1 =
t2 + iœÑ .
(f) Show that any value of t can be reached by some path, by circling the [uN , uU ]
as many times as necessary, and also by passing downwards through it and upwards
through the [‚àí‚àû, uX ] cut as often as necessary (perhaps reversed).
(g) Argue that thus means the function u(t) is an analytic function from the
complex t plane into the u complex plane, analytic except at the points t = nT +
i(m + 21 )œÑ , where u(t) has double poles. Note this function is doubly periodic, with
u(t) = u(t + nT + imœÑ ).
(g) Show that the function is then given by u = Œ≤ ‚Ñò(t ‚àí iœÑ /2) + c, where c is a
constant, Œ≤ is the constant from (4.40), and
‚Ñò(z) =

X
1
+
2
z
m,n‚ààZ



1
1
‚àí
(z ‚àí nT ‚àí miœÑ )2 (nT + miœÑ )2



(m,n)6=0

is the Weierstrass‚Äô ‚Ñò-Function.
(h) Show that ‚Ñò satisfies the differential equation
‚Ñò02 = 4‚Ñò3 ‚àí g2 ‚Ñò ‚àí g3 ,
where
g2 =

X

Z

m,n‚àà
(m,n)6=(0,0)

(mT + inœÑ )‚àí4 ,

g3 =

X

(mT + inœÑ )‚àí6 .

Z

m,n‚àà
(m,n)6=(0,0)

[Note that the Weierstrass function is defined more generally, using parameters
œâ1 = T /2, œâ2 = iœÑ /2, with the œâ‚Äôs permitted to be arbitrary complex numbers
with differing phases.]
4.11 As a rotation about the origin maps the unit sphere into itself, one way
to describe rotations is as a subset of maps f : S 2 ‚Üí S 2 of the (surface of the)
unit sphere into itself. Those which correspond to rotations are clearly one-toone, continuous, and preserve the angle between any two paths which intersect
at a point. This is called a conformal map. In addition, rotations preserve the
distances between points. In this problem we show how to describe such mappings,
and therefore give a representation for the rotations in three dimensions.

122

CHAPTER 4. RIGID BODY MOTION

(a) Let N be the north pole (0, 0, 1) of the unit sphere Œ£ = {(x, y, z), x2 +y 2 +z 2 =
1}. Define the map from the rest of the sphere s : Œ£ ‚àí {N } ‚Üí R2 given by a
stereographic projection, which maps each point on the unit sphere, other than
the north pole, into the point (u, v) in the equatorial plane (x, y, 0) by giving the
intersection with this plane of the straight line which joins the point (x, y, z) ‚àà Œ£
to the north pole. Find (u, v) as a function of (x, y, z), and show that the lengths
of infinitesimal paths in the vicinity of a point are scaled by a factor 1/(1 ‚àí z)
independent of direction, and therefore that the map s preserves the angles between
intersecting curves (i.e. is conformal).
(b) Show that the map f ((u, v)) ‚Üí (u0 , v 0 ) which results from first applying s‚àí1 ,
then a rotation, and then s, is a conformal map from R2 into R2 , except for the
pre-image of the point which gets mapped into the north pole by the rotation.
By a general theorem of complex variables, any such map is analytic, so f : u+iv ‚Üí
u0 + iv 0 is an analytic function except at the point Œæ0 = u0 + iv0 which is mapped
to infinity, and Œæ0 is a simple pole of f . Show that f (Œæ) = (aŒæ + b)/(Œæ ‚àí Œæ0 ), for
some complex a and b. This is the set of complex Mobius transformations, which
are usually rewritten as
Œ±Œæ + Œ≤
f (Œæ) =
,
Œ≥Œæ + Œ¥
where Œ±, Œ≤, Œ≥, Œ¥ are complex constants. An overall complex scale change does not
affect f , so the scale of these four complex constants is generally fixed by imposing
a normalizing condition Œ±Œ¥ ‚àí Œ≤Œ≥ = 1.
(c) Show that composition of Mobius transformations f 00 = f 0 ‚ó¶ f : Œæ ‚àí‚Üí Œæ 0 ‚àí‚Üí
Œæ 00
0
f

f

is given by matrix multiplication,
 00
Œ±

Œ≥ 00

Œ≤ 00
Œ¥ 00



=

 0
Œ±

Œ≥0

Œ≤0
Œ¥0

 

¬∑

Œ±
Œ≥

Œ≤
Œ¥



.

(d) Not every mapping s‚àí1 ‚ó¶ f ‚ó¶ s is a rotation, for rotations need to preserve
distances as well. We saw that an infinitesimal distance d` on Œ£ is mapped by s to
a distance |dŒæ| = d`/(1 ‚àí z). Argue that the condition that f : Œæ ‚Üí ŒæÀú correspond
to a rotation is that d`Àú ‚â° (1 ‚àí zÃÉ)|df /dŒæ||dŒæ| = d`. Express this change of scale in
terms of Œæ and ŒæÀú rather than z and zÃÉ, and find the conditions on Œ±, Œ≤, Œ≥, Œ¥ that
insure this is true for all Œæ. Together with the normalizing condition, show that this
requires the matrix for f to be a unitary matrix with determinant 1, so that the
set of rotations corresponds to the group SU (2). The matrix elements are called
Cayley-Klein parameters, and the real and imaginary parts of them are called the
Euler parameters.

Chapter 5
Small Oscillations
5.1

Small oscillations about stable equilibrium

Consider a situation with N unconstrained generalized coordinates qi described by a mass matrix Mij ({qk }) and a potential U ({qi }), and suppose
that U has a local minimum at some point in configuration space, qi = qi0 .
Then this point is a stable equilibrium point, for the generalized force at that
point is zero, and if the system is placed nearly at rest near that point, it will
not have enough energy to move far away from that point. We may study
the behavior of such motions by expanding the potential1 in Taylor‚Äôs series
expansion in the deviations Œ∑i = qi ‚àí qi0 ,
U (q1 , . . . , qN ) = U (qi0 ) +

1 X ‚àÇ 2U
Œ∑i +
Œ∑i Œ∑j + ... .
‚àÇqi 0
2 ij ‚àÇqi ‚àÇqj 0

X ‚àÇU
i

The constant U (qi0 ) is of no interest, as only changes in potential matter,
so we may as well set it to zero. In the second term, ‚àí ‚àÇU/‚àÇqi |0 is the
generalized force at the equilibrium point, so it is zero. Thus the leading
term in the expansion is the quadratic one, and we may approximate
U ({qi }) =

‚àÇ 2U
1X
Aij Œ∑i Œ∑j , with Aij =
.
2 ij
‚àÇqi ‚àÇqj 0

Note that A is a constant symmetric real matrix.
1

assumed to have continuous second derivatives.

123

(5.1)

124

CHAPTER 5. SMALL OSCILLATIONS

The kinetic energy T = 12 Mij Œ∑Ãái Œ∑Ãáj is already second order in the small
variations from equilibrium, so we may evaluate Mij , which in general can
depend on the coordinates qi , at the equilibrium point, ignoring any higher
order changes. Thus Mij is a constant. Thus both the kinetic and potential
energies are quadratic forms in the displacement Œ∑, which we think of as a
vector in N -dimensional space. Thus we can write the energies in matrix
form
1
1
U = Œ∑ T ¬∑ A ¬∑ Œ∑.
(5.2)
T = Œ∑Ãá T ¬∑ M ¬∑ Œ∑Ãá,
2
2
A and M are real symmetric matrices, and because any displacement corresponds to positive kinetic and nonnegative potential energies, they are positive (semi)definite matrices, meaning that all their eigenvalues are greater
than zero, except that A may also have eigenvalues equal to zero (these
are directions in which the stability is neutral to lowest order, but may be
determined by higher order terms in the displacement).
Lagrange‚Äôs equation of motion
P

0=

‚àÇL
d
d ‚àÇL
‚àí
= M ¬∑ Œ∑Ãá + A ¬∑ Œ∑ = M ¬∑ Œ∑Ãà + A ¬∑ Œ∑
dt ‚àÇ Œ∑Ãái ‚àÇŒ∑i
dt

(5.3)

is not necessarily diagonal in the coordinate Œ∑. We shall use the fact that
any real symmetric matrix can be diagonalized by a similarity transformation with an orthogonal matrix to reduce the problem to a set of independant
harmonic oscillators. While both M and A can be diagonalized by an orthogonal transformation, they can not necessarily be diagonalized by the same
one, so our procedure will be in steps:
1. Diagonalize M with an orthogonal transformation O1 , transforming the
coordinates to a new set x = O1 ¬∑ Œ∑.
2. Scale the x coordinates to reduce the mass matrix to the identity matrix. The new coordinates will be called y.
3. Diagonalize the new potential energy matrix with another orthogonal
matrix O2 , giving the final set of coordinates, Œæ = O2 ¬∑ y. Note this
transformation leaves the kinetic energy matrix diagonal because the
identity matrix is unaffected by similarity transformations.
The Œæ are normal modes, modes of oscillation which are independent in
the sense that they do not affect each other.

5.1. SMALL OSCILLATIONS ABOUT STABLE EQUILIBRIUM

125

Let us do this in more detail. We are starting with the coordinates Œ∑ and
the real symmetric matrices A and M , and we want to solve the equations
M ¬∑ Œ∑Ãà + A ¬∑ Œ∑ = 0. In our first step, we use the matrix O1 , which linear
algebra guarantees exists, that makes m = O1 ¬∑ M ¬∑ O1‚àí1 diagonal. Note O1 is
P
P
time-independent, so defining xi = j O1 ij Œ∑j also gives xÃái = j O1 ij Œ∑Ãáj , and
T =
=
=
=
=

1 T
Œ∑Ãá ¬∑ M ¬∑ Œ∑Ãá
2

1 T  ‚àí1
Œ∑Ãá ¬∑ O1 ¬∑ m ¬∑ O1 ¬∑ Œ∑Ãá
2

1 T
Œ∑Ãá ¬∑ O1T ¬∑ m ¬∑ (O1 ¬∑ Œ∑Ãá)
2
1
(O1 ¬∑ Œ∑Ãá)T ¬∑ m ¬∑ (O1 ¬∑ Œ∑Ãá)
2
1 T
xÃá ¬∑ m ¬∑ xÃá.
2

Similarly the potential energy becomes U = 12 xT ¬∑ O1 ¬∑ A ¬∑ O1‚àí1 ¬∑ x. We know
that the matrix m is diagonal, and the diagonal elements mii are all strictly
‚àö
positive. To begin the second step, define the diagonal matrix Sij = mii Œ¥ij
P
and new coordinates yi = Sii xi = j Sij xj , or y = S¬∑x. Now m = S 2 = S T ¬∑S,
so T = 21 xÃáT ¬∑ m ¬∑ xÃá = 12 xÃáT ¬∑ S T ¬∑ S ¬∑ xÃá = 21 (S ¬∑ xÃá)T ¬∑ S ¬∑ xÃá = 21 yÃá T ¬∑ yÃá. In terms of
y, the potential energy is U = 12 y T ¬∑ B ¬∑ y, where
B = S ‚àí1 ¬∑ O1 ¬∑ A ¬∑ O1‚àí1 ¬∑ S ‚àí1
is still a symmetric matrix2 .
Finally, let O2 be an orthogonal matrix which diagonalizes B, so C =
O2 ¬∑ B ¬∑ O2‚àí1 is diagonal, and let Œæ = O2 ¬∑ y. Just as in the first step,
1
1
U = Œæ T ¬∑ O2 ¬∑ B ¬∑ O2‚àí1 ¬∑ Œæ = Œæ T ¬∑ C ¬∑ Œæ,
2
2
while the kinetic energy
1
1
1
T = yÃá T ¬∑ yÃá = yÃá T ¬∑ O2T ¬∑ O2 ¬∑ yÃá = ŒæÀôT ¬∑ ŒæÀô
2
2
2
is still diagonal. Because the potential energy must still be nonnegative,
‚àö all
the diagonal elements Cii are nonnegative, and we will call them œâi := Cii .
2

O1 ¬∑ A ¬∑ O1‚àí1 is symmetric because A is and O1 is orthogonal, so O1‚àí1 = O1T .

126

CHAPTER 5. SMALL OSCILLATIONS

Then
T =

1 X Àô2
Œæ ,
2 j j

U=

1X 2 2
œâ Œæ ,
2 j j j

Œæ¬®j + œâj2 Œæj = 0,

so we have N independent harmonic oscillators with the solutions
Œæj = Re aj eiœâj t ,
with some arbitrary complex numbers aj .
To find what the solution looks like in terms of the original coordinates
qi , we need to undo all these transformations. As Œæ = O2 ¬∑ y = O2 ¬∑ S ¬∑ x =
O2 ¬∑ S ¬∑ O1 ¬∑ Œ∑, we have
q = q0 + O1‚àí1 ¬∑ S ‚àí1 ¬∑ O2‚àí1 ¬∑ Œæ.
We have completely solved this very general problem in small oscillations, at least in the sense that we have reduced it to a solvable problem of
diagonalizing symmetric real matrices. What we have done may appear abstract and formal and devoid of physical insight, but it is a general algorithm
which will work on a very wide class of problems of small oscillations about
equilibrium. In fact, because diagonalizing matrices is something for which
computer programs are available, this is even a practical method for solving
such systems, even if there are dozens of interacting particles.

5.1.1

Molecular Vibrations

Consider a molecule made up of n atoms. We need to choose the right level
of description to understand low energy excitations. We do not want to
describe the molecule in terms of quarks, gluons, and leptons. Nor do we
need to consider all the electronic motion, which is governed by quantum
mechanics. The description we will use, called the Born-Oppenheimer
approximation, is to model the nuclei as classical particles. The electrons,
which are much lighter, move around much more quickly and cannot be
treated classically; we assume that for any given configuration of the nuclei,
the electrons will almost instantaneously find a quantum-mechanical ground
state, which will have an energy which depends on the current positions of
the nuclei. This is then a potential energy when considering the nuclear
motion. The nuclei themselves will be considered point particles, and we

5.1. SMALL OSCILLATIONS ABOUT STABLE EQUILIBRIUM

127

will ignore internal quantum-mechanical degrees of freedom such as nuclear
spins. So we are considering n point particles moving in three dimensions,
with some potential about which we know only qualitative features. There
are 3n degrees of freedom. Of these, 3 are the center of mass motion, which,
as there are no external forces, is simply motion at constant velocity. Some
of the degrees of freedom describe rotational modes, i.e. motions that the
molecule could have as a rigid body. For a generic molecule this would be
three degrees of freedom, but if the equilibrium configuration of the molecule
is linear, rotation about that line is not a degree of freedom, and so only two
of the degrees of freedom are rotations in that case. The remaining degrees
of freedom, 3n ‚àí 6 for noncollinear and 3n ‚àí 5 for collinear molecules, are
vibrations.

O2

CO 2

H O
2

Figure 5.1: Some simple molecules in their equilibrium positions.
For a collinear molecule, it makes sense to divide the vibrations into
transverse and longitudinal ones. Considering motion in one dimension only,
the nuclei have n degrees of freedom, one of which is a center-of-mass motion,
leaving n ‚àí 1 longitudinal vibrations. So the remaining (3n ‚àí 5) ‚àí (n ‚àí 1) =
2(n ‚àí 2) vibrational degrees of freedom are transverse vibrational modes.
There are no such modes for a diatomic molecule.
Example: CO2
Consider first the CO2 molecule. As it is a molecule, there must be a position
of stable equilibrium, and empirically we know it to be collinear and symmetric, which one might have guessed. We will first consider only collinear
motions of the molecule. If the oxygens have coordinates q1 and q2 , and the
carbon q3 , the potential depends on q1 ‚àí q3 and q2 ‚àí q3 in the same way, so

128

CHAPTER 5. SMALL OSCILLATIONS

the equilibrium positions have q2 ‚àí q3 = ‚àí(q1 ‚àí q3 ) = b. Assuming no direct
force between the two oxygen molecules, the one dimensional motion may be
described near equilibrium by
1
1
k(q3 ‚àí q1 ‚àí b)2 + k(q2 ‚àí q3 ‚àí b)2
2
2
1
1
1
2
2
T =
mO qÃá1 + mO qÃá2 + mC qÃá32 .
2
2
2

U =

We gave our formal solution in terms of displacements from the equilibrium
position, but we now have a situation in which there is no single equilibrium
position, as the problem is translationally invariant, and while equilibrium
has constraints on the differences of q‚Äôs, there is no constraint on the center
of mass. We can treat this in two different ways:
1. Explicitly fix the center of mass, eliminating one of the degrees of freedom.
2. Pick arbitrarily an equilibrium position. While the deviations of the
center-of-mass position from the equilibrium is not confined to small
excursions, the quadratic approximation is still exact.
First we follow the first method. We can always work in a frame where
the center of mass is at rest, at the origin. Then mO (q1 + q2 ) + mC q3 = 0
is a constraint, which we must eliminate. We can do so by dropping q3
as an independant degree of freedom, and we have, in terms of the two
displacements from equilibrium Œ∑1 = q1 + b and Œ∑2 = q2 ‚àí b, q3 = ‚àí(Œ∑1 +
Œ∑2 )mO /mC , and
1
mO
1
1
T = mO (Œ∑Ãá12 + Œ∑Ãá22 ) + mC Œ∑Ãá32 = mO Œ∑Ãá12 + Œ∑Ãá22 +
(Œ∑Ãá1 + Œ∑Ãá2 )2
2
2
2
mC

 
1 m2O
1 + mC /mO
1
Œ∑Ãá1
=
( Œ∑Ãá1 Œ∑Ãá2 )
.
1
1
+
m
/m
Œ∑Ãá2
2 mC
C
O




Now T is not diagonal, or more precisely M isn‚Äôt. We must find the orthogonal matrix O1 such that O1 ¬∑ M ¬∑ O1‚àí1 is diagonal. We may assume it to be
a rotation, which can only be
O=



cos Œ∏
sin Œ∏

‚àí sin Œ∏
cos Œ∏



5.1. SMALL OSCILLATIONS ABOUT STABLE EQUILIBRIUM

129

for some value of Œ∏. It is worthwhile to derive a formula for diagonalizing a
general real symmetric 2 √ó 2 matrix and then plug in our particular form.
Let


M=

a b
,
b d


and O =



c ‚àís
,
s c


where we have abbreviated s = sin Œ∏, c = cos Œ∏. We will require the matrix
element m12 = (O ¬∑ M ¬∑ O‚àí1 )12 = 0, because m is diagonal. This determines
Œ∏:
O¬∑M ¬∑O

‚àí1

c ‚àís
a b
c s
=
s c
b d
‚àís c





c ‚àís
¬∑ as + bc
¬∑ acs + bc2 ‚àí bs2 ‚àí scd
=
=
¬∑
¬∑
¬∑ bs + cd
¬∑
¬∑








where we have placed a ¬∑ in place of matrix elements we don‚Äôt need to calculate. Thus the condition on Œ∏ is
1
(a ‚àí d) sin Œ∏ cos Œ∏ + b(cos2 Œ∏ ‚àí sin2 Œ∏) = 0 = (a ‚àí d) sin 2Œ∏ + b cos 2Œ∏,
2
or
‚àí2b
.
a‚àíd

tan 2Œ∏ =

Notice this determines 2Œ∏ only modulo œÄ, and therefore Œ∏ modulo 90‚ó¶ , which
ought to be expected, as a rotation through 90‚ó¶ only interchanges axes and
reverses directions, both of which leave a diagonal matrix diagonal.
In our case a = d, so tan 2Œ∏ = ‚àû, and Œ∏ = œÄ/4. As x = O1 Œ∑,


x1
x2





=

cos œÄ/4 ‚àí sin œÄ/4
sin œÄ/4 cos œÄ/4



Œ∑1
Œ∑2



1
=‚àö
2



Œ∑1 ‚àí Œ∑2
,
Œ∑1 + Œ∑2


and inversely


Œ∑1
Œ∑2



1
=‚àö
2



x1 + x2
.
‚àíx1 + x2


Then
1
(xÃá1 + xÃá2 )2 (xÃá1 ‚àí xÃá2 )2 mO ‚àö
T =
mO
+
+
( 2xÃá2 )2
2
2
2
mC
"

#

130

CHAPTER 5. SMALL OSCILLATIONS
1
1
2mO 2
mO xÃá21 + mO 1 +
xÃá2
2
2
mC


=
U =
=
=
=
=



1
1
k(q3 ‚àí q1 ‚àí b)2 + k(q2 ‚àí q3 ‚àí b)2
2 "
2
2 
2 #

1
mO
mO
k Œ∑1 +
(Œ∑1 + Œ∑2 ) + Œ∑2 +
(Œ∑1 + Œ∑2 )
2
mC
mC
#
"
2m2O
1
2mO
2
2
2
2
k Œ∑1 + Œ∑2 + 2 (Œ∑1 + Œ∑2 ) +
(Œ∑1 + Œ∑2 )
2
mC
mC
"
#
1
4m
O
k x21 + x22 + 2 (mO + mC )x22
2
mC


1 2 1
mC + 2mO 2 2
kx1 + k
x2 .
2
2
mC

Thus U is already diagonal and we don‚Äôt need to go through steps 2 and 3,
the scaling and second orthogonalization, except to note that if we skip the
scaling the angular frequencies are given by œâi2 = coefficient
in U / coefficient
q
in T . Thus we have one normal mode, x1 , with œâ1 = k/mO , with x2 = 0,
Œ∑1 = ‚àíŒ∑2 , q3 = 0, in which the two oxygens vibrate in and out together,
symmetrically about the carbon, which doesn‚Äôt move. We also have another
mode, x2 , with
œâ2

v
s
u
u k(mC + 2mO )2 /m2O
k(mC + 2mO )
=t
=
,

mO (1 + 2mO /mC )

mO mC

with x1 = 0, Œ∑1 = Œ∑2 , in which the two oxygens move right or left together,
with the carbon moving in the opposite direction.
We have successfully solved for the longitudinal vibrations by eliminating
one of the degrees of freedom. Let us now try the second method, in which
we choose an arbitrary equilibrium position q1 = ‚àíb, q2 = b, q3 = 0. Then
1
1
mO (Œ∑Ãá12 + Œ∑Ãá22 ) + mC Œ∑Ãá32
2
2
i
1 h
2
U =
k (Œ∑1 ‚àí Œ∑3 ) + (Œ∑2 ‚àí Œ∑3 )2 .
2
T =

T is already diagonal, so O1 = 1I, x = Œ∑. In the second step S is the diagonal
‚àö
‚àö
‚àö
matrix with S11 = S22 = mO , S33 = mC , and yi = mO Œ∑i for i = 1, 2,

5.1. SMALL OSCILLATIONS ABOUT STABLE EQUILIBRIUM
and y3 =

‚àö

mC Œ∑3 . Then
Ô£Æ

y3
1 Ô£∞ y1
k
‚àí‚àö
U =
‚àö
2
mO
mC
=

131

!2

y2
y3
+ ‚àö
‚àí‚àö
mO
mC

!2 Ô£π
Ô£ª

i
‚àö
1 k h
mC y12 + mC y22 + 2mO y32 ‚àí 2 mO mC (y1 + y2 )y3 .
2 mO mC

Thus the matrix B is

Ô£∂
‚àö
‚àí mO mC
‚àö
Ô£∑
‚àí mO mC Ô£∏ ,
2mO
‚àö
‚àö
‚àö
which is singular, as it annihilates the vector y T = ( mO , mO , mC ),
which corresponds to Œ∑ T = (1, 1, 1), i.e. all the nuclei are moving by the same
amount, or the molecule is translating rigidly. Thus this vector corresponds
to a zero eigenvalue of U , and a harmonic oscillation of zero frequency. This is
free motion3 , Œæ = Œæ0 +vt. The other two modes can be found by diagonalizing
the matrix, and will be as we found by the other method.
Ô£´

mC
Ô£¨
B=Ô£≠
0
‚àö
‚àí mO mC

0
m
‚àö C
‚àí mO mC

Transverse motion
What about the transverse motion? Consider the equilibrium position of
the molecule to lie in the x direction, and consider small deviations in the z
direction. The kinetic energy
1
1
1
mO zÃá1 + mO zÃá22 + mC zÃá32 .
2
2
2
is already diagonal, just as for
the longitudinal modes in the second method. Any potential energy must be due to a resistance
to bending, so to second order,
z
Œ∏
2
U ‚àù (œà ‚àí Œ∏)2 ‚àº (tan œà ‚àí tan Œ∏)2 =
b
œà
[(z2 ‚àíz3 )/b+(z1 ‚àíz3 )/b]2 = b‚àí2 (z1 +
z
z
b 3
1
z2 ‚àí 2z3 )2 .
Note that the potential energy is proportional to the square of a single linear
T =

3

To see that linear motion is a limiting case of harmonic motion as œâ ‚Üí 0, we need to
choose the complex coefficient to be a function of œâ, A(œâ) = x0 ‚àí iv0 /œâ, with x0 and v0
real. Then x(t) = limœâ‚Üí0 Re A(œâ)eiœât = x0 + v0 limœâ‚Üí0 sin(œât)/œâ = x0 + v0 t

132

CHAPTER 5. SMALL OSCILLATIONS

combination of the displacements, or to the square of one component (with
respect to a particular direction) of the displacement. Therefore there is no
contribution of the two orthogonal directions, and there are two zero modes,
or two degrees of freedom with no restoring force. One of these is the center of
mass motion, z1 = z2 = z3 , and the other is the third direction in the abstract
space of possible displacements, z T = (1, ‚àí1, 0), with z1 = ‚àíz2 , z3 = 0, which
we see is a rotation. Thus there remains only one true transverse vibrational
mode in the z direction, and also one in the y direction, which together with
the two longitudinal ones we found earlier, make up the 4 vibrational modes
we expected from the general formula 2(n ‚àí 2) for a collinear molecule.
You might ask whether these oscillations we have discussed are in any
way observable. Quantum mechanically, a harmonic oscillator can only be in
states with excitation energy E = nhÃÑœâ, where n ‚àà Z is an integer and 2œÄhÃÑ
is Planck‚Äôs constant. When molecules are in an excited state, they can emit
a photon while changing to a lower energy state. The energy of the photon,
which is the amount lost by the molecule, is proportional to the frequency,
‚àÜE = 2œÄhÃÑf , so by measuring the wavelength of the emitted light, we can
determine the vibrational frequencies of the molecules. So the calculations
we have done, and many others for which we have built the apparatus, are
in fact very practical tools for molecular physics.

5.1.2

An Alternative Approach

The step by step diagonalization we just gave is not the easiest approach to
solving the linear differential equation (5.3). Solutions to linear differential
equations are subject to superposition, and equations with coefficients independent of time are simplified by Fourier transform, so we can express the
N dimensional vector of functions Œ∑j (t) as
Œ∑j (t) =

Z ‚àû
‚àí‚àû

dœâœàj (œâ)e‚àíiœât .

Then the Lagrange equations become
Z ‚àû
‚àí‚àû

dœâ

X



Aij ‚àí œâ 2 Mij œàj (œâ)e‚àíiœât = 0 for all t.

j

But e‚àíiœât are linearly independent functions of t ‚àà R, so
X
j



Aij ‚àí œâ 2 Mij œàj (œâ) = 0.

5.2. OTHER INTERACTIONS

133

This implies œàj (œâ) = 0 except when the matrix Aij ‚àí œâ 2 Mij is singular,
det (Aij ‚àí œâ 2 Mij ) = 0, which gives a discrete set of angular frequencies
œâ1 . . . œâN , and for each œâj an eigenvector œàj .

5.2

Other interactions

In our treatment we assumed a Lagrangian formulation with a kinetic term
purely quadratic in ~qÀô, together with a velocity independent potential. There
is a wider scope of small oscillation problems which might include dissipative
forces like friction, or external time-dependent forces, or perhaps terms in
the Lagrangian linear in the velocities. An example of the latter occurs
in rotating reference frames, from the Coriolus force, and is important in
the question of whether there is a gravitationally stable location for small
objects caught between the Earth and the moon at the ‚ÄúL5‚Äù point4 . Each of
these complications introduces terms, even in the linear approximation to the
equations of motion, which cannot be diagonalized away, because there is not
significant freedom of diagonalization left, in general, after having simplified
T and U . Thus the approach of section 5.1 does not generalize well, but the
approach of section 5.1.2 can be applied.
For example, we might consider adding a generalized force Qi on Œ∑i , conP
sisting of a dissipative force j Rij Œ∑Ãáj and a driving force Fi . We will assume
R is a symmetric matrix, as might be a result of a Rayleigh dissipation function (see Section 2.7 or Ref. [6]). We will consider the motion to first order
in F , so any coordinate dependence of R or F is replaced, as it was for M
and A, by their values at the equilibrium position. Thus the equations of
motion become
X
(Mij Œ∑Ãàj + Rij Œ∑Ãáj + Aij Œ∑j ) ‚àí Fi = 0.
j

Again making the ansatz that
Œ∑j (t) =

Z ‚àû
‚àí‚àû

dœâœàj (œâ)e‚àíiœât

and expressing Fi (t) in terms of its fourier transform
Fj (t) =
4

See problem 5.3.

Z ‚àû
‚àí‚àû

dœâ fÀúi (œâ)e‚àíiœât

134

CHAPTER 5. SMALL OSCILLATIONS

we find
X



‚àíœâ 2 Mij ‚àí iœâRij + Aij œàj = fÀúi .

j

Except for at most 2N values of œâ the matrix multiplying œàj will have a nonzero determinant and will be invertible, allowing us to find the response œàj
to the fourier component of the driving force, fÀúi . Those values of œâ for which
the determinant vanishes, and the vector œàj which the matrix annihilates,
correspond to damped modes that we would see if the driving force were
removed.

5.3

String dynamics

In this section we consider two closely related problems, transverse oscillations of a stretched loaded string, and of a stretched heavy string. The latter
is is a limiting case of the former. This will provide an introduction to field
theory, in which the dynamical degrees of freedom are not a discrete set but
are defined at each point in space. In Chapter 8 we will discuss more interesting and involved cases such as the electromagnetic field, where at each
~ and B
~ as degrees of freedom, though not without
point in space we have E
constraints.
The loaded string we will consider is a light string under tension œÑ stretched
between two fixed points a distance ` apart, say at x = 0 and x = `. On
the string, at points x = a, 2a, 3a, . . . , na, are fixed n particles each of mass
m, with the first and last a distance a away from the fixed ends. Thus
` = (n + 1)a. We will consider only small transverse motion of these masses,
using yi as the transverse displacement of the i‚Äôth mass, which is at x = ia.
We assume all excursions from the equilibrium positions yi = 0 are small, and
in particular that the difference in successive displacements yi+1 ‚àí yi  a.
Thus we are assuming that the angle made by each segment of the string,
Œ∏i = tan‚àí1 [(yi+1 ‚àí yi )/a]  1. Working to first order in the Œ∏‚Äôs in the equations of motion, and second order for the Lagrangian, we see that restricting
our attention to transverse motions and requiring no horizontal motion forces
taking the tension œÑ to be constant along the string. The transverse force on
the i‚Äôth mass is thus
Fi = œÑ

yi‚àí1 ‚àí yi
œÑ
yi+1 ‚àí yi
+œÑ
= (yi+1 ‚àí 2yi + yi‚àí1 ).
a
a
a

5.3. STRING DYNAMICS

135

The potential energy U (y1 , . . . , yn ) then satisfies
‚àÇU
œÑ
= ‚àí (yi+1 ‚àí 2yi + yi‚àí1 )
‚àÇyi
a
so
U (y1 , . . . , yi , . . . , yn )
Z yi
œÑ
dyi (2yi ‚àí yi+1 ‚àí yi‚àí1 ) + F (y1 , . . . , yi‚àí1 , yi+1 , . . . , yn )
=
a
0

œÑ 2
=
yi ‚àí (yi+1 + yi‚àí1 )yi + F (y1 , . . . , yi‚àí1 , yi+1 , . . . , yn )
a 

œÑ
(yi+1 ‚àí yi )2 + (yi ‚àí yi‚àí1 )2 + F 0 (y1 , . . . , yi‚àí1 , yi+1 , . . . , yn )
=
2a
n
X
œÑ
(yi+1 ‚àí yi )2 + constant.
=
i=0 2a
The F and F 0 are unspecified functions of all the yj ‚Äôs except yi . In the last
expression we satisfied the condition for all i, and we have used the convenient
definition y0 = yn+1 = 0. We can and will drop the arbitrary constant.
The kinetic energy is T = 21 m

Pn 2
yÃá .
1

i

Before we continue with the analysis of this problem, let us note that
another physical setup also leads to the same Lagrangian. Consider a one
dimensional lattice of identical atoms with a stable equilibrium in which they
are evenly spaced, with interactions between nearest neighbors. Let Œ∑i be the
longitudinal displacement of the i‚Äôth atom from its equilibrium position. The
P
kinetic energy is simply T = 21 m n1 Œ∑Ãái2 . As the interatomic distance differs
from its equilibrium position by Œ∑i+1 ‚àí Œ∑i , the interaction potential of atoms
i and i + 1 can be approximated by U (Œ∑i+1 , Œ∑i ) ‚âà 12 k(Œ∑i+1 ‚àí Œ∑i )2 . We have
in effect atoms separated by springs of spring constant k, and we see that
if k = œÑ /a, we get the same Lagrangian for longitudinal oscillations of this
lattice as we had for the transverse oscillations of the loaded string.
As the kinetic energy is simply T = 21 m n1 yÃái2 , the mass matrix is already
proportional to the identity matrix and we do not need to go through the
first two steps of our general process. The potential energy U = 21 y T ¬∑ A ¬∑ y
P

136

CHAPTER 5. SMALL OSCILLATIONS

has a non-diagonal n √ó n matrix
‚àí2 1
0 0 ¬∑¬∑¬∑ 0
0
Ô£¨ 1
‚àí2 1 0 ¬∑ ¬∑ ¬∑ 0
0 Ô£∑
Ô£∑
Ô£¨
Ô£∑
Ô£¨
Ô£∑
0
1
‚àí2
1
¬∑
¬∑
¬∑
0
0
œÑÔ£¨
.
A=‚àí Ô£¨
..
..
.. . .
..
.. Ô£∑
Ô£¨ ..
.
aÔ£¨ .
.
.
.
.
. Ô£∑
Ô£∑
Ô£∑
Ô£¨
Ô£≠ 0
0
0 0 ¬∑ ¬∑ ¬∑ ‚àí2 1 Ô£∏
0
0
0 0 ¬∑ ¬∑ ¬∑ 1 ‚àí2
Ô£∂

Ô£´

Diagonalizing even a 3 √ó 3 matrix is work, so an n √ó n matrix might seem
out of the question, without some hints from the physics of the situation. In
this case the hint comes in a roundabout fashion ‚Äî we will first consider a
limit in which n ‚Üí ‚àû, the continuum limit, which leads to an interesting
physical situation in its own right.
Suppose we consider the loaded string problem in the limit that the spacing a becomes very small, but the number of masses m becomes large, keeping
the total length ` of the string fixed. If at the same time we adjust the individual masses so that the mass per unit length, œÅ, is fixed, our bumpy
string gets smoothed out in the limit, and we might expect that in this limit
we reproduce the physical problem of transverse modes of a uniformly dense
stretched string, like a violin string. Thus we wish to consider the limit
a ‚Üí 0,

n ‚Üí ‚àû,

` = (n + 1)a fixed,

m ‚Üí 0,

œÅ = m/a fixed.

It is natural to think of the degrees of freedom as associated with the label x
rather than i, so we redefine the dynamical functions {yj (t)} as y(x, t), with
y(ja, t) = yj (t). While this only defines the function at discrete points in x,
these are closely spaced for small a and become dense as a ‚Üí 0. We will
assume that the function y(x) is twice differentiable in the continuum limit,
though we shall see that this is not the case for all possible motions of the
discrete system.
What happens to the kinetic and potential energies in this limit? For the
kinetic energy,
1 X 2 1 X 2
1 X
1 Z`
T = m
yÃái = œÅ
ayÃá (xi ) = œÅ
‚àÜxyÃá 2 (xi ) ‚Üí œÅ dx yÃá 2 (x),
2
2 i
2 i
2 0
i
where the next to last expression is just the definition of a Riemann integral.
For the potential energy,
œÑ X
œÑX
yi+1 ‚àí yi
U=
(yi+1 ‚àí yi )2 =
‚àÜx
2a i
2 i
‚àÜx


2

œÑZ`
‚Üí
dx
2 0

‚àÇy
‚àÇx

!2

.

5.3. STRING DYNAMICS

137

The equation of motion for yi is
myÃài =

‚àÇL
‚àÇU
œÑ
=‚àí
= [(yi+1 ‚àí yi ) ‚àí (yi ‚àí yi‚àí1 )],
‚àÇyi
‚àÇyi
a

or

œÑ
([y(x + a) ‚àí y(x)] ‚àí [y(x) ‚àí y( x ‚àí a)]).
a
We need to be careful about taking the limit
œÅayÃà(x) =

y(x + a) ‚àí y(x)
‚àÇy
‚Üí
a
‚àÇx
because we are subtracting two such expressions evaluated at nearby points,
and because we will need to divide by a again to get an equation between
finite quantities. Thus we note that
‚àÇy
y(x + a) ‚àí y(x)
=
+ O(a2 ),
a
‚àÇx x+a/2
so
y(x + a) ‚àí y(x) y(x) ‚àí y( x ‚àí a)
‚àí
a
a

œÑ
œÅyÃà(x) =
a
Ô£´

!

Ô£∂

œÑ Ô£≠ ‚àÇy
‚àÇy
‚àÇ 2y
Ô£∏‚ÜíœÑ
‚âà
‚àí
,
a ‚àÇx x+a/2 ‚àÇx x‚àía/2
‚àÇx2
and we wind up with the wave equation for transverse waves on a massive
string
2
‚àÇ 2y
2‚àÇ y
‚àí
c
= 0,
‚àÇt2
‚àÇx2
where
s
œÑ
c=
.
œÅ
Solving this wave equation is very simple. For the fixed boundary conditions y(x) = 0 at x = 0 and x = `, the solution is a fourier expansion
y(x, t) =

‚àû
X
p=1

Re Bp eickp t sin kp x,

138

CHAPTER 5. SMALL OSCILLATIONS

where kp ` = pœÄ. Each p represents one normal mode, and there are an
infinite number as we would expect because in the continuum limit there are
an infinite number of degrees of freedom.
We have certainly not shown that y(x) = B sin kx is a normal mode for
the problem with finite n, but it is worth checking it out. This corresponds
to a mode with yj = B sin kaj, on which we apply the matrix A
X
œÑ
(A ¬∑ y)i =
Aij yj = ‚àí (yi+1 ‚àí 2yi + yi‚àí1 )
a
j
œÑ
= ‚àí B (sin(kai + ka) ‚àí 2 sin(kai) + sin(kai ‚àí ka))
a
œÑ
= ‚àí B(sin(kai) cos(ka) + cos(kai) sin(ka) ‚àí 2 sin(kai)
a
+ sin(kai) cos(ka) ‚àí cos(kai) sin(ka))
œÑ
=
B (2 ‚àí 2 cos(ka)) sin(kai)
a
2œÑ
=
(1 ‚àí cos(ka)) yi .
a
So we see that it is a normal mode, although the frequency of oscillation
s

œâ=

s

2œÑ
œÑ sin(ka/2)
(1 ‚àí cos(ka)) = 2
am
œÅ
a

q

differs from k œÑ /œÅ except in the limit a ‚Üí 0 for fixed k.
The wave numbers k which index the normal modes are restricted by
the fixed ends to the discrete set k = pœÄ/` = pœÄ/(n + 1)a, for p ‚àà Z, i.e. p is
an integer. This is still too many (‚àû) for a system with a finite number of
degrees of freedom. The resolution of this paradox is that not all different k‚Äôs
correspond to different modes. For example, if p0 = p + 2m(n + 1) for some
integer m, then k 0 = k + 2œÄm/a, and sin(k 0 aj) = sin(kaj + 2mœÄ) = sin(kaj),
so k and k 0 represent the same normal mode. Also, if p0 = 2(n + 1) ‚àí p,
k 0 = (2œÄ/a)‚àík, sin(k 0 aj) = sin(2œÄ ‚àíkaj) = ‚àí sin(kaj), so k and k 0 represent
the same normal mode, with opposite phase. Finally p = n + 1, k = œÄ/a
gives yj = B sin(kaj) = 0 for all j and is not a normal mode. This leaves as
independent only p = 1, ..., n, the right number of normal modes for a system
with n degrees of freedom.
The angular frequency of the p‚Äôth normal mode
r

œâp = 2

œÑ
pœÄ
sin
ma
2(n + 1)

5.4. FIELD THEORY

139

in plotted in Fig. 5.3. For fixed values of p and œÅ, as n ‚Üí ‚àû,
s

s

œÑ1
paœÄ
œÑ pœÄ
œâp = 2
sin
‚Üí2
= ckp ,
œÅa
2`
œÅ 2`
as we have in the continuum limit.
But if we consider modes with a
fixed ratio of p/n as n ‚Üí ‚àû, we
do not have a smooth limit y(x),
and such nodes are not appropriate for the continuum limit. In the
physics of crystals, the former kind
of modes are known as accoustic modes, while the later modes,
in particular those for n ‚àí p fixed,
which depend on the discrete nature of the crystal, are called opti- Fig. 5.3. Frequencies of oscillation
of the loaded string.
cal modes.
1

5.4

2

3

4

5

6

7

8

9

10

11

12

Field theory

We now examine how to formulate the continuum limit directly.

5.4.1

Lagrangian density

We saw in the last section that the kinetic and potential energies in the
continuum limit can be written as integrals over x of densities, and so we
may also write the Lagrangian as the integral of a Lagrangian density
L(x),
L=T ‚àíU =

Z L
0

Ô£Æ

dxL(x),

1
1
L(x) = Ô£∞ œÅyÃá 2 (x, t) ‚àí œÑ
2
2

‚àÇy(x, t)
‚àÇx

!2 Ô£π
Ô£ª.

This Lagrangian, however, will not be of much use until we figure out what is
meant by varying it with respect to each dynamical degree of freedom or its
corresponding velocity. In the discrete case we have the canonical momenta
Pi = ‚àÇL/‚àÇ yÃái , where the derivative requires holding all yÃáj fixed, for j 6= i, as
P
well as all yk fixed. This extracts one term from the sum 21 œÅ ayÃái2 , and this

140

CHAPTER 5. SMALL OSCILLATIONS

would appear to vanish in the limit a ‚Üí 0. Instead, we define the canonical
momentum as a density, Pi ‚Üí aP (x = ia), so
P (x = ia) = lim

1 ‚àÇ X
a L(y(x), yÃá(x), x)|x=ai .
a ‚àÇ yÃái i

We may think of the last part of this limit,
lim

a‚Üí0

X

a L(y(x), yÃá(x), x)|x=ai =

Z

dx L(y(x), yÃá(x), x),

i

if we also define a limiting operation
lim

1 ‚àÇ

a‚Üí0 a ‚àÇ yÃái

‚Üí

Œ¥
,
Œ¥ yÃá(x)

and similarly for a1 ‚àÇy‚àÇ i , which act on functionals of y(x) and yÃá(x) by
Œ¥y(x1 )
= Œ¥(x1 ‚àí x2 ),
Œ¥y(x2 )

Œ¥ yÃá(x1 )
Œ¥y(x1 )
=
= 0,
Œ¥y(x2 )
Œ¥ yÃá(x2 )

Œ¥ yÃá(x1 )
= Œ¥(x1 ‚àí x2 ).
Œ¥ yÃá(x2 )

Here Œ¥(x0 ‚àí x) is the Dirac delta function, defined by its integral,
Z x2

f (x0 )Œ¥(x0 ‚àí x)dx0 = f (x)

x1

for any function f (x), provided x ‚àà (x1 , x2 ). Thus
Z `
Œ¥ Z ` 01 2 0
P (x) =
dx œÅyÃá (x , t) =
dx0 œÅyÃá(x0 , t)Œ¥(x0 ‚àí x) = œÅyÃá(x, t).
Œ¥ yÃá(x) 0
2
0

We also need to evaluate
Œ¥
Œ¥ Z ` 0 ‚àíœÑ
L=
dx
Œ¥y(x)
Œ¥y(x) 0
2

‚àÇy
‚àÇx

!2

.
x=x0

For this we need
Œ¥ ‚àÇy(x0 )
‚àÇ
=
Œ¥(x0 ‚àí x) := Œ¥ 0 (x0 ‚àí x),
0
0
Œ¥y(x) ‚àÇx
‚àÇx

5.4. FIELD THEORY

141

which is again defined by its integral,
Z x2

f (x0 )Œ¥ 0 (x0 ‚àí x)dx0 =

Z x2

f (x0 )

x1

x1

=

‚àÇ
Œ¥(x0 ‚àí x)dx0
‚àÇx0

x
f (x )Œ¥(x ‚àí x)|x21 ‚àí
0

0

Z x2
x1

dx0

‚àÇf
Œ¥(x0 ‚àí x)
‚àÇx0

‚àÇf
(x),
=
‚àÇx
where after integration by parts the surface term is dropped because Œ¥(x ‚àí
x0 ) = 0 for x 6= x0 , which it is for x0 = x1 , x2 if x ‚àà (x1 , x2 ). Thus
Z `
‚àÇy
‚àÇ 2y
Œ¥
L = ‚àí dx0 œÑ (x0 )Œ¥ 0 (x0 ‚àí x) = œÑ 2 ,
Œ¥y(x)
‚àÇx
‚àÇx
0

and Lagrange‚Äôs equations give the wave equation
œÅyÃà(x, t) ‚àí œÑ

‚àÇ 2y
= 0.
‚àÇx2

(5.4)

We have derived the wave equation for small transverse deformations
of a strectch string by considering the continuum limit of a loaded string,
in the process demonstating how to formulate Lagrangian mechanics for a
continuum system. Of course it is more usual, and simpler, to derive it
directly by considering Newton‚Äôs law on an infinitesimal element of the string.
Let‚Äôs include gravity for good measure. If the string point initially at x
has a transverse displacement y(x)
and a longitudinal displacement
œÑ (x+‚àÜ x)
Œ∑(x), both considered small, the
Œ∏ (x+‚àÜ x)
Œ∏ (x )
slope of the string dy/dx is also
small. The segment [x, x + ‚àÜx] has
‚àÜx
œÑ (x )
a mass œÅ‚àÜx, where as before œÅ is
x
x+‚àÜx
the mass per unit length, and the
forces on it are
in x direction:
in y direction:

œÑ (x + ‚àÜx) cos Œ∏(x + ‚àÜx) ‚àí œÑ (x) cos Œ∏(x) = œÅ‚àÜxŒ∑Ãà
œÑ (x + ‚àÜx) sin Œ∏(x + ‚àÜx) ‚àí œÑ (x) sin Œ∏(x) ‚àí œÅg‚àÜx = œÅ‚àÜxyÃà

As Œ∏ << 1, we can replace cos Œ∏ by 1 and sin Œ∏ with tan Œ∏ = ‚àÇy/‚àÇx, and
then from the first equation we see that ‚àÇœÑ /‚àÇx is already small, so we can

142

CHAPTER 5. SMALL OSCILLATIONS

consider œÑ as constant in the second equation, which gives
!

œÑ

‚àÇy
‚àÇy
‚àí
‚àí œÅg‚àÜx = œÅ‚àÜxyÃà,
‚àÇx x+‚àÜx ‚àÇx x

or
‚àÇ 2y
œÑ 2 ‚àí œÅg = œÅyÃà.
‚àÇx
This agrees with Eq. 5.4 if we drop the gravity term, which we had not
included in our discussion of the loaded string.

5.4.2

Three dimensional continua

Could we do the same kind of analysis on a three dimensional solid object?
We might label each piece of the object with an equilibrium or reference
position ~x, and consider the dynamics of possible displacements ~Œ∑ (~x). We
will assume this displacement is small and smooth function of ~x and t, in
fact twice differentiable. Consider the dynamics of an infinitesimal volume
element ‚àÜV . The acceleration of each volume element will be determined by
the ratio of the net force on that volume to its mass, œÅ‚àÜV , where œÅ is now the
density, mass per unit volume, and is also assumed to be a smooth function,
though not necessarily constant. The forces we will consider will be of two
types. There may be external forces which will be taken to be extensive,
that is, proportional to the volume, called volume forces. One example is
gravity near the Earth‚Äôs surface, with F~ = ‚àíœÅg‚àÜV eÃÇz . If the material under
discussion had an electric charge density œÅE (~x) in an external electric field
~ x), there would also be a volume force œÅE (~x)E(~
~ x) ‚àÜV . In addition to the
E(~
volume forces, there are also surface forces which the rest of the object
exerts on the element under consideration. We will assume that all such
forces are local, due to the material on the other side of the surface, and
continuously varying, so the force across an infinitesimal element of surface
dS will be proportional to its area, at least if we keep the direction fixed.

5.4. FIELD THEORY

143

In fact, we can show that the force
~ is linear
across an infinitesimal surface dS
~ even when the direction
in the vector dS
~1 and
changes. Consider two elements dS
~
dS2 , shown as rectangles, and the third
1
~
side dS3 , which is the opposite of their
sum in the limit that size shrinks to zero.
Together with the two parallel triangular
3
pieces, these bound an infinitesimal volume. Let us scale the whole picture by a
factor Œª. The force on each side is proportional to Œª2 , but the mass of the volume
2
is proportional to Œª3 , so as Œª ‚Üí 0, the
coefficient of Œª2 in the sum of the forces must vanish. The triangular pieces
~1 and dS
~2 cancels
cancel each other, so the sum of the forces through dS
~3 . That is, the force is linear (additive) in the surface
the force through dS
~
elements dS.
~ This would
But the force is not necessarily in the same direction as dS.
be true for the pressure in a gas, or in a nonviscous or static fluid, in which no
tangential forces could be exerted along the boundary. But more generally,
~ will be specified by a matrix, and the force exerted on
a force linear in dS
P
~
dV across dS will be Fi = ‚àí j Pij dSj , where P is known as the stress
tensor5 .
Though P is not a scalar or diagonal in general, there is one constraint on the stress tensor ‚Äî it is
symmetric. To see this, consider z
y
the prism shown, and the torque in
the y direction. The forces across
Œª
the two faces perpendicular to z
h
are of order Œª, and are equal and
x
Œª
opposite, so they provide a torque
‚àíŒª2 hPxz in the y direction. Sim-

S

S

S

5

To be clear:

P

j Pij dSj is the force exerted by the back side of the surface element on

R
~ is an outward normal, the force on the volume is ‚àí P Pij dSj ,
the front side, so if dS
j
S
and a pressure corresponds to P = +pŒ¥ij . This agrees with Symon ([17]) but has a reversed
sign from Taylor‚Äôs ([18]) Œ£ = ‚àíP.

144

CHAPTER 5. SMALL OSCILLATIONS

ilarly the two faces perpendicular to x provide a torque +Œª2 hPzx in that
direction. The equal forces on other two faces have a moment arm parallel
to y and therefore provide no torque in that direction. But the moment of
inertia about the y axis is of order Œª2 dV = Œª4 h. So if the angular acceleration
is to remain finite as Œª ‚Üí 0, we must have Pzx ‚àí Pxz = 0, and P must be a
symmetric matrix.
We expect that the stress forces the material on one side of a boundary
exerts on the other is due to some distortion of the material. Near any value
of x, we may expand the displacement as
Œ∑i (x + ‚àÜx) = Œ∑i (x) +

‚àÇŒ∑i
‚àÜxj + ...
‚àÇxj

Moving the entire object as a whole, ~Œ∑ (x) = constant, or rotating it as a rigid
body about an axis œâ
~ , with ‚àÇŒ∑i /‚àÇxj = ijk œâk , will not produce any stress, and
so we will not consider such displacements to be part of the strain tensor,
which we therefore define to be the symmetric part of the derivative matrix:
1
Sij =
2

!

‚àÇŒ∑j
‚àÇŒ∑i
+
.
‚àÇxj ‚àÇxi

In general, the properties of the material will determine how the stress tensor
is related to the strain tensor, though for small displacements we expect it
to depend linearly.
Even linear dependence could be quite complex, but if the material properties are rotationally symmetric, things are fairly simple. Of course in a crystal we might not satisfy that condition, but if we do assume the functional
dependence of the stress on the strain is rotationally invariant, we may find
the most general possibilities by decomposing the tensors into pieces which
behave suitably under rotations. Here we are generalizing the idea that a
vector cannot be defined in terms of pure scalars, and a scalar can depend on
vectors only through a scalar product. A symmetric tensor consists of a piece,
its trace, which behaves like a scalar, and a traceless piece, called the deviatoric part, which behaves differently, as an irreducible representation6 .
6

Representations of a symmetry group are defined as vector spaces which are invariant
under the action of the symmetry, and irreducible ones are those for which no proper
subspace is closed in that fashion. For more on this, see any book on group theory for
physicists. But for representations of the rotation group a course in quantum mechanics
may be better. The traceless part of the symmetric tensor transforms like a state with
angular momentum 2.

5.4. FIELD THEORY

145

The only possible linear relationships are thus
Tr P = ‚àíŒ± Tr S;

1
1
Pij ‚àí Œ¥ij Tr P = ‚àíŒ≤ Sij ‚àí Œ¥ij Tr S .
3
3




(5.5)

These are known as the generalized Hooke‚Äôs law for an elastic solid.
The tensor stress and strain we have described here are perhaps not as familiar as some other relations met in more elementary courses. First consider
the bulk modulus B, the inverse of the ratio of the fractional decrease in
volume to the isotropic pressure which causes it. Here the stress and strain
tensors are both multiples of the identity, P = +pŒ¥ij and d~Œ∑ = ‚àícd~x, so
S = ‚àícŒ¥ij and c = p/Œ±. For a linear contraction x ‚Üí x ‚àí cx the volume will
contract by ‚àÜV = ‚àí3cV . Therefore the
p
Œ±
p
=
= .
bulk modulus B =
‚àídV /V
3c
3
Next, consider a shear, in which the displacement might be ~Œ∑ = cyeÃÇx
produced by forces ¬±Fx on the
Fx
horizontal faces shown, and ¬±Fy
on the vertical faces. To have
w
Fy
no rotation we need wFx = LFy . Fy
The shear modulus G is defined by
Fx
‚àíPxy = Fx /A = GdŒ∑x /dy = Gc,
L
where A is the area of the top face.
As
!
1
c
1 ‚àÇŒ∑x ‚àÇŒ∑y
+
= (c + 0) =
Sxy =
2 ‚àÇy
‚àÇx
2
2
and all other components are zero, we can set
Œ≤=‚àí

Pxy
= 2G.
Sxy

Finally, consider a rod being pulled by a force F stretching a distance ‚àÜL
over a length L. Hooke‚Äôs constant is k = F/‚àÜL and Young‚Äôs modulus
Y is defined by
F
‚àÜL
=Y
so Y = kL/A.
A
L
The strain S11 = ‚àÜL /L, and the stress has ‚àíP11 = Y S11 , with all other
components of the stress zero. But there may be displacement in the transverse directions. If the rod is axially symmetric we may assume S22 = S33 ,

146

CHAPTER 5. SMALL OSCILLATIONS

so
‚àí Tr P = ‚àíP11 = Y S11 = Œ± Tr S = Œ± (S11 + 2S22 ) ,



1
Y
1
Œ≤
‚àí P22 ‚àí Tr P = 0 ‚àí S11 = Œ≤ S22 ‚àí Tr S = (S22 ‚àí S11 )
3
3
3
3


Thus solving the two equations
Y S11 = Œ± (S11 + 2S22 )
Œ≤
Y
(S22 ‚àí S11 )
‚àí S11 =
3
3
gives the value of Young‚Äôs modulus
Y =

3Œ±Œ≤
2Œ± + Œ≤

and the contraction of the transverse dimentsions,
S22 =

Œ≤‚àíŒ±
S11 .
2Œ± + Œ≤

The Equation of Motion
Now that the generalized Hooke‚Äôs law provides the forces for a solid in a given
configuration, we can write down the equations of motion. The infinitesimal
volume
originally at the reference point ~r is at position ~r + ~Œ∑ (~r, t). Its mass
R
is V œÅdV , and the force on it is the sum of the volume force and the surface
R
~ r)dV , where E could be
force. We will write the volume force as F~vol = V E(~
‚àíœÅgeÃÇz for gravity or some other intensive external force. The surface force is
Fisurf = ‚àí

Z X
S

or F~ surf = ‚àí

Pij (~r)dSj

Z

~
P(~r) ¬∑ dS.

S

j

In this vector form we imply that the first index of P is matched to that
~ and summed
of F~ surf , while the second index is paired with that of dS
over. Gauss‚Äôs law tells us that this is the integral over the volume V of the
divergence, but we should take care that this divergence dots the derivative
with the second index, that is
F surf = ‚àí
i

Z X
V

j

‚àÇ
Pij (~r)dV.
‚àÇxj

5.4. FIELD THEORY

147

However, as P is symmetric, we can get away with writing
F~ surf = ‚àí

Z

~ ¬∑ P(~r)dV.
‚àá

V

Writing Hooke‚Äôs law as
1
1
P = ‚àíŒ≤S + 1I(Tr P + Œ≤ Tr S) = ‚àíŒ≤S ‚àí 1I(Œ± ‚àí Œ≤) Tr S,
3
3
(where 1I is the identity matrix 1Iij = Œ¥ij ), Newton‚Äôs second law gives
œÅ(~r)

‚àÇ 2 ~Œ∑ (~r)
~ r) ‚àí ‚àá
~ ¬∑ P(~r)
= E(~
‚àÇt2
~ Tr S(~r)
~ r) + Œ≤ ‚àá
~ ¬∑ S(~r) + Œ± ‚àí Œ≤ ‚àá
= E(~
3

where in the last term we note that the divergence contracted into the 1I
gives an ordinary gradient on the scalar function Tr S. As the strain tensor
is already given in terms of derivatives of ~Œ∑ , we have
~ ¬∑ S(~r)]j =
[‚àá

X
i

‚àÇ 1
‚àÇxi 2

‚àÇŒ∑j
‚àÇŒ∑i
+
‚àÇxj ‚àÇxi

!

1
=
2

!

‚àÇ ~
‚àá ¬∑ ~Œ∑ + ‚àá2 Œ∑j ,
‚àÇxj

~ ¬∑ S(~r) = 1 ‚àá(
~ ‚àá
~ ¬∑ ~Œ∑ ) + 1 ‚àá2 ~Œ∑ . Also Tr S = Pi ‚àÇŒ∑i /‚àÇxi = ‚àá
~ ¬∑ ~Œ∑ , so we find
or ‚àá
2
2
the equations of motion
‚àÇ 2 ~Œ∑ (~r)
~ ‚àá
~ ¬∑ ~Œ∑ ) + Œ≤ ‚àá2 ~Œ∑ .
~ r) + Œ± + Œ≤ ‚àá(
= E(~
œÅ(~r)
2
‚àÇt
3
6
2
!

(5.6)

This equation is called the Navier equation. We can rewrite this in terms of
the shear modulus G and the bulk modulus B:
‚àÇ 2 ~Œ∑ (~r)
~ r) + B + G ‚àá(
~ ‚àá
~ ¬∑ ~Œ∑ ) + G‚àá2 ~Œ∑ .
=
E(~
‚àÇt2
3


œÅ(~r)



Fluids
In discussing the motion of pieces of a solid, we specified which piece of the
material was under consideration by its ‚Äúoriginal‚Äù or ‚Äúreference‚Äù position ~r,
from which it might be displaced by a small amount ~Œ∑ (~r). So ~r is actually a
label for a particular hunk of material. This is called the material description. It is not very useful for a fluid, however, as any element of the fluid

148

CHAPTER 5. SMALL OSCILLATIONS

may flow arbitrarily far from some initial position. It is more appropriate to
consider ~r as a particular point of space, and œÅ(~r, t) or ~v (~r, t) or T (~r, t) as
the density or velocity or temperature of whatever material happens to be
at point ~r at the time t. This is called the spatial description.
If we wish to examine how some physical property of the material is changing with time, however, the physical processes which cause change do so on a
particular hunk of material. For example, the concentration of a radioactive
substance in a hunk of fluid might change due to its decay rate or due to its
diffusion, understandable physical processes, while the concentration at the
point ~r may change just because new fluid is at the point in question. In
describing the physical processes, we will need to consider the rate of change
for a given hunk of fluid. Thus we need the stream derivative, which involves
the difference of the property (say c) at the new position ~r 0 = ~r + ~v ‚àÜt at
time t + ‚àÜt and that at the old ~r, t. Thus
c(~r + ~v ‚àÜt, t + ‚àÜt) ‚àí c(~r, t)
dc
~ + ‚àÇc .
(~r, t) = lim
= ~v ¬∑ ‚àác
‚àÜt‚Üí0
dt
‚àÜt
‚àÇt
In particular, Newton‚Äôs law refers to the acceleration of a hunk of material,
so it is the stream derivative of the velocity which will be changed by the
forces acting on the fluid:
d~v
œÅ(~r)‚àÜV
= œÅ(~r)‚àÜV
dt

~ v (~r, t) + ‚àÇ~v (~r, t)
~v ¬∑ ‚àá~
‚àÇt

!

= F~ surf + F~ vol .

The forces on a fluid are different from that in a solid. The volume force
is of the same nature, the most common being F~ vol = ‚àíœÅgeÃÇz dV , and the
pressure piece of the stress, Pp = +p1I is also the same. Thus we can expect
~ ¬∑ 1Ip)dV = dV (‚àíœÅgeÃÇz ‚àí ‚àáp).
~
a force of the form F~ = (‚àíœÅgeÃÇz ‚àí ‚àá
A static
fluid can not experience a shear force. So there will be no shear component
of the stress due to a deviatoric part of the strain. But there can be stress
due to the velocity of the fluid. Of course a uniformly moving fluid will
not be stressed, but if the velocity varies from point to point, stress could
be produced. Considering first derivatives, the nine components of ‚àÇvi /‚àÇxj
~ ¬∑ ~v , an antisymmetric piece, and a traceless symmetric
have a scalar piece ‚àá
piece, each transforming differently under rotations. Thus for an isotropic
fluid the stress may have a piece
‚àÇvj
‚àÇvi
+
Pij = ‚àí¬µ
‚àÇxj ‚àÇxi

!

~ ¬∑ ~v 1I
‚àí ŒΩ‚àá

5.4. FIELD THEORY

149

in addition to the scalar piece p1I. The coefficient ¬µ is called the viscosity.
~ ¬∑ ~v may be hard to see relative to the pressure
The piece proportional to ‚àá
term, and is not usually included7
~ v , is in fact just the fractional rate of
The scalar component of ‚àÇvi /‚àÇxj , ‚àá¬∑~
change of the volume. To see that, consider the surface S which bounds the
material in question. If a small piece of that surface is moving with velocity
~ so
~v , it is adding volume to the material at a rate ~v ¬∑ dS,
I
Z
dV
~=
~ ¬∑ ~v dV.
= ~v ¬∑ dS
‚àá
dt
S
V

As the mass of the material in question is constant, d(œÅV )/dt = 0, so
dœÅ
~ ¬∑ ~v = 0.
+ œÅ‚àá
dt
This is known as the equation of continuity.
With
!
X ‚àÇvj
‚àÇvi
‚àÇvj
Pij = p1I ‚àí ¬µ
+
‚àí ŒΩ1I
‚àÇxj ‚àÇxi
j ‚àÇxj
the surface force is
F~isurf =

I
S

‚àípdSi + ¬µ

j

Ô£´

=

XI
S

!

X I ‚àÇvj
‚àÇvi
‚àÇvj
+
dSj + ŒΩ
dSi
‚àÇxj ‚àÇxi
S ‚àÇxj
j
Ô£∂

X ‚àÇ 2 vj
X ‚àÇ 2 vi
‚àÇp
Ô£≠‚àí
Ô£∏ dV
+
(¬µ
+
ŒΩ)
+¬µ
2
‚àÇxi
V
j ‚àÇxi xj
j ‚àÇxj

Z

where the last equality is by Gauss‚Äô law. This can be rewritten in vector
form:
Z 

surf
~
~ + ¬µ‚àá2~v + (¬µ + ŒΩ)‚àá(
~ ‚àá
~ ¬∑ ~v dV
F
=
‚àí‚àáp
V

Adding in F~ vol = ‚àíœÅgeÃÇz dV and setting this equal to œÅ dV d~v /dt, we find
d~v
‚àÇ~v (~r, t)
~ v (~r, t)
=
+ ~v ¬∑ ‚àá~
(5.7)
dt
‚àÇt

1~
¬µ
¬µ + ŒΩ ~ ~
r, t) + ‚àá2~v (~r, t) +
‚àá ‚àá ¬∑ ~v (~r, t) .
= ‚àígeÃÇz ‚àí ‚àáp(~
œÅ
œÅ
œÅ
7

Tietjens ([19]), following Stokes, assumes the trace of P is independent of the ‚Äúvelocity
~ ¬∑ ~v , which requires ŒΩ = ‚àí2¬µ/3. But Prandtl and Tietjens [12] drop the
of dilatation‚Äù ‚àá
~
~
‚àá(‚àá ¬∑ ~v ) term in (5.7) entirely, equivalent to taking ŒΩ = ‚àí¬µ.

150

CHAPTER 5. SMALL OSCILLATIONS

This is the Navier-Stokes equation for a viscous fluid. For an inviscid fluid,
one with a negligible viscosity, this reduces to the simpler Euler‚Äôs equation
‚àÇ~v (~r, t)
~ v (~r, t) = ‚àígeÃÇz ‚àí 1 ‚àáp(~
~ r, t).
+ ~v ¬∑ ‚àá~
‚àÇt
œÅ

(5.8)

If we assume the fluid is inviscid and incompressible, so œÅ is constant,
and also make the further simplifying assumption that we are looking at a
steady-state flow, for which ~v and p at a fixed point do not change, the partial
~ ¬∑ ~v = 0. Then Euler‚Äôs equation becomes
derivatives ‚àÇ/‚àÇt vanish, and ‚àá
~ v (~r) = ‚àígeÃÇz ‚àí 1 ‚àáp(~
~ r).
~v ¬∑ ‚àá~
œÅ

(5.9)

In a steady state situation, any function f (~r) has a stream derivative
d
f = ~v ¬∑ ‚àáf,
dt
~
so the first term in (5.9) is d~v /dt, and the second term is ‚àí‚àá(gz).
Dotting
the equation in this form into œÅ~v , we have
œÅ~v ¬∑

d~v
~ = 0 = d 1 œÅv 2 + œÅgz + p
+ œÅ~v ¬∑ ‚àá(gz) + ~v ¬∑ ‚àáp
dt
dt 2




which implies Bernoulli‚Äôs equation:
1 2
œÅv + œÅgz + p = constant along a streamline
2
where the restriction is because a streamline is the set of points in the flow
which are traversed by an element of the fluid as time goes by.

Exercises
5.1 Three springs connect two masses to each other and to immobile walls, as
shown. Find the normal modes and frequencies of oscillation, assuming the system
remains along the line shown.

a
k

a

2a
m

2k

m

k

5.4. FIELD THEORY

151

5.2 Consider the motion, in a fixed vertical plane, of a double pendulum consisting
of two masses attached to each other and to a fixed
point by inextensible strings of length L. The upper
mass has mass m1 and the lower mass m2 . This is all in
a laboratory with the ordinary gravitational forces near
the surface of the Earth.
L
a) Set up the Lagrangian for the motion, assuming the
strings stay taut.
b) Simplify the system under the approximation that the
motion involves only small deviations from equilibrium.
Put the problem in matrix form appropriate for the procedure discussed in class.
c) Find the frequencies of the normal modes of oscillation. [Hint: following exactly the steps given in class will
be complex, but the analogous procedure reversing the
order of U and T will work easily.]

m

1

L
m

2

5.3 (a) Show that if three mutually gravitating point masses are at the vertices
of an equilateral triangle which is rotating about an axis normal to the plane of
the triangle and through the center of mass, at a suitable angular velocity œâ, this
motion satisfies the equations of motion. Thus this configuration is an equilibrium
in the rotating coordinate system. Do not assume the masses are equal.
(b) Suppose that two stars of masses M1 and M2 are rotating in circular orbits
about their common center of mass. Consider a small mass m which is approximately in the equilibrium position described above (which is known as the L5
point). The mass is small enough that you can ignore its effect on the two stars.
Analyze the motion, considering specifically the stability of the equilibrium point
as a function of the ratio of the masses of the stars.
5.4 In considering the limit of a loaded string we found that in the limit a ‚Üí
0, n ‚Üí ‚àû with ` fixed, the modes with fixed integer p became a smooth excitation
y(x, t) with finite wavenumber k and frequency œâ = ck.
Now consider the limit with q := n+1‚àíp fixed as n ‚Üí ‚àû. Calculate the expression
for yj in that limit. This will not have a smooth limit, but there is nonetheless a
sense in which it can be described by a finite wavelength. Explain what this is,
and give the expression for yj in terms of this wavelength.
5.5 Consider the Navier equation ignoring the volume force, and show that
a) a uniform elastic material can support longitudinal waves. At what speed do
they travel?

152

CHAPTER 5. SMALL OSCILLATIONS

b) an uniform elastic material can support transverse waves. At what speed do
they travel?
c) Granite has a density of 2700 kg/m3 , a bulk modulus of 4 √ó 1010 N/m2 and a
shear modulus of 2.5 √ó 1010 N/m2 . If a short spike of transverse oscillations arrives
25 seconds after a similar burst of longitudinal oscillations, how far away was the
explosion that caused these waves?

Chapter 6
Hamilton‚Äôs Equations
We discussed the generalized momenta
pi =

‚àÇL(q, qÃá, t)
,
‚àÇ qÃái

and how the canonical variables {qi , pj } describe phase space. One can use
phase space rather than {qi , qÃáj } to describe the state of a system at any
moment. In this chapter we will explore the tools which stem from this
phase space approach to dynamics.

6.1

Legendre transforms

The important object for determining the motion of a system using the Lagrangian approach is not the Lagrangian itself but its variation, under arbitrary changes in the variables q and qÃá, treated as independent variables. It
is the vanishing of the variation of the action under such variations which
determines the dynamical equations. In the phase space approach, we want
to change variables qÃá ‚Üí p, where the pi are components of the gradient of
the Lagrangian with respect to the velocities. This is an example of a general
procedure called the Legendre transformation. We will discuss it in terms of
the mathematical concept of a differential form.
Because it is the variation of L which is important, we need to focus
our attention on the differential dL rather than on L itself. We first want
to give a formal definition of the differential, which we will do first for a
function f (x1 , ..., xn ) of n variables, although for the Lagrangian we will
153

154

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

later subdivide these into coordinates and velocities. We will take the space
in which x takes values to be some general n-dimensional space we call M,
which might be ordinary Euclidean space but might be something else, like
the surface of a sphere1 . Given a function f of n independent variables xi ,
the differential is
df =

n
X
‚àÇf
i=1 ‚àÇxi

dxi .

(6.1)

What does that mean? As an approximate statement, this can be regarded
as saying
df ‚âà ‚àÜf ‚â° f (xi + ‚àÜxi ) ‚àí f (xi ) =

n
X
‚àÇf
i=1 ‚àÇxi

‚àÜxi + O(‚àÜxi ‚àÜxj ),

with some statement about the ‚àÜxi being small, followed by the dropping of
the ‚Äúorder (‚àÜx)2 ‚Äù terms. Notice that df is a function not only of the point
x ‚àà M, but also of the small displacements ‚àÜxi . A very useful mathematical
language emerges if we formalize the definition of df , extending its definition
to arbitrary ‚àÜxi , even when the ‚àÜxi are not small. Of course, for large ‚àÜxi
they can no longer be thought of as the difference of two positions in M
and df no longer has the meaning of the difference of two values of f . Our
formal df is now defined as a linear function of these ‚àÜxi variables, which
we therefore consider to be a vector ~v lying in an n-dimensional vector space
Rn . Thus df : M √ó Rn ‚Üí R is a real-valued function with two arguments,
one in M and one in a vector space. The dxi which appear in (6.1) can be
thought of as operators acting on this vector space argument to extract the
i0 th component, and the action of df on the argument (x, ~v ) is df (x, ~v ) =
P
i (‚àÇf /‚àÇxi )vi .
This differential is a special case of a 1-form, as is each of the operators
dxi . All n of these dxi form a basis of 1-forms, which are more generally
œâ=

X

œâi (x)dxi ,

i

where the œâi (x) are functions on the manifold M. If there exists an ordinary
function f (x) such that œâ = df , then œâ is said to be an exact 1-form.
1

Mathematically, M is a manifold, but we will not carefully define that here. The
precise definition is available in Ref. [16].

6.1. LEGENDRE TRANSFORMS

155

Consider L(qi , vj , t), where vi = qÃái . At a given time we consider q and v
as independant variables. The differential of L on the space of coordinates
and velocities, at a fixed time, is
dL =

X ‚àÇL
i

‚àÇqi

dqi +

X ‚àÇL
i

‚àÇvi

dvi =

X ‚àÇL

‚àÇqi

i

dqi +

X

pi dvi .

i

If we wish to describe physics in phase space (qi , pi ), we are making a change
of variables from vi to the gradient with respect to these variables, pi =
‚àÇL/‚àÇvi , where we focus now on the variables being transformed and ignore
P
the fixed qi variables. So dL = i pi dvi , and the pi are functions of the vj
determined by the function L(vi ). Is there a function g(pi ) which reverses
P
the roles of v and p, for which dg = i vi dpi ? If we can invert the functions
P
p(v), we can define g(pi ) = i pi vi (pj ) ‚àí L(vi (pj )), which has a differential
dg =

X

dvi pi +

X

i

=

X

vi dpi ‚àí dL =

i

X

dvi pi +

i

X
i

vi dpi ‚àí

X

pi dvi

i

vi dpi

i

as requested, and which also determines the relationship between v and p,
vi =

‚àÇg
= vi (pj ),
‚àÇpi

giving the inverse relation to pk (v` ). This particular form of changing variables is called a Legendre transformation. In the case of interest here,
the function g is called H(qi , pj , t), the Hamiltonian,
H(qi , pj , t) =

X

pk qÃák (qi , pj , t) ‚àí L(qi , qÃáj (q` , pm , t), t).

(6.2)

k

Other examples of Legendre transformations occur in thermodynamics.
The energy change of a gas in a variable container with heat flow is sometimes
written
dE = dÃÑQ ‚àí pdV,
where dÃÑQ is not an exact differential, and the heat Q is not a well defined
system variable. Though Q is not a well defined state function, the differential
dÃÑQ is a well defined 1-form on the manifold of possible states of the system.

156

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

It is not, however, an exact 1-form, which is why Q is not a function on that
manifold. We can express dÃÑQ by defining the entropy and temperature, in
terms of which dÃÑQ = T dS, and the entropy S and temperature T are well
defined state functions. Thus the state of the gas can be described by the
two variables S and V , and changes involve an energy change
dE = T dS ‚àí pdV.
We see that the temperature is T = ‚àÇE/‚àÇS|V . If we wish to find quantities
appropriate for describing the gas as a function of T rather than S, we define
the free energy F by ‚àíF = T S ‚àí E so dF = ‚àíSdT ‚àí pdV , and we treat
F as a function F (T, V ). Alternatively, to use the pressure p rather than V ,
we define the enthalpy X(p, S) = V p + E, dX = V dp + T dS. To make both
changes, and use (T, p) to describe the state of the gas, we use the Gibbs
free energy G(T, p) = X ‚àí T S = E + V p ‚àí T S, dG = V dp ‚àí SdT . Each of
these involves a Legendre transformation starting with E(S, V ).
Unlike Q, E is a well defined property of the gas when it is in a volume
V if its entropy is S, so E = E(S, V ), and
T =

‚àÇE
,
‚àÇS V

p=

‚àÇE
.
‚àÇV S

‚àÇ 2E
‚àÇ 2E
‚àÇT
‚àÇp
=
we can conclude that
=
. We may also
‚àÇS‚àÇV
‚àÇV ‚àÇS
‚àÇV S
‚àÇS V
consider the state of the gas to be described by T and V , so

As

dE =

‚àÇE
‚àÇE
dT +
dV
‚àÇT V
‚àÇV T
"

1
p
1 ‚àÇE
1
dT +
dS = dE + dV =
T
T
T ‚àÇT V
T

‚àÇE
p+
‚àÇV T

!#

from which we can conclude
‚àÇ
‚àÇV

1 ‚àÇE
T ‚àÇT V

!

"

‚àÇ 1
=
‚àÇT T
T

‚àÇE
p+
‚àÇV T

and therefore
T

‚àÇp
‚àÇE
‚àíp=
.
‚àÇT V
‚àÇV T

!#

,
V

dV,

6.1. LEGENDRE TRANSFORMS

157

This is a useful relation in thermodynamics.
Let us get back to mechanics. Most Lagrangians we encounter have the
decomposition L = L2 +L1 +L0 into terms quadratic, linear, and independent
of velocities, as considered in 2.4.2. Then the momenta are linear in velocities,
P
pi = j Mij qÃáj + ai , or in matrix form p = M ¬∑ qÃá + a, which has the inverse
relation qÃá = M ‚àí1 ¬∑ (p ‚àí a). As H = L2 ‚àí L0 , H = 21 (p ‚àí a) ¬∑ M ‚àí1 ¬∑ (p ‚àí a) ‚àí L0 .
As a simple example, with a = 0 and a diagonal matrix M , consider spherical
coordinates, in which the kinetic energy is

p2
1
p2
m 2
T =
rÃá + r2 Œ∏Ãá2 + r2 sin2 Œ∏œÜÃá2 =
p2r + 2Œ∏ + 2 œÜ 2
.
2
2m
r
r sin Œ∏
!

Note that the generalized momenta are not normalized components of the
ordinary momentum, as pŒ∏ 6= p~ ¬∑ eÃÇŒ∏ , in fact it doesn‚Äôt even have the same
units.
The equations of motion in Hamiltonian form,
qÃák =

‚àÇH
,
‚àÇpk q,t

pÃák = ‚àí

‚àÇH
,
‚àÇqk p,t

are almost symmetric in their treatment of q and p. If we define a 2N
dimensional coordinate Œ∑ for phase space,
Œ∑i
Œ∑N +i

= qi
= pi



for 1 ‚â§ i ‚â§ N,

we can write Hamilton‚Äôs equation in terms of a particular matrix J,
2N
X

‚àÇH
Œ∑Ãáj =
Jjk
,
‚àÇŒ∑k
k=1



where J =

0
‚àí1IN √óN

1IN √óN
0



.

J is like a multidimensional version of the iœÉy which we meet in quantummechanical descriptions of spin 1/2 particles. It is real, antisymmetric, and
because J 2 = ‚àí1I, it is orthogonal. Mathematicians would say that J describes the complex structure on phase space, also called the symplectic structure.
In Section 2.1 we discussed how the Lagrangian is unchanged by a change
of generalized coordinates used to describe the physical situation. More precisely, the Lagrangian transforms as a scalar under such point transformations, taking on the same value at the same physical point, described in the

158

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

new coordinates. There is no unique set of generalized coordinates which
describes the physics. But in transforming to the Hamiltonian language,
different generalized coordinates may give different momenta and different
Hamiltonians. An nice example is given in Goldstein, a mass on a spring attached to a ‚Äúfixed point‚Äù which is on a truck moving at uniform velocity vT ,
relative to the Earth. If we use the Earth coordinate x to describe the mass,
the equilibrium position of the spring is moving in time, xeq = vT t, ignoring a
negligible initial position. Thus U = 21 k(x ‚àí vT t)2 , while T = 12 mxÃá2 as usual,
and L = 12 mxÃá2 ‚àí 21 k(x ‚àí vT t)2 , p = mxÃá, H = p2 /2m + 12 k(x ‚àí vT t)2 . The
equation of motion is pÃá = mxÃà = ‚àí‚àÇH/‚àÇx = ‚àík(x ‚àí vT t), of course. This
shows that H is not conserved, dH/dt = (p/m)dp/dt + k(xÃá ‚àí vT )(x ‚àí vT t) =
‚àí(kp/m)(x ‚àí vT t) + (kp/m ‚àí kvT )(x ‚àí vT t) = ‚àíkvT (x ‚àí vT t) 6= 0. Alternatively, dH/dt = ‚àí‚àÇL/‚àÇt = ‚àíkvT (x ‚àí vT t) 6= 0. This is not surprising; the
spring exerts a force on the truck and the truck is doing work to keep the
fixed point moving at constant velocity.
On the other hand, if we use the truck coordinate x0 = x ‚àí vT t, we
may describe the motion in this frame with T 0 = 12 mxÃá0 2 , U 0 = 21 kx0 2 , L0 =
1
mxÃá0 2 ‚àí 12 kx0 2 , giving the correct equations of motion p0 = mxÃá0 , pÃá0 = mxÃà0 =
2
‚àí‚àÇL0 /‚àÇx0 = ‚àíkx0 . With this set of coordinates, the Hamiltonian is H 0 =
xÃá0 p0 ‚àí L0 = p0 2 /2m + 21 kx0 2 , which is conserved. From the correspondence
between the two sets of variables, x0 = x ‚àí vT t, and p0 = p ‚àí mvT , we see that
the Hamiltonians at corresponding points in phase space differ, H(x, p) ‚àí
H 0 (x0 , p0 ) = (p2 ‚àí p02 )/2m = 2mvT p ‚àí 12 mvT2 6= 0.
Thus the Hamiltonian is not invariant, or a scalar, under change of generalized coordinates, or point transformations.

6.2

Variations on phase curves

In applying Hamilton‚Äôs Principle to derive Lagrange‚Äôs Equations, we considered variations in which Œ¥qi (t) was arbitrary except at the initial and final
times, but the velocities were fixed in terms of these, Œ¥ qÃái (t) = (d/dt)Œ¥qi (t).
In discussing dynamics in terms of phase space, this is not the most natural
variation, because this means that the momenta are not varied independently. Here we will show that Hamilton‚Äôs equations follow from a modified
Hamilton‚Äôs Principle, in which the momenta are freely varied.

6.3. CANONICAL TRANSFORMATIONS

159

We write the action in terms of the Hamiltonian,
I=

Z tf "X
ti

#

pi qÃái ‚àí H(qj , pj , t) dt,

i

and consider its variation under arbitrary variation of the path in phase
space, (qi (t), pi (t)). The qÃái (t) is still dqi /dt, but the momentum is varied free
of any connection to qÃái . Then
Œ¥I =

Z tf "X
ti

i

Œ¥pi

‚àÇH
qÃái ‚àí
‚àÇpi

!

‚àí

X
i

Œ¥qi

‚àÇH
pÃái +
‚àÇqi

tf

!#

dt +

X
i

,

pi Œ¥qi
ti

RP

where we have integrated the
pi dŒ¥qi /dt term by parts. Note that in order
to relate stationarity of the action to Hamilton Equations of Motion, it is
necessary only to constrain the qi (t) at the initial and final times, without
imposing any limitations on the variation of pi (t), either at the endpoints, as
we did for qi (t), or in the interior (ti , tf ), where we had previously related pi
and qÃáj . The relation between qÃái and pj emerges instead among the equations
of motion.
The qÃái seems a bit out of place in a variational principle over phase space,
and indeed we can rewrite the action integral as an integral of a 1-form over
a path in extended phase space,
I=

Z X

pi dqi ‚àí H(q, p, t)dt.

i

We will see, in section 6.6, that the first term of the integrand leads to a very
important form on phase space, and that the whole integrand is an important
1-form on extended phase space.

6.3

Canonical transformations

We have seen that it is often useful to switch from the original set of coordinates in which a problem appeared to a different set in which the problem
became simpler. We switched from cartesian to center-of-mass spherical coordinates to discuss planetary motion, for example, or from the Earth frame to
the truck frame in the example in which we found how Hamiltonians depend
on coordinate choices. In all these cases we considered a change of coordinates q ‚Üí Q, where each Qi is a function of all the qj and possibly time, but

160

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

not of the momenta or velocities. This is called a point transformation.
But we have seen that we can work in phase space where coordinates and
momenta enter together in similar ways, and we might ask ourselves what
happens if we make a change of variables on phase space, to new variables
Qi (q, p, t), Pi (q, p, t). We should not expect the Hamiltonian to be the same
either in form or in value, as we saw even for point transformations, but there
must be a new Hamiltonian K(Q, P, t) from which we can derive the correct
equations of motion,
QÃái =

‚àÇK
,
‚àÇPi

PÃái = ‚àí

‚àÇK
.
‚àÇQi

The analog of Œ∑ for our new variables will be called Œ∂, so


Œ∂=

Q
,
P


Œ∂Ãá = J ¬∑

‚àÇK
.
‚àÇŒ∂

If this exists, we say the new variables (Q, P ) are canonical variables and
the transformation (q, p) ‚Üí (Q, P ) is a canonical transformation. Note
that the functions Qi and Pi may depend on time as well as on q and p.
These new Hamiltonian equations are related to the old ones, Œ∑Ãá = J ¬∑
‚àÇH/‚àÇŒ∑, by the function which gives the new coordinates and momenta in
terms of the old, Œ∂ = Œ∂(Œ∑, t). Then
Œ∂Ãái =

‚àÇŒ∂i
dŒ∂i X ‚àÇŒ∂i
=
Œ∑Ãáj +
.
dt
‚àÇt
j ‚àÇŒ∑j

Let us write the Jacobian matrix Mij := ‚àÇŒ∂i /‚àÇŒ∑j . In general, M will not be a
constant but a function on phase space. The above relation for the velocities
now reads
Œ∂Ãá = M ¬∑ Œ∑Ãá +

‚àÇŒ∂
.
‚àÇt Œ∑

The gradients in phase space are also related,
X ‚àÇŒ∂j
‚àÇ
‚àÇ
=
,
‚àÇŒ∑i t,Œ∑
j ‚àÇŒ∑i t,Œ∑ ‚àÇŒ∂j t,Œ∂

or ‚àáŒ∑ = M T ¬∑ ‚àáŒ∂ .

Thus we have
‚àÇŒ∂
‚àÇŒ∂
‚àÇŒ∂
= M ¬∑ J ¬∑ ‚àáŒ∑ H +
= M ¬∑ J ¬∑ M T ¬∑ ‚àáŒ∂ H +
‚àÇt
‚àÇt
‚àÇt
= J ¬∑ ‚àáŒ∂ K.

Œ∂Ãá = M ¬∑ Œ∑Ãá +

6.3. CANONICAL TRANSFORMATIONS

161

Let us first consider a canonical transformation which does not depend
on time, so ‚àÇŒ∂/‚àÇt|Œ∑ = 0. We see that we can choose the new Hamiltonian to
be the same as the old, K = H, and get correct mechanics, if
M ¬∑ J ¬∑ M T = J.

(6.3)

We will require this condition even when Œ∂ does depend on t, but then we
need to revisit the question of finding K.
The condition (6.3) on M is similar to, and a generalization of, the condition for orthogonality of a matrix, OOT = 1I, which is of the same form with
J replaced by 1I. Another example of this kind of relation in physics occurs
in special relativity, where a Lorentz transformation L¬µŒΩ gives the relation
P
between two coordinates, x0¬µ = ŒΩ L¬µŒΩ xŒΩ , with xŒΩ a four dimensional vector
with x4 = ct. Then the condition which makes L a Lorentz transformation
is
1
Ô£¨0
Ô£¨
with g = Ô£¨
Ô£≠0
0
Ô£´

L ¬∑ g ¬∑ LT = g,

0
1
0
0

0 0
0 0 Ô£∑
Ô£∑
Ô£∑.
1 0 Ô£∏
0 ‚àí1
Ô£∂

The matrix g in relativity is known as the indefinite metric, and the condition
on L is known as pseudo-orthogonality. In our current discussion, however,
J is not a metric, as it is antisymmetric rather than symmetric, and the word
which describes M is symplectic.
Just as for orthogonal transformations, symplectic transformations can be
divided into those which can be generated by infinitesimal transformations
(which are connected to the identity) and those which can not. Consider a
transformation M which is almost the identity, Mij = Œ¥ij + Gij , or M =
1I + G, where  is considered some infinitesimal parameter while G is a finite
matrix. As M is symplectic, (1 + G) ¬∑ J ¬∑ (1 + GT ) = J, which tells us that
to lowest order in , GJ + JGT = 0. Comparing this to the condition for
the generator of an infinitesimal rotation, ‚Ñ¶ = ‚àí‚Ñ¶T , we see that it is similar
except for the appearence of J on opposite sides, changing orthogonality to
symplecticity. The new variables under such a canonical transformation are
Œ∂ = Œ∑ + G ¬∑ Œ∑.
The condition (6.3) for a transformation Œ∑ ‚Üí Œ∂ to be canonical does not
involve time ‚Äî each canonical transformation is a fixed map of phase-space
onto itself, and could be used at any t. We might consider a set of such

162

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

maps, one for each time, giving a time dependant map g(t) : Œ∑ ‚Üí Œ∂. Each
such map could be used to transform the trajectory of the system at any
time. In particular, consider the set of maps g(t, t0 ) which maps each point
Œ∑ at which a system can be at time t0 into the point to which it will evolve
at time t. That is, g(t, t0 ) : Œ∑(t0 ) 7‚Üí Œ∑(t). If we consider t = t0 + ‚àÜt for
infinitesimal ‚àÜt, this is an infinitesimal transformation. As Œ∂i = Œ∑i + ‚àÜtŒ∑Ãái =
P
P
Œ∑i + ‚àÜt k Jik ‚àÇH/‚àÇŒ∑k , we have Mij = ‚àÇŒ∂i /‚àÇŒ∑j = Œ¥ij + ‚àÜt k Jik ‚àÇ 2 H/‚àÇŒ∑j ‚àÇŒ∑k ,
P
so Gij = k Jik ‚àÇ 2 H/‚àÇŒ∑j ‚àÇŒ∑k ,
T

(GJ + JG )ij =

X

=

X

k`

‚àÇ 2H
‚àÇ 2H
J`j + Ji` Jjk
Jik
‚àÇŒ∑` ‚àÇŒ∑k
‚àÇŒ∑` ‚àÇŒ∑k
(Jik J`j + Ji` Jjk )

k`

!

‚àÇ 2H
.
‚àÇŒ∑` ‚àÇŒ∑k

The factor in parentheses in the last line is (‚àíJik Jj` + Ji` Jjk ) which is antisymmetric under k ‚Üî `, and as it is contracted into the second derivative,
which is symmetric under k ‚Üî `, we see that (GJ + JGT )ij = 0 and we
have an infinitesimal canonical transformation. Thus the infinitesimal flow
of phase space points by the velocity function is canonical. As compositions
of canonical transformations are also canonical2 , the map g(t, t0 ) which takes
Œ∑(t0 ) into Œ∑(t), the point it will evolve into after a finite time increment t ‚àí t0 ,
is also a canonical transformation.
Notice that the relationship ensuring Hamilton‚Äôs equations exist,
M ¬∑ J ¬∑ M T ¬∑ ‚àáŒ∂ H +

‚àÇŒ∂
= J ¬∑ ‚àáŒ∂ K,
‚àÇt

with the symplectic condition M ¬∑J¬∑M T = J, implies ‚àáŒ∂ (K‚àíH) = ‚àíJ¬∑‚àÇŒ∂/‚àÇt,
so K differs from H here. This discussion holds as long as M is symplectic,
even if it is not an infinitesimal transformation.

6.4

Poisson Brackets

Suppose I have some function f (q, p, t) on phase space and I want to ask how
f , evaluated on a dynamical system, changes as the system evolves through
2

If M = M1 ¬∑ M2 and M1 ¬∑ J ¬∑ M1T = J, M2 ¬∑ J ¬∑ M2T = J, then M ¬∑ J ¬∑ M T =
(M1 ¬∑ M2 ) ¬∑ J(¬∑M2T ¬∑ M1T ) = M1 ¬∑ (M2 ¬∑ J ¬∑ M2T ) ¬∑ M1T = M1 ¬∑ J ¬∑ M1T = J, so M is canonical.

6.4. POISSON BRACKETS

163

phase space with time. Then
X ‚àÇf
X ‚àÇf
df
‚àÇf
=
qÃái +
pÃái +
dt
‚àÇt
i ‚àÇqi
i ‚àÇpi
X ‚àÇf ‚àÇH
X ‚àÇf ‚àÇH
‚àÇf
‚àí
+
.
=
‚àÇt
i ‚àÇpi ‚àÇqi
i ‚àÇqi ‚àÇpi

(6.4)

The structure of the first two terms is that of a Poisson bracket, a bilinear
operation of functions on phase space defined by
[u, v] :=

X ‚àÇu ‚àÇv
i

‚àÇqi ‚àÇpi

‚àí

X ‚àÇu ‚àÇv
i

‚àÇpi ‚àÇqi

.

(6.5)

Thus Eq. 6.4 may be rewritten as
df
‚àÇf
= [f, H] +
.
dt
‚àÇt

(6.6)

The Poisson bracket is a fundamental property of the phase space. In
symplectic language,
[u, v] =

X ‚àÇu
ij

‚àÇŒ∑i

Jij

‚àÇv
= (‚àáŒ∑ u)T ¬∑ J ¬∑ ‚àáŒ∑ v.
‚àÇŒ∑j

(6.7)

If we describe the system in terms of a different set of canonical variables
Œ∂, we should still find the function f (t) changing at the same rate. We may
think of u and v as functions of Œ∂ as easily as of Œ∑. Really we are thinking
of u and v as functions of points in phase space, represented by u(Œ∑) = uÃÉ(Œ∂)
and we may ask whether [uÃÉ, vÃÉ]Œ∂ is the same as [u, v]Œ∑ . Using ‚àáŒ∑ = M T ¬∑ ‚àáŒ∂ ,
we have
[u, v]Œ∑ =



M T ¬∑ ‚àáŒ∂ uÃÉ

T

¬∑ J ¬∑ M T ‚àáŒ∂ vÃÉ = (‚àáŒ∂ uÃÉ)T ¬∑ M ¬∑ J ¬∑ M T ‚àáŒ∂ vÃÉ

= (‚àáŒ∂ uÃÉ)T ¬∑ J‚àáŒ∂ vÃÉ = [uÃÉ, vÃÉ]Œ∂ ,
so we see that the Poisson bracket is independent of the coordinatization
used to describe phase space, as long as it is canonical.
The Poisson bracket plays such an important role in classical mechanics,
and an even more important role in quantum mechanics, that it is worthwhile
to discuss some of its abstract properties. First of all, from the definition it
is obvious that it is antisymmetric:
[u, v] = ‚àí[v, u].

(6.8)

164

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

It is a linear operator on each function over constant linear combinations,
but is satisfies a Leibnitz rule for non-constant multiples,
[uv, w] = [u, w]v + u[v, w],

(6.9)

which follows immediately from the definition, using Leibnitz‚Äô rule on the
partial derivatives. A very special relation is the Jacobi identity,
[u, [v, w]] + [v, [w, u]] + [w, [u, v]] = 0.

(6.10)

We need to prove that this is true. To simplify the presentation, we introduce
some abbreviated notation. We use a subscript ,i to indicate partial derivative
with respect to Œ∑i , so u,i means ‚àÇu/‚àÇŒ∑i , and u,i,j means ‚àÇ(‚àÇu/‚àÇŒ∑i )/‚àÇŒ∑j . We
will assume all our functions on phase space are suitably differentiable, so
u,i,j = u,j,i . We will also use the summation convention, that any index
which appears twice in a term is assumed to be summed over3 . Then [v, w] =
v,i Jij w,j , and
[u, [v, w]] = [u, v,i Jij w,j ]
= [u, v,i ]Jij w,j + v,i Jij [u, w,j ]
= u,k Jk` v,i,` Jij w,j + v,i Jij u,k Jk` w,j,` .
In the Jacobi identity, there are two other terms like this, one with the
substitution u ‚Üí v ‚Üí w ‚Üí u and the other with u ‚Üí w ‚Üí v ‚Üí u, giving
a sum of six terms. The only ones involving second derivatives of v are the
first term above and the one found from applying u ‚Üí w ‚Üí v ‚Üí u to the
second, u,i Jij w,k Jk` v,j,` . The indices are all dummy indices, summed over, so
their names can be changed, by i ‚Üí k ‚Üí j ‚Üí ` ‚Üí i, converting this second
term to u,k Jk` w,j Jji v,`,i . Adding the original term u,k Jk` v,i,` Jij w,j , and using
v,`,i = v,i,` , gives u,k Jk` w,j (Jji +Jij )v,`,i = 0 because J is antisymmetric. Thus
the terms in the Jacobi identity involving second derivatives of v vanish, but
the same argument applies in pairs to the other terms, involving second
derivatives of u or of w, so they all vanish, and the Jacobi identity is proven.
This argument can be made more elegantly if we recognize that for each
function f on phase space, we may view [f, ¬∑] as a differential operator on
3

This convention of understood summation was invented by Einstein, who called it the
‚Äúgreatest contribution of my life‚Äù.

6.4. POISSON BRACKETS

165

functions g on phase space, mapping g ‚Üí [f, g]. Calling this operator Df ,
we see that
Df =

!

X X ‚àÇf
j

‚àÇŒ∑i

i

Jij

‚àÇ
,
‚àÇŒ∑j

which is of the general form that a differential operator has,
Df =

X

fj

j

‚àÇ
,
‚àÇŒ∑j

where fj are an arbitrary set of functions on phase space. For the Poisson
bracket, the functions fj are linear combinations of the f,j , but fj 6= f,j .
With this interpretation, [f, g] = Df g, and [h, [f, g]] = Dh Df g. Thus
[h, [f, g]] + [f, [g, h]] = [h, [f, g]] ‚àí [f, [h, g]] = Dh Df g ‚àí Df Dh g
= (Dh Df ‚àí Df Dh )g,
(6.11)
and we see that this combination of Poisson brackets involves the commutator
of differential operators. But such a commutator is always a linear differential
operator itself,
Dh Df =

X

hi

X ‚àÇfj ‚àÇ
X
‚àÇ2
‚àÇ
‚àÇ
hi
hi fj
fj
=
+
‚àÇŒ∑i ‚àÇŒ∑j
‚àÇŒ∑i ‚àÇŒ∑j
‚àÇŒ∑i ‚àÇŒ∑j
ij
ij

fj

X ‚àÇhi ‚àÇ
X
‚àÇ
‚àÇ
‚àÇ2
hi
=
fj
+
hi fj
‚àÇŒ∑j ‚àÇŒ∑i
‚àÇŒ∑j ‚àÇŒ∑i
‚àÇŒ∑i ‚àÇŒ∑j
ij
ij

ij

Df Dh =

X
ij

so in the commutator, the second derivative terms cancel, and
Dh Df ‚àí Df Dh =

X

=

X

ij

ij

hi

X ‚àÇhi ‚àÇ
‚àÇfj ‚àÇ
‚àí
fj
‚àÇŒ∑i ‚àÇŒ∑j
‚àÇŒ∑j ‚àÇŒ∑i
ij

‚àÇfj
‚àÇhj
hi
‚àí fi
‚àÇŒ∑i
‚àÇŒ∑i

!

‚àÇ
.
‚àÇŒ∑j

This is just another first order differential operator, so there are no second
derivatives of g left in (6.11). In fact, the identity tells us that this combination is
Dh Df ‚àí Df Dh = D[h,f ]

(6.12)

166

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

An antisymmetric product which obeys the Jacobi identity is what makes
a Lie algebra. Lie algebras are the infinitesimal generators of Lie groups,
or continuous groups, one example of which is the group of rotations SO(3)
which we have already considered. Notice that the ‚Äúproduct‚Äù here is not associative, [u, [v, w]] 6= [[u, v], w]. In fact, the difference [u, [v, w]] ‚àí [[u, v], w] =
[u, [v, w]] + [w, [u, v]] = ‚àí[v, [w, u]] by the Jacobi identity, so the Jacobi identity replaces the law of associativity in a Lie algebra. Lie groups play a
major role in quantum mechanics and quantum field theory, and their more
extensive study is highly recommended for any physicist. Here we will only
mention that infinitesimal rotations, represented either by the œâ‚àÜt or ‚Ñ¶‚àÜt
of Chapter 4, constitute the three dimensional Lie algebra of the rotation
group (in three dimensions).
Recall that the rate at which a function on phase space, evaluated on the
system as it evolves, changes with time is
‚àÇf
df
= ‚àí[H, f ] +
,
dt
‚àÇt

(6.13)

where H is the Hamiltonian. The function [f, g] on phase space also evolves
that way, of course, so
d[f, g]
‚àÇ[f, g]
= ‚àí[H, [f, g]] +
dt
‚àÇt
"

#

"

#

‚àÇg
‚àÇf
, g + f,
= [f, [g, H]] + [g, [H, f ]] +
‚àÇt
‚àÇt
"
!# "
!#
‚àÇg
‚àÇf
= f, ‚àí[H, g] +
+ g, [H, f ] ‚àí
‚àÇt
‚àÇt
"
# "
#
df
dg
‚àí g,
.
= f,
dt
dt
If f and g are conserved quantities, df /dt = dg/dt = 0, and we have the
important consequence that d[f, g]/dt = 0. This proves Poisson‚Äôs theorem:
The Poisson bracket of two conserved quantities is a conserved quantity.
We will now show an important theorem, known as Liouville‚Äôs theorem, that the volume of a region of phase space is invariant under canonical
transformations. This is not a volume in ordinary space, but a 2n dimenQ
sional volume, given by integrating the volume element 2n
i=1 dŒ∑i in the old

6.5. HIGHER DIFFERENTIAL FORMS

167

coordinates, and by
2n
Y

dŒ∂i = det

i=1

2n
2n
Y
‚àÇŒ∂i Y
dŒ∑i = |det M | dŒ∑i
‚àÇŒ∑j i=1
i=1

in the new, where we have used the fact that the change of variables requires
a Jacobian in the volume element. But because J = M ¬∑ J ¬∑ M T , det J =
det M det J det M T = (det M )2 det J, and J is nonsingular, so det M = ¬±1,
and the volume element is unchanged.
In statistical mechanics, we generally do not know the actual state of a
system, but know something about the probability that the system is in a
particular region of phase space. As the transformation which maps possible
values of Œ∑(t1 ) to the values into which they will evolve at time t2 is a canonical transformation, this means that the volume of a region in phase space
does not change with time, although the region itself changes. Thus the probability density, specifying the likelihood that the system is near a particular
point of phase space, is invariant as we move along with the system.

6.5

Higher Differential Forms

In section 6.1 we discussed a reinterpretation of the differential df as an
example of a more general differential 1-form, a map œâ : M √ó Rn ‚Üí R. We
saw that the {dxi } provide a basis for these forms, so the general 1-form can
P
be written as œâ = i œâi (x) dxi . The differential df gave an example. We
defined an exact 1-form as one which is a differential of some well-defined
P
function f . What is the condition for a 1-form to be exact? If œâ = œâi dxi
is df , then œâi = ‚àÇf /‚àÇxi = f,i , and
œâi,j =

‚àÇ 2f
‚àÇ 2f
‚àÇœâi
=
=
= œâj,i .
‚àÇxj
‚àÇxi ‚àÇxj
‚àÇxj ‚àÇxi

Thus one necessary condition for œâ to be exact is that the combination œâj,i ‚àí
œâi,j = 0. We will define a 2-form to be the set of these objects which must
vanish. In fact, we define a differential k-form to be a map
n
œâ (k) : M √ó R
√ó ¬∑{z
¬∑ ¬∑ √ó Rn} ‚Üí R
|
k times

which is linear in its action on each of the Rn and totally antisymmetric in
its action on the k copies, and is a smooth function of x ‚àà M. At a given

168

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

point, a basis of the k-forms is4
dxi1 ‚àß dxi2 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik :=

X

(‚àí1)P dxiP 1 ‚äó dxiP 2 ‚äó ¬∑ ¬∑ ¬∑ ‚äó dxiP k .

P ‚ààSk

For example, in three dimensions there are three independent 2-forms at a
point, dx1 ‚àßdx2 , dx1 ‚àßdx3 , and dx2 ‚àßdx3 , where dx1 ‚àßdx2 = dx1 ‚äódx2 ‚àídx2 ‚äó
dx1 , which means that, acting on ~u and ~v , dx1 ‚àß dx2 (~u, ~v ) = u1 v2 ‚àí u2 v1 . The
product ‚àß is called the wedge product or exterior product, and can be
extended to act between k1 - and k2 -forms so that it becomes an associative
distributive product. Note that this definition of a k-form agrees, for k = 1,
with our previous definition, and for k = 0 tells us a 0-form is simply a
function on M. The general expression for a k-form is
œâ (k) =

X

œâi1 ...ik (x)dxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik .

i1 <...<ik

Let us consider some examples in three dimensional Euclidean5 space E 3 ,
where there is a correspondance we can make between vectors and 1- and
2-forms. In this discussion we will not be considering how the objects change
under changes in the coordinates of E 3 , to which we will return later.
k = 0: As always, 0-forms are simply functions, f (x), x ‚àà E 3 .
P

k = 1: A 1-form œâ = œâi dxi can be thought of, or associated with, a vector
P
~
~ = ‚àáf
~ .
field A(x)
= œâi (x)eÃÇi . Note that if œâ = df , œâi = ‚àÇf /‚àÇxi , so A
k = 2: A general two form is a sum over the three independent wedge products with independent functions B12 (x), B13 (x), B23 (x). Let us extend
the definition of Bij to make it an antisymmetric matrix, so
B=

X
i<j

4

Bij dxi ‚àß dxj =

X

Bij dxi ‚äó dxj .

i,j

Some explanation of the mathematical symbols might be in order here. Sk is the group
of permutations on k objects, and (‚àí1)P is the sign of the permutation P , which is plus
or minus one if the permutation can be built from an even or an odd number, respectively,
of transpositions of two of the elements. The tensor product ‚äó of two linear operators into
a field is a linear operator which acts on the product space, or in other words a bilinear
n
n
operator with two arguments. Here dxi ‚äó dxj is an operator on R √ó R which maps the
pair of vectors (~u, ~v ) to ui vj .
5
Forms are especially useful in discussing more general manifolds, such as occur in
general relativity. Then one must distinguish between covariant and contravariant vectors,
a complication we avoid here by treating only Euclidean space.

6.5. HIGHER DIFFERENTIAL FORMS

169

As we did for the angular velocity matrix ‚Ñ¶ in (4.2), we can condense
the information in the antisymmetric matrix Bij into a vector field
~ = P Bi eÃÇi , with Bij = P ijk Bk . Note that this step requires that
B
we are working in E 3 rather than some other dimension. Thus B =
P
1P
1 P
ijk ijk Bk dxi ‚äó dxj . Also note 2
ij ijk Bij = 2
ij` ijk ij` B` = Bk .
k = 3: There is only one basis 3-form available in three dimensions, dx1 ‚àß
dx2 ‚àß dx3 . Any other 3-form is proportional to this one, though the
proportionality can be a function of {xi }. In particular dxi ‚àßdxj ‚àßdxk =
ijk dx1 ‚àß dx2 ‚àß dx3 . The most general 3-form C is simply specified by
an ordinary function C(x), which multiplies dx1 ‚àß dx2 ‚àß dx3 .
Having established, in three dimensions, a correspondance between vectors and 1- and 2-forms, and between functions and 0- and 3-forms, we can
ask to what the wedge product corresponds in terms of these vectors. If
~ and C
~ are two vectors corresponding to the 1-forms A = P Ai dxi and
A
P
C = Ci dxi , and if B = A ‚àß C, then
B=

X

Ai Cj dxi ‚àß dxj =

ij

X

X

ij

ij

(Ai Cj ‚àí Aj Ci )dxi ‚äó dxj =

Bij dxi ‚äó dxj ,

so Bij = Ai Cj ‚àí Aj Ci , and
Bk =

X
1X
1X
1X
kij Bij =
kij Ai Cj ‚àí
kij Aj Ci =
kij Ai Cj ,
2
2
2

so
~ =A
~ √ó C,
~
B
and the wedge product of two 1-forms is the cross product of their vectors.
If A is a 1-form and B is a 2-form, the wedge product C = A ‚àß B =
C(x)dx1 ‚àß dx2 ‚àß dx3 is given by
C = A‚àßB =
=

X
i`

Ai B`

XX

Ai Bjk

i j<k

|{z}

dxi ‚àß dxj ‚àß dxk
|

{z

}

jk` B` ijk dx1 ‚àß dx2 ‚àß dx3

X

jk` ijk

j<k

| {z }

dx1 ‚àß dx2 ‚àß dx3

symmetric under j ‚Üî k
X
X
1X
=
Ai B`
jk` ijk dx1 ‚àß dx2 ‚àß dx3 =
Ai B` Œ¥i` dx1 ‚àß dx2 ‚àß dx3
2 i`
jk
i`
~¬∑B
~ dx1 ‚àß dx2 ‚àß dx3 ,
= A

170

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

so we see that the wedge product of a 1-form and a 2-form gives the dot
product of their vectors.
If A and B are both 2-forms, the wedge product C = A ‚àß B must be a
4-form, but there cannot be an antisymmetric function of four dxi ‚Äôs in three
dimensions, so C = 0.
The exterior derivative
We defined the differential of a function f , which we now call a 0-form, giving
P
a 1-form df = f,i dxi . Now we want to generalize the notion of differential
so that d can act on k-forms for arbitrary k. This generalized differential
d : k-forms ‚Üí (k + 1)-forms
is called the exterior derivative. It is defined to be linear and to act on
one term in the sum over basis elements by
d (fi1 ...ik (x)dxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik ) = (dfi1 ...ik (x)) ‚àß dxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik
X
=
fi1 ...ik ,j dxj ‚àß dxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik .
j

Clearly some examples are called for, so let us look again at three dimensional Euclidean space.
k = 0: For a 0-form f , df =
~ .
vectors, df ‚àº ‚àáf

P

f,i dxi , as we defined earlier. In terms of

k = 1: For a 1-form œâ = œâi dxi , dœâ = i dœâi ‚àß dxi = ij œâi,j dxj ‚àß dxi =
P
ij (œâj,i ‚àí œâi,j ) dxi ‚äódxj , corresponding to a two form with Bij = œâj,i ‚àí
œâi,j . These Bij are exactly the things which must vanish if œâ is to be
~ with
exact. In three dimensional Euclidean space, we have a vector B
P
1 P
~ √óœâ
~ )k , so here
components Bk = 2 kij (œâj,i ‚àí œâi,j ) = kij ‚àÇi œâj = (‚àá
~
~
the exterior derivative of a 1-form gives a curl, B = ‚àá √ó œâ
~.
P

P

P

k = 2: On a two form B = i<j Bij dxi ‚àß dxj , the exterior derivative gives
P P
a 3-form C = dB = k i<j Bij,k dxk ‚àß dxi ‚àß dxj . In three-dimensional
Euclidean space, this reduces to
P

C=

XX
k` i<j

(‚àÇk ij` B` ) kij dx1 ‚àß dx2 ‚àß dx3 =

X

‚àÇk Bk dx1 ‚àß dx2 ‚àß dx3 ,

k

~ ¬∑ B,
~ and the exterior derivative on a 2-form gives the
so C(x) = ‚àá
divergence of the corresponding vector.

6.5. HIGHER DIFFERENTIAL FORMS

171

k = 3: If C is a 3-form, dC is a 4-form. In three dimensions there cannot
be any 4-forms, so dC = 0 for all such forms.
We can summarize the action of the exterior derivative in three dimensions
in this diagram:
f

d
-

~
œâ (1) ‚àº A

‚àáf

d
-

d

~
œâ (2) ‚àº B

œâ (3)

-

‚àá√óA

d

- 0

‚àá¬∑B

Now that we have d operating on all k-forms, we can ask what happens
if we apply it twice. Looking first in three dimenions, on a 0-form we get
~ ‚àº ‚àáf , and dA ‚àº ‚àá √ó A, so d2 f ‚àº ‚àá √ó ‚àáf . But the curl of a
d2 f = dA for A
~ ‚àº ‚àá√óA
~
gradient is zero, so d2 = 0 in this case. On a one form d2 A = dB, B
~
and dB ‚àº ‚àá ¬∑ B = ‚àá ¬∑ (‚àá √ó A). Now we have the divergence of a curl,
which is also zero. For higher forms in three dimensions we can only get zero
because the degree of the form would be greater than three. Thus we have
a strong hint that d2 might vanish in general. To verify this, we apply d2 to
P
œâ (k) = œâi1 ...ik dxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik . Then
dœâ =

X

X

(‚àÇj œâi1 ...ik ) dxj ‚àß dxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik

j i1 <i2 <¬∑¬∑¬∑<ik

d(dœâ) =

X

X

`j i1 <i2 <¬∑¬∑¬∑<ik

( ‚àÇ` ‚àÇj œâi1 ...ik ) dx` ‚àß dxj ‚àßdxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik
| {z }

symmetric

|

{z

}

antisymmetric

= 0.
This is a very important result. A k-form which is the exterior derivative of
some (k ‚àí 1)-form is called exact, while a k-form whose exterior derivative
vanishes is called closed, and we have just proven that all exact k-forms are
closed.
The converse is a more subtle question. In general, there are k-forms
which are closed but not exact, given by harmonic functions on the manifold
M, which form what is known as the cohomology of M. This has to do with
global properties of the space, however, and locally every closed form can be
written as an exact one.6 The precisely stated theorem, known as PoincareÃÅ‚Äôs
6

An example may be useful. In two dimensions, irrotational vortex flow can be represented by the 1-form œâ = ‚àíyr‚àí2 dx + xr‚àí2 dy, which satisfies dœâ = 0 wherever it is well
defined, but it is not well defined at the origin. Locally, we can write œâ = dŒ∏, where Œ∏ is
the polar coordinate. But Œ∏ is not, strictly speaking, a function on the plane, even on the

172

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

Lemma, is that if œâ is a closed k-form on a coordinate neighborhood U of a
manifold M , and if U is contractible to a point, then œâ is exact on U . We will
ignore the possibility of global obstructions and assume that we can write
closed k-forms in terms of an exterior derivative acting on a (k ‚àí 1)-form.
Coordinate independence of k-forms
We have introduced forms in a way which makes them appear dependent
on the coordinates xi used to describe the space M. This is not what we
want at all7 . We want to be able to describe physical quantities that have
intrinsic meaning independent of a coordinate system. If we are presented
with another set of coordinates yj describing the same physical space, the
points in this space set up a mapping, ideally an isomorphism, from one
coordinate system to the other, ~y = ~y (~x). If a function represents a physical
field independent of coordinates, the actual function f (x) used with the x
coordinates must be replaced by another function fÀú(y) when using the y
coordinates. That they both describe the physical value at a given physical
point requires f (x) = fÀú(y) when y = y(x), or more precisely8 f (x) = fÀú(y(x)).
This associated function and coordinate system is called a scalar field.
If we think of the differential df as the change in f corresponding to
an infinitesimal change dx, then clearly dfÀú is the same thing in different
coordinates, provided we understand the dyi to represent the same physical
displacement as dx does. That means
dyk =

X ‚àÇyk
j

‚àÇxj

dxj .

plane with the origin removed, because it is not single-valued. It is a well defined function
on the plane with a half axis removed, which leaves a simply-connected region, a region
with no holes. In fact, this is the general condition for the exactness of a 1-form ‚Äî a
closed 1-form on a simply connected manifold is exact.
7
Indeed, most mathematical texts will first define an abstract notion of a vector in
the tangent space as a directional derivative operator, specified by equivalence classes of
parameterized paths on M. Then 1-forms are defined as duals to these vectors. In the
first step any coordinatization of M is tied to the corresponding basis of the vector space
Rn . While this provides an elegant coordinate-independent way of defining the forms, the
abstract nature of this definition of vectors can be unsettling to a physicist.
8
More elegantly, giving the map x ‚Üí y the name œÜ, so y = œÜ(x), we can state the
relation as f = fÀú ‚ó¶ œÜ.

6.5. HIGHER DIFFERENTIAL FORMS

173

As f (x) = fÀú(y(x)) and fÀú(y) = f (x(y)), the chain rule gives
X ‚àÇ fÀú ‚àÇyj
‚àÇf
=
,
‚àÇxi
j ‚àÇyj ‚àÇxi

‚àÇ fÀú X ‚àÇf ‚àÇxi
=
,
‚àÇyj
i ‚àÇxi ‚àÇyj

so
X ‚àÇ fÀú

dfÀú =

‚àÇyk

k

X ‚àÇf

=

‚àÇxi

ij

dyk =

X ‚àÇf ‚àÇxi ‚àÇyk
ijk ‚àÇxi ‚àÇyk ‚àÇxj

Œ¥ij dxj =

X

dxj

f,i dxi = df.

i

We impose this transformation law in general on the coefficients in our kforms, to make the k-form invariant, which means that the coefficients are
covariant,
œâÃÉj =

X ‚àÇxi

‚àÇyj

i

œâi

X

k
Y
‚àÇxi

i1 ,i2 ,...,ik

`=1 ‚àÇyjl

œâÃÉj1 ...jk =

!
`

œâi1 ...ik .

Integration of k-forms
Suppose we have a k-dimensional smooth ‚Äúsurface‚Äù S in M, parameterized
by coordinates (u1 , ¬∑ ¬∑ ¬∑ , uk ). We define the integral of a k-form
œâ (k) =

X

œâi1 ...ik dxi1 ‚àß ¬∑ ¬∑ ¬∑ ‚àß dxik

i1 <...<ik

over S by
Z

œâ

(k)

=

Z

S

X

œâi1 ...ik (x(u))

i1 ,i2 ,...,ik

k
Y
‚àÇxi

!
`

`=1 ‚àÇu`

du1 du2 ¬∑ ¬∑ ¬∑ duk .

We had better give some examples. For k = 1, the ‚Äúsurface‚Äù is actually
a path Œì : u 7‚Üí x(u), and
Z X
Œì

œâi dxi =

Z umax X
umin

œâi (x(u))

‚àÇxi
du,
‚àÇu

174

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

~ ¬∑ d~r, the path integral of
which seems obvious. In vector notation this is Œì A
~
the vector A.
For k = 2,
Z
Z
‚àÇxi ‚àÇxj
œâ (2) = Bij
dudv.
‚àÇu ‚àÇv
S
R

In three dimensions, the parallelogram
which is the image of the rectangle [u, u +
du] √ó [v, v + dv] has edges (‚àÇ~x/‚àÇu)du and
(‚àÇ~x/‚àÇv)dv, which has an area equal to the
magnitude of

v
u

!

‚àÇ~x ‚àÇ~x
√ó
dudv
‚àÇu ‚àÇv

~ =
‚ÄúdS‚Äù

~
and a normal in the direction of ‚ÄúdS‚Äù.
Writing Bij in terms of the corre~ Bij = ijk Bk , so
sponding vector B,
Z

œâ

(2)

=

Z

S

S

=

Z
S

so

ijk Bk

‚àÇ~x
‚àÇu

!
i

‚àÇ~x ‚àÇ~x
√ó
‚àÇu ‚àÇv

Bk

‚àÇ~x
‚àÇv

!

dudv
j

!

dudv =

Z

~ ¬∑ dS,
~
B

S

k

~ through the surface.
œâ (2) gives the flux of B
Similarly for k = 3 in three dimensions,

R

X

ijk

‚àÇ~x
‚àÇu

!
i

‚àÇ~x
‚àÇv

!
j

‚àÇ~x
‚àÇw

!

dudvdw
k

is the volume of the parallelopiped which is the image of [u, u + du] √ó [v, v +
dv] √ó [w, w + dw]. As œâijk = œâ123 ijk , this is exactly what appears:
Z

œâ

(3)

=

Z X

Z
‚àÇxi ‚àÇxj ‚àÇxk
ijk œâ123
dudvdw = œâ123 (x)dV.
‚àÇu ‚àÇv ‚àÇw

Notice that we have only defined the integration of k-forms over submanifolds of dimension k, not over other-dimensional submanifolds. These are
the only integrals which have coordinate invariant meanings. Also note that
the integrals do not depend on how the surface is coordinatized.

6.6. THE NATURAL SYMPLECTIC 2-FORM

175

We state9 a marvelous theorem, special cases of which you have seen often
before, known as Stokes‚Äô Theorem. Let C be a k-dimensional submanifold
of M, with ‚àÇC its boundary. Let œâ be a (k ‚àí 1)-form. Then Stokes‚Äô theorem
says
Z
C

dœâ =

Z

œâ.

(6.14)

‚àÇC

This elegant jewel is actually familiar in several contexts in three dimensions. If k = 2, C is a surface, usually called S, Rbounded
by a closed path
R
~
~
Œì = ‚àÇS. If œâ is a 1-form associated with
A, then Œì œâ = Œì A ¬∑ d~`. Now dœâ is
R
R 
~ √ó A,
~ and dœâ =
~
~
~
the 2-form ‚àº ‚àá
S
S ‚àá √ó A ¬∑ dS, so we see that this Stokes‚Äô
theorem includes the one we first learned by that name. But it also includes
other possibilities. We can try k = 3, where
C = V is a volume with surface
~ ¬∑ dS,
~ while dœâ ‚àº ‚àá
~ ¬∑ B,
~
~ is a two form, R œâ = R B
S = ‚àÇV . Then if œâ ‚àº B
S
S
R
R
~
~
so V dœâ = ‚àá ¬∑ BdV , so here Stokes‚Äô general theorem gives Gauss‚Äôs theorem. Finally, we could consider k = 1, C = Œì, which has a boundary ‚àÇC
consisting of two points,Rsay A and B. Our 0-form œâ = f is a function, and
Stokes‚Äô theorem gives10 Œì df = f (B) ‚àí f (A), the ‚Äúfundamental theorem of
calculus‚Äù.

6.6

The natural symplectic 2-form

We now turn our attention back to phase space, with a set of canonical
coordinates (qi , pi ). Using these coordinates we can define a particular 1P
form œâ1 = i pi dqi . For a point transformation Qi = Qi (q1 , . . . , qn , t) we
may use the same Lagrangian, reexpressed in the new variables, of course.
Here the Qi are independent of the velocities qÃáj , so on phase space11 dQi =
9

For a proof and for a more precise explanation of its meaning, we refer the reader to
the mathematical literature. In particular [14] and [3] are advanced calculus texts which
give elementary discussions in Euclidean 3-dimensional space. A more general treatment
is (possibly???) given in [16].
10
Note that there is a direction associated with the boundary, which is induced by a
direction associated with C itself. This gives an ambiguity in what we have stated, for
example how the direction of an open surface induces a direction on Rthe closed loop which
~ ¬∑ d~`. We have not
bounds it. Changing this direction would clearly reverse the sign of A
worried about this ambiguity, but we cannot avoid noticing the appearence of the sign in
this last example.
11
i
We have not included a term ‚àÇQ
‚àÇt dt which would be necessary if we were considering
a form in the 2n + 1 dimensional extended phase space which includes time as one of its

176
P

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

j (‚àÇQi /‚àÇqj )dqj . The new velocities are given by

QÃái =

X ‚àÇQi
j

‚àÇqj

‚àÇQi
,
‚àÇt

qÃáj +

so

‚àÇ QÃái
‚àÇQi
=
.
‚àÇ qÃáj
‚àÇqj

Thus the old canonical momenta,
pi =

X ‚àÇL(Q, QÃá, t)
X
‚àÇ QÃáj
‚àÇL(q, qÃá, t)
‚àÇQj
=
=
Pj
.
‚àÇ qÃái
‚àÇ
qÃá
‚àÇq
‚àÇ QÃáj
i
i
j
j
q,t
q,t
q,t

Thus the form œâ1 may be written
œâ1 =

XX
i

Pj

j

X
‚àÇQj
Pj dQj ,
dqi =
‚àÇqi
j

so the form of œâ1 is invariant under point transformations. This is too limited, however, for our current goals of considering general canonical transformations on phase space, under which œâ1 will not be invariant. However, its
exterior derivative
X
dpi ‚àß dqi
œâ2 := dœâ1 =
i

is invariant under all canonical transformations, as we shall show momentarily. This makes it special, the natural symplectic structure on phase
space. We can reexpress œâ2 in terms of our combined coordinate notation Œ∑i ,
because
‚àí

X
i<j

Jij dŒ∑i ‚àß dŒ∑j = ‚àí

X
i

dqi ‚àß dpi =

X

dpi ‚àß dqi = œâ2 .

i

We must now show that the natural symplectic structure is indeed form
invariant under canonical transformation. Thus if Qi , Pi are a new set of
canonical coordinates, combined into Œ∂j , we expect the corresponding object
P
formed from them, œâ20 = ‚àí ij Jij dŒ∂i ‚äó dŒ∂j , to reduce to the same 2-form, œâ2 .
We first note that
X ‚àÇŒ∂i
X
dŒ∂i =
dŒ∑j =
Mij dŒ∑j ,
j ‚àÇŒ∑j
j
coordinates.

6.6. THE NATURAL SYMPLECTIC 2-FORM

177

with the same Jacobian matrix M we met in section 6.3. Thus
œâ20 = ‚àí

X

Jij dŒ∂i ‚äó dŒ∂j = ‚àí

ij

= ‚àí

X

X
ij

MT ¬∑ J ¬∑ M

k`


k`

Jij

X

Mik dŒ∑k ‚äó

k

X

Mj` dŒ∑`

`

dŒ∑k ‚äó dŒ∑` .

Things will work out if we can show M T ¬∑ J ¬∑ M = J, whereas what we know
for canonical transformations from Eq. (6.3) is that M ¬∑ J ¬∑ M T = J. We
also know M is invertible and that J 2 = ‚àí1, so if we multiply this known
equation from the left by ‚àíJ ¬∑ M ‚àí1 and from the right by J ¬∑ M , we learn
that
‚àíJ ¬∑ M ‚àí1 ¬∑ M ¬∑ J ¬∑ M T ¬∑ J ¬∑ M = ‚àíJ ¬∑ M ‚àí1 ¬∑ J ¬∑ J ¬∑ M
= J ¬∑ M ‚àí1 ¬∑ M = J
= ‚àíJ ¬∑ J ¬∑ M T ¬∑ J ¬∑ M = M T ¬∑ J ¬∑ M,
which is what we wanted to prove. Thus we have shown that the 2-form œâ2
is form-invariant under canonical transformations, and deserves its name.
One important property of the 2-form œâ2 on phase space is that it is
non-degenerate. A 2-form has two slots to insert vectors ‚Äî inserting one
leaves a 1-form. Non-degenerate means there is no non-zero vector ~v on phase
space such that œâ2 (¬∑, ~v ) = 0, that is, such that œâ2 (~u, ~v ) = 0, for all ~u on phase
space. This follows simply from the fact that the matrix Jij is non-singular.
Extended phase space
One way of looking at the evolution of a system is in phase space, where
a given system corresponds to a point moving with time, and the general
equations of motion corresponds to a velocity field. Another way is to consider extended phase space, a 2n + 1 dimensional space with coordinates
(qi , pi , t), for which a system‚Äôs motion is a path, monotone in t. By the modified Hamilton‚ÄôsRprinciple, the path of a system in this space is an extremum of
t P
the action I = tif pi dqi ‚àí H(q, p, t)dt, which is the integral of the one-form
œâ3 =

X

pi dqi ‚àí H(q, p, t)dt.

The exterior derivative of this form involves the symplectic structure, œâ2 ,
as dœâ3 = œâ2 ‚àí dH ‚àß dt. The 2-form œâ2 on phase space is nondegenerate,

178

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

and every vector in phase space is also in extended phase space. On such a
vector, on which dt gives zero, the extra term gives only something in the dt
direction, so there are still no vectors in this subspace which are annihilated
by dœâ3 . Thus there is at most one direction in extended phase space which
is annihilated by dœâ3 . But any 2-form in an odd number of dimensions
must annihilate some vector, because in a given basis it corresponds to an
antisymmetric matrix Bij , and in an odd number of dimensions det B =
det B T = det(‚àíB) = (‚àí1)2n+1 det B = ‚àí det B, so det B = 0 and the matrix
is singular, annihilating some vector Œæ. In fact, for dœâ3 this annihilated vector
Œæ is the tangent to the path the system takes through extended phase space.
One way to see this is to simply work out what dœâ3 is and apply it to
the vector Œæ, which is proportional to ~v = (qÃái , pÃái , 1). So we wish to show
dœâ3 (¬∑, ~v ) = 0. Evaluating
X

X

X

X

X

dpi ‚àß dqi (¬∑, ~v ) =
dpi dqi (~v ) ‚àí
dqi dpi (~v ) =
dpi qÃái ‚àí
dqi pÃái
dH ‚àß dt(¬∑, ~v ) = dH dt(~v ) ‚àí dt dH(~v )
!
X ‚àÇH
X ‚àÇH
‚àÇH
dqi +
dpi +
dt 1
=
‚àÇqi
‚àÇpi
‚àÇt
!
X ‚àÇH
X ‚àÇH
‚àÇH
‚àídt
qÃái
+
pÃái
+
‚àÇqi
‚àÇpi
‚àÇt
!
X ‚àÇH
X
X ‚àÇH
‚àÇH
‚àÇH
dqi +
dpi ‚àí dt
qÃái
+ pÃái
=
‚àÇqi
‚àÇpi
‚àÇqi
‚àÇpi
!
!
X
‚àÇH
‚àÇH
dœâ3 (¬∑, ~v ) =
qÃái ‚àí
dpi ‚àí pÃái +
dqi
‚àÇpi
‚àÇqi
!
X
‚àÇH
‚àÇH
+
qÃái
+ pÃái
dt
‚àÇqi
‚àÇpi
= 0

where the vanishing is due to the Hamilton equations of motion.
There is a more abstract way of understanding why dœâ3 (¬∑, ~v )
vanishes, from the modified Hamilton‚Äôs principle, which states
that if the path taken were infinitesimally varied from the physical path, there would be no change in the action. But this change
is the integral of œâ3 along a loop, forwards in time along the first
trajectory and backwards along the second. From Stokes‚Äô theorem this means the integral of dœâ3 over a surface connecting

Œ¥Œ∑

v dt

6.6. THE NATURAL SYMPLECTIC 2-FORM

179

these two paths vanishes. But this surface is a sum over infinitesimal parallelograms one side of which is ~v ‚àÜt and the other side of which12 is (Œ¥~q(t), Œ¥~p(t), 0).
As this latter vector is an arbitrary function of t, each parallelogram must independently give 0, so that its contribution to the integral, dœâ3 ((Œ¥~q, Œ¥~p, 0), ~v )‚àÜt =
0. In addition, dœâ3 (~v , ~v ) = 0, of course, so dœâ3 (¬∑, ~v ) vanishes on a complete
basis of vectors and is therefore zero.

6.6.1

Generating Functions

Consider a canonical transformation (q, p) ‚Üí (Q, P ), and the two 1-forms
P
P
œâ1 = i pi dqi and œâ10 = i Pi dQi . We have mentioned that the difference of
these will not vanish in general, but the exterior derivative of this difference,
d(œâ1 ‚àí œâ10 ) = œâ2 ‚àí œâ20 = 0, so œâ1 ‚àí œâ10 is an closed 1-form. Thus it is exact13 ,
and there must be a function F on phase space such that œâ1 ‚àí œâ10 = dF .
We call F the generating function of the canonical transformation14
If the transformation (q, p) ‚Üí (Q, P ) is such that the old q‚Äôs alone, without
information about the old p‚Äôs, do not impose any restrictions on the new Q‚Äôs,
then the dq and dQ are independent, and we can use q and Q to parameterize phase space15 . Then knowledge of the function F (q, Q) determines the
transformation, as
Ô£´

œâ1 ‚àí œâ10

=

Ô£∂

‚àÇF
‚àÇF
Ô£≠
(pi dqi ‚àí Pi dQi ) = dF =
dqi +
dQi Ô£∏
‚àÇqi Q
‚àÇQi q
i
i
X

X

=‚áí pi =

‚àÇF
,
‚àÇqi Q

‚àíPi =

‚àÇF
.
‚àÇQi q

If the canonical transformation depends on time, the function F will
also depend on time. Now if we consider the motion in extended phase
space, we know the phase trajectory that the system takes through extended
12

It is slightly more elegant to consider the path parameterized independently of time,
and consider arbitrary variations (Œ¥q, Œ¥p, Œ¥t), because the integral involved in the action,
being the integral of a 1-form, is independent of the parameterization. With this approach
we find immediately that dœâ3 (¬∑, ~v ) vanishes on all vectors.
13
We are assuming phase space is simply connected, or else we are ignoring any complications which might ensue from F not being globally well defined.
14
This is not an infinitesimal generator in the sense we have in Lie algebras ‚Äî this
generates a finite canonical transformation for finite F .
15
Note that this is the opposite extreme from a point transformation, which is a canonical
transformation for which the Q‚Äôs depend only on the q‚Äôs, independent of the p‚Äôs.

180

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

phase space is determined by Hamilton‚Äôs equations, which could be written
in any set of canonical coordinates, so in particular there is some Hamiltonian
K(Q, P, t) such that the tangent to the phase trajectory, ~v , is annihilated by
P
dœâ30 , where œâ30 = Pi dQi ‚àí K(Q, P, t)dt. Now in general knowing that two
2-forms both annihilate the same vector would not be sufficient to identify
them, but in this case we also know that restricting dœâ3 and dœâ30 to their
action on the dt = 0 subspace gives the same 2-form œâ2 . That is to say, if
~u and ~u 0 are two vectors with time components zero, we know that (dœâ3 ‚àí
dœâ30 )(~u,~u 0 ) = 0. Any vector can be expressed as a multiple of ~v and some
vector ~u with time component zero, and as both dœâ3 and dœâ30 annihilate ~v ,
we see that dœâ3 ‚àí dœâ30 vanishes on all pairs of vectors, and is therefore zero.
Thus œâ3 ‚àí œâ30 is a closed 1-form, which must be at least locally exact, and
indeed œâ3 ‚àí œâ30 = dF , where F is the generating function we found above16 .
P
P
Thus dF = pdq ‚àí P dQ + (K ‚àí H)dt, or
K=H+

‚àÇF
.
‚àÇt

The function F (q, Q, t) is what Goldstein calls F1 . The existence of F
as a function on extended phase space holds even if the Q and q are not
independent, but in this case F will need to be expressed as a function of
other coordinates. Suppose the new P ‚Äôs and the old q‚Äôs are independent, so
P
we can write F (q, P, t). Then define F2 = Qi Pi + F . Then
dF2 =

X

=

X

so
Qi =

Qi dPi +

X

Pi dQi +

Qi dPi +

X

pi dqi + (K ‚àí H)dt,

‚àÇF2
,
‚àÇPi

pi =

‚àÇF2
,
‚àÇqi

X

pi dqi ‚àí

X

Pi dQi + (K ‚àí H)dt

K(Q, P, t) = H(q, p, t) +

‚àÇF2
.
‚àÇt

The generating function can be a function of old momenta rather than the
old coordinates. Making one choice for the old coordinates and one for the
new, there are four kinds of generating functions as described by Goldstein.
P
Let us consider some examples. The function F1 = i qi Qi generates an
From its definition in that context, we found that in phase space, dF = œâ1 ‚àí œâ10 ,
which is the part of œâ3 ‚àí œâ30 not in the time direction. Thus if œâ3 ‚àí œâ30 = dF 0 for some
other function F 0 , we know dF 0 ‚àí dF = (K 0 ‚àí K)dt for some new Hamiltonian function
K 0 (Q, P, t), so this corresponds to an ambiguity in K.
16

6.6. THE NATURAL SYMPLECTIC 2-FORM

181

interchange of p and q,
Q i = pi ,

Pi = ‚àíqi ,

which leaves the Hamiltonian unchanged. We saw this clearly leaves the
form of Hamilton‚Äôs equations unchanged. An interesting generator of the
P
second type is F2 = i Œªi qi Pi , which gives Qi = Œªi qi , Pi = Œª‚àí1
i pi , a simple
change in scale of the coordinates with a corresponding inverse scale change
in momenta to allow [Qi , Pj ] = Œ¥ij to remain unchanged. This also doesn‚Äôt
change H. For Œª = 1, this is the identity transformation, for which F = 0,
of course.
Placing point transformations in this language provides another example.
For a point transformation, Qi = fi (q1 , . . . , qn , t), which is what one gets with
a generating function
F2 =

X

fi (q1 , . . . , qn , t)Pi .

i

Note that
pi =

‚àÇF2 X ‚àÇfj
=
Pj
‚àÇqi
j ‚àÇqi

is at any point ~q a linear transformation of the momenta, required to preserve
the canonical Poisson bracket, but this transformation is ~q dependent, so
~ is a function of ~q and t only, independent of p~, P~ (q, p, t) will in general
while Q
have a nontrivial dependence on coordinates as well as a linear dependence
on the old momenta.
For a harmonic oscillator, a simple scaling gives
H=



p2
k
1q
+ q2 =
k/m P 2 + Q2 ,
2m 2
2

where Q = (km)1/4 q, P = (km)‚àí1/4 p. In this form, thinking
of phase space as just some two-dimensional space, we seem to
be encouraged to consider a second canonical transformation
Q, P ‚àí‚Üí Œ∏, P, generated by F1 (Q, Œ∏), to a new, polar, coordiF1

nate system with Œ∏ = tan‚àí1 Q/P as the new coordinate, and
we might hope to have the radial coordinate related to the new
momentum, P = ‚àí ‚àÇF1 /‚àÇŒ∏|Q . As P = ‚àÇF1 /‚àÇQ|Œ∏ is also Q cot Œ∏,
we can take F1 = 21 Q2 cot Œ∏, so

P

Œ∏
Q

182

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

1
1
1
P = ‚àí Q2 (‚àí csc2 Œ∏) = Q2 (1 + P 2 /Q2 ) = (Q2 + P 2 ) = H/œâ.
2
2
2
Note as F1 is not time dependent, K = H and is independent of Œ∏, which is
therefore an ignorable coordinate, so its conjugate momentum P is conserved.
Of course
q P differs from the conserved Hamiltonian H only by the factor
œâ = k/m, so this is not unexpected. With H now linear in the new
momentum P, the conjugate coordinate Œ∏ grows linearly with time at the
fixed rate Œ∏Ãá = ‚àÇH/‚àÇP = œâ.
Infinitesimal generators, redux
Let us return to the infinitesimal canonical transformation
Œ∂i = Œ∑i + gi (Œ∑j ).
Mij = ‚àÇŒ∂i /‚àÇŒ∑j = Œ¥ij + ‚àÇgi /‚àÇŒ∑j needs to be symplectic, and so Gij = ‚àÇgi /‚àÇŒ∑j
satisfies the appropriate condition for the generator of a symplectic matrix,
G ¬∑ J = ‚àíJ ¬∑ GT . For the generator of the canonical transformation, we
need a perturbation of the generator for the identity transformation, which
can‚Äôt be in F1 form (as (q, Q) are not independent), but is easily done in F2
P
form, F2 (q, P ) = i qi Pi + G(q, P, t), with pi = ‚àÇF2 /‚àÇqi = Pi + ‚àÇG/‚àÇqi ,
Qi = ‚àÇF2 /‚àÇPi = qi + ‚àÇG/‚àÇPi , or


Œ∂=

Qi
Pi





=

qi
pi





+

0 1I
‚àí1I 0



‚àÇG/‚àÇqi
‚àÇG/‚àÇpi



= Œ∑ + J ¬∑ ‚àáG,

where we have ignored higher order terms in  in inverting the q ‚Üí Q relation
and in replacing ‚àÇG/‚àÇPi with ‚àÇG/‚àÇpi .
The change due to the infinitesimal transformation may be written in
terms of Poisson bracket with the coordinates themselves:
Œ¥Œ∑ = Œ∂ ‚àí Œ∑ = J ¬∑ ‚àáG = [Œ∑, G].
In the case of an infinitesimal transformation due to time evolution, the small
parameter can be taken to be ‚àÜt, and Œ¥Œ∑ = ‚àÜt Œ∑Ãá = ‚àÜt[H, Œ∑], so we see that
the Hamiltonian acts as the generator of time translations, in the sense that
it maps the coordinate Œ∑ of a system in phase space into the coordinates the
system will have, due to its equations of motion, at a slightly later time.
This last example encourages us to find another interpretation of canonical transformations. Up to now we have taken a passive view of the transformation, as a change of variables describing an unchanged physical situation,

6.6. THE NATURAL SYMPLECTIC 2-FORM

183

just as the passive view of a rotation is to view it as a change in the description of an unchanged physical point in terms of a rotated set of coordinates.
But rotations are also used to describe changes in the physical situation with
regards to a fixed coordinate system17 , and similarly in the case of motion
through phase space, it is natural to think of the canonical transformation
generated by the Hamiltonian as describing the actual motion of a system
through phase space rather than as a change in coordinates. More generally,
we may view a canonical transformation as a diffeomorphism18 of phase
space onto itself, g : M ‚Üí M with g(q, p) = (Q, P ).
For an infinitesimal canonical transformation, this active interpretation
gives us a small displacement Œ¥Œ∑ = [Œ∑, G] for every point Œ∑ in phase space,
so we can view G and its associated infinitesimal canonical transformation
as producing a flow on phase space. G also builds a finite transformation by
repeated application, so that we get a sequence of canonical transformations
g Œª parameterized by Œª = n‚àÜŒª. This sequence maps an initial Œ∑0 into a sequence of points g Œª Œ∑0 , each generated from the previous one by the infinitesimal transformation ‚àÜŒªG, so g Œª+‚àÜŒª Œ∑0 ‚àí g Œª Œ∑0 = ‚àÜŒª[g Œª Œ∑0 , G]. In the limit
‚àÜŒª ‚Üí 0, with n allowed to grow so that we consider a finite range of Œª, we
have a one (continuous) parameter family of transformations g Œª : M ‚Üí M,
satisfying the differential equation
i
dg Œª (Œ∑) h Œª
= g Œ∑, G .
dŒª

This differential equation defines a phase flow on phase space. If G is not
a function of Œª, this has the form of a differential equation solved by an
exponential,
g Œª (Œ∑) = eŒª[¬∑,G] Œ∑,
which means

1
g Œª (Œ∑) = Œ∑ + Œª[Œ∑, G] + Œª2 [[Œ∑, G], G] + ....
2

In the case that the generating function is the Hamiltonian, G = H, this
phase flow gives the evolution through time, Œª is t, and the velocity field on
17

We leave to Mach and others the question of whether this distinction is real.
An isomorphism g : M ‚Üí N is a 1-1 map with an image including all of N (onto),
which is therefore invertible to form g ‚àí1 : N ‚Üí M. A diffeomorphism is an isomorphism
g for which both g and g ‚àí1 are differentiable.
18

184

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

phase space is given by [Œ∑, H]. If the Hamiltonian is time independent, the
velocity field is fixed, and the solution is formally an exponential.
Let us review changes due to a generating function considered in the
passive and alternately in the active view. In the passive picture, we view Œ∑
and Œ∂ = Œ∑+Œ¥Œ∑ as alternative coordinatizations of the same physical point A in
P
phase space. For an infinitesimal generator F2 = i qi Pi + G, Œ¥Œ∑ = J‚àáG =
[Œ∑, G]. A physical scalar defined by a function u(Œ∑) changes its functional
form to uÃÉ, but not its value at a given physical point, so uÃÉ(Œ∂A ) = u(Œ∑A ). For
the Hamiltonian, there is a change in value as well, for HÃÉ or KÃÉ may not be
the same as H, even at the corresponding point,
KÃÉ(Œ∂A ) = H(Œ∑A ) +

‚àÇG
‚àÇF2
= H(Œ∑A ) + 
.
‚àÇt
‚àÇt A

Now consider an active view. Here a canonical transformation is thought
of as moving the point in phase space, and at the same time changing the
functions u ‚Üí uÃÉ, H ‚Üí KÃÉ, where we are focusing on the form of these functions, on how they depend on their arguments. We think of Œ∂ as representing
the Œ∑ coordinates of a different point B of phase space, although the coordinates Œ∑B = Œ∂A . We ask how uÃÉ and KÃÉ differ from u and H at B, evaluated
at the same values of their arguments, not at what we considered the same
physical point in the passive view. Let19
‚àÜu = uÃÉ(Œ∑B ) ‚àí u(Œ∑B ) = uÃÉ(Œ∂A ) ‚àí u(Œ∂A ) = u(Œ∑A ) ‚àí u(Œ∂A ) = ‚àíŒ¥Œ∑i
= ‚àí

X

[Œ∑i , G]

i

‚àÇu
‚àÇŒ∑i

‚àÇu
= ‚àí[u, G]
‚àÇŒ∑i

‚àÜH = KÃÉ(Œ∑B ) ‚àí H(Œ∑B ) = KÃÉ(Œ∂A ) ‚àí H(Œ∑B )
!
‚àÇG
‚àÇG
= H(Œ∑A ) + 
‚àí H(Œ∑A ) ‚àí Œ¥Œ∑ ¬∑ ‚àáŒ∑ H = 
‚àí [H, G]
‚àÇt A
‚àÇt
dG
=  .
dt
19

We differ by a sign from Goldstein in the definition of ‚àÜu.

6.6. THE NATURAL SYMPLECTIC 2-FORM

Œ∑2
A

Œ∂1 (A)
Œ∑2(A)

Œ∑2

185

Œ∑1 (B) = Œ∂1 (A)
Œ¥Œ∑
A

Œ∑ (A)
B Œ∑2 (B) = Œ∂ (A)
2

Œ∑1
Œ∑1(A) Œ∂ (A)

2
Passive view of the canonical transformation. Point A is the same
point, whether expressed in coordinates Œ∑j or Œ∂j , and scalar functions take the same value there, so
u(Œ∑A ) = uÃÉ(Œ∂A ).

2

Œ∑1
Œ∑1(A)
Active view of the transformation,
moving from point A in phase space
to point B. So Œ∑B = Œ∂A . The function uÃÉ then differs from u when evaluated on the same coordinates Œ∑.

Note that if the generator of the transformation is a conserved quantity,
the Hamiltonian is unchanged, in that it is the same function after the transformation as it was before. That is, the Hamiltonian is form invariant.
So we see that conserved quantities are generators of symmetries of the
problem, transformations which can be made without changing the Hamiltonian. We saw that the symmetry generators form a closed algebra under
Poisson bracket, and that finite symmetry transformations result from exponentiating the generators. Let us discuss the more common conserved quantities in detail, showing how they generate symmetries. We have already seen
that ignorable coordinates lead to conservation of the corresponding momentum. Now the reverse comes if we assume one of the momenta, say pI , is
conserved. Then from our discussion we know that the generator G = pI
will generate canonical transformations which are symmetries of the system.
Those transformations are
Œ¥qj = [qj , pI ] = Œ¥jI ,

Œ¥pj = [pj , pI ] = 0.

Thus the transformation just changes the one coordinate qI and leaves all
the other coordinates and all momenta unchanged. In other words, it is a
translation of qI . As the Hamiltonian is unchanged, it must be independent
of qI , and qI is an ignorable coordinate.

186

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

~ = ijk œâi rj pk
Second, consider the angular momentum component œâ
~ ¬∑L
~ produces changes
for a point particle with q = ~r. As a generator, ~œâ ¬∑ L
Œ¥r` = [r` , ijk œâi rj pk ] = ijk œâi rj [r` , pk ] = ijk œâi rj Œ¥`k = ij` œâi rj
= (~œâ √ó ~r)` ,
which is how the point moves under a rotation about the axis œâ
~ . The momentum also changes,
Œ¥p` = [p` , ijk œâi rj pk ] = ijk œâi pk [p` , rj ] = ijk œâi pk (‚àíŒ¥`j ) = ‚àíi`k œâi pk
= (~œâ √ó p~)` ,
so p~ also rotates.
By Poisson‚Äôs theorem, the set of constants of the motion is closed under Poisson bracket, and given two such generators, the bracket is also a
symmetry, so the symmetries form a Lie algebra under Poisson bracket.
~ are both symmetries, and we have just seen
For a free particle, p~ and L
that [p` , Li ] = ik` pk , a linear combination of symmetries, while of course
[pi , pj ] = 0 generates the identity transformation and is in the algebra. What
about [Li , Lj ]? As Li = ik` rk p` ,
[Li , Lj ] =
=
=
=
=
=

[ik` rk p` , Lj ]
ik` rk [p` , Lj ] + ik` [rk , Lj ]p`
‚àíik` rk j`m pm + ik` jmk rm p`
(Œ¥ij Œ¥km ‚àí Œ¥im Œ¥jk ) rk pm ‚àí (Œ¥ij Œ¥m` ‚àí Œ¥im Œ¥j` ) rm p`
(Œ¥ia Œ¥jb ‚àí Œ¥ib Œ¥ja ) ra pb
kij kab ra pb = ijk Lk .

(6.15)

~ so we do not get a new
We see that we get back the third component of L,
kind of conserved quantity, but instead we see that the algebra closes on the
space spanned by the momenta and angular momenta. We also note that
~ conserved without the third
it is impossible to have two components of L
~ does a rotation the
component also being conserved. Note also that œâ
~ ¬∑L
~ Indeed it will do so on any vector
same way on the three vectors ~r, p~, and L.
composed from ~r, and p~, rotating all of the physical system20 .
20

If there is some rotationally non-invariant property of a particle which is not built
~ = ~r √ó p~, in which case L
~ is not the
out of ~r and p~, it will not be suitably rotated by L
full angular momentum but only the orbital angular momentum. The generator of
~ is then the sum of L
~ and
a rotation of all of the physics, the full angular momentum J,
another piece, called the intrinsic spin of the particle.

6.7. HAMILTON‚ÄìJACOBI THEORY

187

The use of the Levi-Civita ijk to write L as a vector is peculiar to three
dimensions; in other dimensions d 6= 3 there is no -symbol to make a vector
out of L, but the angular momentum can always be treated as an antisymmetric tensor, Lij = xi pj ‚àí xj pi . There are D(D ‚àí 1)/2 components, and the
Lie algebra again closes
[Lij , Lk` ] = Œ¥jk Li` ‚àí Œ¥ik Lj` ‚àí Œ¥j` Lik + Œ¥i` Ljk .
We have related conserved quantities to generators of infinitesimal canonical transformation, but these infinitesimals can be integrated to produce finite transformations as well. As we mentioned earlier, from an infinitesimal
generator G we can exponentiate to form a one-parameter set of transformations
Œ∂Œ± (Œ∑) = eŒ±[¬∑,G] Œ∑
1
= 1 + Œ±[¬∑, G] + Œ±2 [[¬∑, G], G] + ... Œ∑
2
1 2
= Œ∑ + Œ±[Œ∑, G] + Œ± [[Œ∑, G], G] + ....
2




In this fashion, any Lie algebra, and in particular the Lie algebra formed
by the Poisson brackets of generators of symmetry transformations, can be
exponentiated to form a continuous group of finite transformations, called a
~
Lie Group. In the case of angular momentum, the three components of L
form a three-dimensional Lie algebra, and the exponentials of these form a
three-dimensional Lie group which is SO(3), the rotation group.

6.7

Hamilton‚ÄìJacobi Theory

We have mentioned the time dependent canonical transformation that maps
the coordinates of a system at a given fixed time t0 into their values at
a later time t. Now let us consider the reverse transformation, mapping
(q(t), p(t)) ‚Üí (Q = q0 , P = p0 ). But then QÃá = 0, PÃá = 0, and the Hamiltonian which generates these trivial equations of motion is K = 0. We denote
by S(q, P, t) the generating function of type 2 which generates this transformation. It satisfies
K = H(q, p, t) +

‚àÇS
= 0,
‚àÇt

with pi =

‚àÇS
,
‚àÇqi

188

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

so S is determined by the differential equation
!

‚àÇS
‚àÇS
,t +
= 0,
H q,
‚àÇq
‚àÇt

(6.16)

which we can think of as a partial differential equation in n + 1 variables q, t,
thinking of P as fixed and understood. If H is independent of time, we can
solve by separating the t from the q dependence, we may write S(q, P, t) =
W (q, P ) ‚àí Œ±t, where Œ± is the separation constant independent of q and t, but
not necessarily of P . We get a time-independent equation
‚àÇW
H q,
‚àÇq

!

= Œ±.

(6.17)

The function S is known as Hamilton‚Äôs principal function, while the
function W is called Hamilton‚Äôs characteristic function, and the equations (6.16) and (6.17) are both known as the Hamilton-Jacobi equation.
They are still partial differential equations in many variables, but under some
circumstances further separation of variables may be possible. We consider
first a system with one degree of freedom, with a conserved H, which we will
sometimes specify even further to the particular case of a harmonic oscillator.
Then we we treat a separable system with two degrees of freedom.
We are looking for new coordinates (Q, P ) which are time independent,
and have the differential equation for Hamilton‚Äôs principal function S(q, P, t):
‚àÇS
H q,
‚àÇq

!

+

‚àÇS
= 0.
‚àÇt

For a harmonic oscillator with H = p2 /2m + 12 kq 2 , this equation is
‚àÇS
‚àÇq

!2

+ kmq 2 + 2m

‚àÇS
= 0.
‚àÇt

(6.18)

For any conserved Hamiltonian, we can certainly find a separated solution of
the form
S = W (q, P ) ‚àí Œ±(P )t,
and then the terms in (6.16) from the Hamiltonian are independent of t. For
the harmonic oscillator, we have an ordinary differential equation,
dW
dq

!2

= 2mŒ± ‚àí kmq 2 ,

6.7. HAMILTON‚ÄìJACOBI THEORY

189

which can be easily integrated
W =

Z qq

2mŒ± ‚àí kmq 2 dq + f (Œ±)

0

Œ±
1
= f (Œ±) +
Œ∏ + sin 2Œ∏ ,
œâ
2




q

(6.19)
q

where we have made a substitution sin Œ∏ = q k/2Œ±, used œâ = k/m, and
made explicit note that the constant (in q) of integration, f (Œ±), may depend
on Œ±. For other hamiltonians, we will still have the solution to the partial
differential equation for S given by separation of variables S = W (q, P ) ‚àí Œ±t,
because H was assumed time-independent, but the integral for W may not
be doable analytically.
As S is a type 2 generating function,
p=

‚àÇF2
‚àÇW
=
.
‚àÇq
‚àÇq

For our harmonic oscillator, this gives
‚àÇW
p=
‚àÇŒ∏

,

‚àö
‚àÇq
Œ± 1 + cos 2Œ∏
= q
= 2Œ±m cos Œ∏.
‚àÇŒ∏
œâ 2Œ±/k cos Œ∏

Plugging into the Hamiltonian, we have
H = Œ±(cos2 Œ∏ + sin2 Œ∏) = Œ±,
which will always be the case when (6.17) holds.
We have not spelled out what our new momentum P is, except that it is
conserved, and we can take it to be Œ±. The new coordinate Q = ‚àÇS/‚àÇP =
‚àÇW/‚àÇŒ±|q ‚àí t. But Q is, by hypothesis, time independent, so
‚àÇW
= t + Q.
‚àÇŒ± q
For the harmonic oscillator calculation (6.19),
‚àÇW
1
1
Œ± ‚àÇŒ∏
Œ∏
= f 0 (Œ±) + (Œ∏ + sin 2Œ∏) +
(1 + cos 2Œ∏) = f 0 (Œ±) +
‚àÇŒ± q
œâ
2
œâ ‚àÇŒ± q
œâ

190

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS
q

where for the second equality we used sin Œ∏ = q k/2Œ± to evaluate
‚àíq
‚àÇŒ∏
=
‚àÇŒ± q 2Œ± cos Œ∏

s

k
1
= ‚àí tan Œ∏.
2Œ±
2Œ±

Thus Œ∏ = œât + Œ¥, for Œ¥ some constant.
As an example of a nontrivial problem with two degrees of freedom which
is nonetheless separable and therefore solvable using the Hamilton-Jacobi
method, we consider the motion of a particle of mass m attracted by Newtonian gravity to two equal masses fixed in space. For simplicity we consider
only motion in a plane containing the two masses, which we take to be at
(¬±c, 0) in cartesian coordinates x, y. If r1 and r2 are the distances from the
particle to the two fixed masses respectively, the gravitational potential is
U = ‚àíK(r1‚àí1 + r2‚àí1 ), while the kinetic energy is simple in terms of x and y,
T = 12 m(xÃá2 + yÃá 2 ). The relation between these is, of course,
r12 = (x + c)2 + y 2
r22 = (x ‚àí c)2 + y 2

y
r1

r2

Considering both the kinetic and
potential energies, the problem will
c
x
c
not separate either in
terms of (x, y) or in terms of (r1 , r2 ), but it does separate in terms of elliptical
coordinates
Œæ = r1 + r2
Œ∑ = r1 ‚àí r2
Àô
From r12 ‚àí r22 = 4cx = ŒæŒ∑ we find a fairly simple expression xÃá = (Œæ Œ∑Ãá + ŒæŒ∑)/4c.
The expression for y is more difficult, but can be found from observing that
1 2
(r + r22 ) = x2 + y 2 + c2 = (Œæ 2 + Œ∑ 2 )/4, so
2 1
Œæ 2 + Œ∑2
ŒæŒ∑
‚àí
y =
4
4c
2

or
y=

!2

‚àí c2 =

(Œæ 2 ‚àí 4c2 )(4c2 ‚àí Œ∑ 2 )
,
16c2

q
1q 2
Œæ ‚àí 4c2 4c2 ‚àí Œ∑ 2
4c

6.7. HAMILTON‚ÄìJACOBI THEORY
and

191

s

s

!

1
4c2 ‚àí Œ∑ 2
Œæ 2 ‚àí 4c2
yÃá =
Œæ ŒæÀô 2
‚àí
Œ∑
Œ∑Ãá
.
4c
Œæ ‚àí 4c2
4c2 ‚àí Œ∑ 2
Squaring, adding in the x contribution, and simplifying then shows that
Œæ 2 ‚àí Œ∑2 2
Œæ 2 ‚àí Œ∑ 2 Àô2
Œ∑Ãá
+
Œæ .
4c2 ‚àí Œ∑ 2
Œæ 2 ‚àí 4c2
!

m
T =
8

Note that there are no crossed terms ‚àù ŒæÀôŒ∑Ãá, a manifestation of the orthogonality of the curvilinear coordinates Œæ and Œ∑. The potential energy becomes
1
1
+
U = ‚àíK
r1 r2




2
2
+
= ‚àíK
Œæ+Œ∑ Œæ‚àíŒ∑

!

=

‚àí4KŒæ
.
Œæ 2 ‚àí Œ∑2

In terms of the new coordinates Œæ and Œ∑ and their conjugate momenta, we
see that

2/m  2 2
2
2
2
2
p
(Œæ
‚àí
4c
)
+
p
(4c
‚àí
Œ∑
)
‚àí
2mKŒæ
.
H= 2
Œæ
Œ∑
Œæ ‚àí Œ∑2
Then the Hamilton-Jacobi equation for Hamilton‚Äôs characteristic function is
Ô£´

2/m Ô£≠ 2
‚àÇW
(Œæ ‚àí 4c2 )
2
2
Œæ ‚àíŒ∑
‚àÇŒæ

!2

‚àÇW
+ (4c2 ‚àí Œ∑ 2 )
‚àÇŒ∑

Ô£∂

!2

‚àí 2mKŒæ Ô£∏ = Œ±,

or
‚àÇW
(Œæ ‚àí 4c )
‚àÇŒæ
2

2

!2

1
‚àí 2mKŒæ ‚àí mŒ±Œæ 2
2

‚àÇW
+(4c ‚àí Œ∑ )
‚àÇŒ∑
2

!2

2

1
+ Œ±mŒ∑ 2 = 0.
2

If W is to separate into a Œæ dependent piece and an Œ∑ dependent one, the
first line will depend only on Œæ, and the second only on Œ∑, so they must each
be constant, with W (Œæ, Œ∑) = WŒæ (Œæ) + WŒ∑ (Œ∑), and
dWŒæ (Œæ)
(Œæ ‚àí 4c )
dŒæ
2

2

!2

1
‚àí 2mKŒæ ‚àí Œ±mŒæ 2 = Œ≤
2

dWŒ∑ (Œ∑)
(4c ‚àí Œ∑ )
dŒ∑
2

2

!2

1
+ Œ±mŒ∑ 2 = ‚àíŒ≤.
2

These are now reduced to integrals for Wi , which can in fact be integrated
to give an explicit expression in terms of elliptic integrals.

192

6.8

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

Action-Angle Variables

Consider again a general system with one degree of freedom and a conserved
Hamiltonian. Suppose the system undergoes periodic behavior, with p(t)
and qÃá(t) periodic with period œÑ . We don‚Äôt require q itself to be periodic as
it might be an angular variable which might not return to the same value
when the system returns to the same physical point, as, for example, the
angle which describes a rotation.
If we define an integral over one full period,
1 Z t+œÑ
p dq,
J(t) =
2œÄ t
it will be time independent. As p = ‚àÇW/‚àÇq = p(q, Œ±), the integral
can be
R
defined without reference to time, just as the integral 2œÄJ = pdq over one
orbit of q, holding Œ± fixed. Then J becomes a function of Œ± alone, and if we
assume this function to be invertible, H = Œ± = Œ±(J). We can take J to be
our canonical momentum P . Using Hamilton‚Äôs Principal Function S as the
generator, we find Q = ‚àÇS/‚àÇJ = ‚àÇW (q, J)/‚àÇJ ‚àí(dŒ±/dJ)t. Alternatively, we
might use Hamilton‚Äôs Characteristic Function W by itself as the generator,
to define the conjugate variable œÜ = ‚àÇW (q, J)/‚àÇJ, which is simply related
to Q = œÜ ‚àí (dŒ±/dJ)t. Note that œÜ and Q are both canonically conjugate
to J, differing at any instant only by a function of J. As the HamiltonJacobi Q is time independent, we see that œÜÃá = dŒ±/dJ = dH/dJ = œâ(J),
which is a constant, because while it is a function of J, J is a constant in
time. We could also derive œÜÃá from Hamilton‚Äôs equations considering W as a
genenerator, for W is time independent, the therefore the new Hamiltonian
is unchanged, and the equation of motion for œÜ is simply œÜÃá = ‚àÇH/‚àÇJ. Either
way, we have œÜ = œât + Œ¥. The coordinates (J, œÜ) are called action-angle
variables. Consider the change in œÜ during one cycle.
‚àÜœÜ =

I

I
‚àÇœÜ
dq =
‚àÇq

‚àÇ ‚àÇW
‚àÇq ‚àÇJ

!

dq =

d I
d
pdq =
2œÄJ = 2œÄ.
dJ
dJ

Thus we see that in one period œÑ , ‚àÜœÜ = 2œÄ = œâœÑ , so œâ = 1/œÑ .
For our harmonic oscillator, of course,
2œÄJ =

I

pdq =

‚àö

s

2Œ±m

2Œ± Z 2œÄ
2Œ±œÄ
cos2 Œ∏dŒ∏ = q
k 0
k/m

6.8. ACTION-ANGLE VARIABLES

193

q

so J is just a constant 1/ k/m times the old canonical momentum Œ±, and
q

q

thus its conjugate œÜ = k/m(t + Œ≤), so œâ = k/m as we expect. The
important thing here is that ‚àÜœÜ = 2œÄ, even if the problem itself is not
solvable.

Exercises
6.1 In Exercise 2.7, we discussed the connection between two Lagrangians, L1 and
L2 , which differed by a total time derivative of a function on extended configuration
space,
d
L1 ({qi }, {qÃáj }, t) = L2 ({qi }, {qÃáj }, t) + Œ¶(q1 , ..., qn , t).
dt
You found that these gave the same equations of motion, but differing momenta
(1)
(2)
pi and pi . Find the relationship between the two Hamiltonians, H1 and H2 ,
and show that these lead to equivalent equations of motion.
6.2 A uniform static magnetic field can be described by a static vector potential
~ = 1B
~ √ó ~r. A particle of mass m and charge q moves under the influence of this
A
2
field.
(a) Find the Hamiltonian, using inertial cartesian coordinates.
(b) Find the Hamiltonian, using coordinates of a rotating system with angular
~
velocity œâ
~ = ‚àíq B/2mc.
6.3 Consider a symmetric top with one point on the symmetry axis fixed in
space, as we did at the end of chapter 4. Write the Hamiltonian for the top.
Noting the cyclic (ignorable) coordinates, explain how this becomes an effective
one-dimensional system.
6.4 (a) Show that a particle under a central force with an attractive potential
inversely proportional to the distance squared has a conserved quantity D = 12 ~r ¬∑
p~ ‚àí Ht.
(b) Show that the infinitesimal transformation generated by G := 21 ~r ¬∑ p~ scales
~ = (1 +  )~r, P~ = (1 ‚àí  )~
~r and p~ by opposite infinitesimal amounts, Q
2
2 p, or for a
‚àí1
~
~
finite transformation Q = Œª~r, P = Œª p~. Show that if we describe the motion in
terms of a scaled time T = Œª2 t, the equations of motion are invariant under this
~ P~ , T ).
combined transformation (~r, p~, t) ‚Üí (Q,
6.5 We saw that the Poisson bracket associates with every differentiable function
f on phase space a differential operator Df := [f, ¬∑] which acts on functions g

194

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

on phase space by Df g = [f, g]. We also saw that every differential operator is
associated with a vector, which in a particular coordinate system has components
fi , where
X
‚àÇ
Df =
fi
.
‚àÇŒ∑i
A 1-form acts on such a vector by
dxj (Df ) = fj .
Show that for the natural symplectic structure œâ2 , acting on the differential operator coming from the Poisson bracket as its first argument,
œâ2 (Df , ¬∑) = df,
which indicates the connection between œâ2 and the Poisson bracket.
6.6 Give a complete discussion of the relation of forms in cartesian coordinates
in four dimensions to functions, vector fields, and antisymmetric matrix (tensor)
fields, and what wedge products and exterior derivatives of the forms correspond
to in each case. This discussion should parallel what is done in section 6.5 for
three dimensions. [Note that two different antisymmetric tensors, B¬µŒΩ and BÃÉ¬µŒΩ =
1P
œÅœÉ ¬µŒΩœÅœÉ BœÅœÉ , can be related to the same 2-form, in differing fashions. They
2
are related to each other with the four dimensional jk`m , which you will need to
define, and are called duals of each other. Using one fashion, the two different
2-forms associated with these two matrices are also called duals.
(b) Let F¬µŒΩ be a 4 √ó 4 matrix defined over a four dimensional space (x, y, z, ict),
with matrix elements Fjk = jk` B` , for j, k, ` each 1, 2, 3, and F4j = iEj = ‚àíFj4 .
Show that the statement that F corresponds, by one of the two fashions, to a
closed 2-form F, constitutes two of Maxwell‚Äôs equations, and explain how this
implies that 2-form is the exterior derivative of a 1-form, and what that 1-form is
in terms of electromagnetic theory described in 3-dimensional language.
(c) Find the 3-form associated with the exterior derivative of the 2-form dual to F,
and show that it is associated with the 4-vector charge current density J = (~j, icœÅ),
where ~j is the usual current density and œÅ the usual charge density.
6.7 Consider the following differential forms:
A = y dx + x dy + dz
B = y 2 dx + x2 dy + dz
C = xy(y ‚àí x) dx ‚àß dy + y(y ‚àí 1) dx ‚àß dz + x(x ‚àí 1) dy ‚àß dz
D = 2(x ‚àí y) dx ‚àß dy ‚àß dz
E = 2(x ‚àí y) dx ‚àß dy

6.8. ACTION-ANGLE VARIABLES

195

Find as many relations as you can, expressible without coordinates, among these
forms. Consider using the exterior derivative and the wedge product.
6.8 Consider the unusual Hamiltonian for a one-dimensional problem
H = œâ(x2 + 1)p,
where œâ is a constant.
(a) Find the equations of motion, and solve for x(t).
1

(b) Consider the transformation to new phase-space variables P = Œ±p 2 , Q =
1
Œ≤xp 2 . Find the conditions necessary for this to be a canonical transformation, and find a generating function F (x, Q) for this transformation.
(c) What is the Hamiltonian in the new coordinates?
6.9 For the central force problem with an attractive coulomb law,
H=

p2
K
‚àí ,
2m
r

we saw that the Runge-Lenz vector
~ = p~ √ó L
~ ‚àí mK ~r
A
|r|
~ Find the Poisson brackets of Ai with Lj , which you
is a conserved quantity, as is L.
should be able to do without detailed calculation, and also of Ai with Aj . [Hint:
it might be useful to first show that [pi , f (~r)] = ‚àí‚àÇi f for any function of the
~ independently,
coordinates only. It will be useful to evaluate the two terms in A
and to use the Jacobi identity judiciously.]
6.10 a) Argue that [H, Li ] = [H, Ai ] = 0. Show that for any differentiable
function R on phase space and any differentiable function f of one variable, if
[H, R] = 0 then [f (H), R] = 0.
‚àö
b) Scale the Ai to form new conserved quantities Mi = Ai / ‚àí2mH. Given the
~ M
~.
results of (a), find the simple algebra satisfied by the six generators L,
c) Define Lij = ijk Lk , for i, j, k = 1, 2, 3, and Li4 = ‚àíL4i = Mi . Show that in
this language, with ¬µ, ŒΩ, œÅ, œÉ = 1, ..., 4,
[L¬µŒΩ , LœÅœÉ ] = ‚àíŒ¥ŒΩœÅ L¬µœÉ + Œ¥¬µœÅ LŒΩœÉ + Œ¥ŒΩœÉ L¬µœÅ ‚àí Œ¥¬µœÉ LŒΩœÅ .
What does this imply about the symmetry group of the Hydrogen atom?

196

CHAPTER 6. HAMILTON‚ÄôS EQUATIONS

6.11 Consider a particle of mass m and charge q in the field of a fixed electric
dipole with dipole moment21 p. In spherical coordinates, the potential energy is
given by
1 qp
U (~r) =
cos Œ∏.
4œÄ0 r2
a) Write the Hamiltonian. It is independent of t and œÜ. As a consequence, there
are two conserved quantities. What are they?
b) Find the partial differential equation in t, r, Œ∏, and œÜ satisfied by Hamilton‚Äôs
principal function S, and the partial differential equation in r, Œ∏, and œÜ satisfied
by Hamilton‚Äôs characteristic function W.
c) Assume W can be broken up into r-dependent, Œ∏-dependent, and œÜ-dependent
pieces:
W (r, Œ∏, œÜ, Pi ) = Wr (r, Pi ) + WŒ∏ (Œ∏, Pi ) + WœÜ (œÜ, Pi ).
Find ordinary differential equations for Wr , WŒ∏ and WœÜ .

21

Please note that q and p are the charge and dipole moments here, not coordinates or
momenta of the particle.

Chapter 7
Perturbation Theory
The class of problems in classical mechanics which are amenable to exact
solution is quite limited, but many interesting physical problems differ from
such a solvable problem by corrections which may be considered small. One
example is planetary motion, which can be treated as a perturbation on a
problem in which the planets do not interact with each other, and the forces
with the Sun are purely Newtonian forces between point particles. Another
example occurs if we wish to find the first corrections to the linear small
oscillation approximation to motion about a stable equilibrium point. The
best starting point is an integrable system, for which we can find sufficient
integrals of the motion to give the problem a simple solution in terms of
action-angle variables as the canonical coordinates on phase space. One then
phrases the full problem in such a way that the perturbations due to the
extra interactions beyond the integrable forces are kept as small as possible.
We first examine the solvable starting point.

7.1

Integrable systems

An integral of the motion for a hamiltonian system is a function F on
phase space M for which the Poisson bracket with H vanishes, [F, H] = 0.
More generally, a set of functions on phase space is said to be in involution if
all their pairwise Poisson brackets vanish. The systems we shall consider are
integrable systems in the sense that there exists one integral of the motion
for each degree of freedom, and these are in involution and independent.
Thus on the 2n-dimensional manifold of phase space, there are n functions
197

198

CHAPTER 7. PERTURBATION THEORY

Fi for which [Fi , Fj ] = 0, and the Fi are independent, so the dFi are linearly
independent at each point Œ∑ ‚àà M. We will assume the first of these is the
Hamiltonian. As each of the Fi is a conserved quantity, the motion of the
system is confined to a submanifold of phase space determined by the initial
values of these invariants fi = Fi (q(0), p(0)):
Mf~ = {Œ∑ : Fi (Œ∑) = fi for i = 1, . . . , n,

connected},

where if the space defined by Fi (Œ∑) = fi is disconnnected, Mf~ is only the
piece in which the system starts. The differential operators DFi = [Fi , ¬∑]
correspond to vectors tangent to the manifold Mf~, because acting on each
of the Fj functions DFi vanishes, as the F ‚Äôs are in involution.
These
differential operators also commute with one another, because as we saw in
(6.12),
DFi DFj ‚àí DFj DFi = D[Fi ,Fj ] = 0.
P

P

They are also linearly independent, for if
Œ±i DFi = 0,
Œ±i DFi Œ∑j =
P
P
0 = [ Œ±i Fi , Œ∑j ], which means that
Œ±i Fi is a constant on phase space,
and that would contradict the assumed independence of the Fi . Thus the
DFi are n commuting independent differential operators corresponding to
the generators Fi of an Abelian1 group of displacements on Mf~. A given
reference point Œ∑0 ‚àà M is mapped by the canonical transformation generator
P
ti Fi into some other point g~t(Œ∑0 ) ‚àà Mf~. Poisson‚Äôs Theorem shows the
volume covered diverges with ~t, so if the manifold Mf~ is compact, there must
be many values of ~t for which g~t(Œ∑0 ) = Œ∑0 . These elements form a discrete
Abelian subgroup, and therefore a lattice in Rn . It has n independent lattice
vectors, and a unit cell which is in 1-1 correspondence with Mf~. Let these
basis vectors be ~e1 , . . . , ~en . These are the edges of the unit cell in Rn , the
P
interior of which is a linear combination ai~ei where each of the ai ‚àà [0, 1).
We therefore have a diffeomorphism between this unit cell and Mf~, which
induces coordinates on Mf~. Because these are periodic, we scale the ai to
~ given by
new coordinates œÜi = 2œÄai , so each point of Mf~ is labelled by œÜ,
P
the ~t = œÜk~ek /2œÄ for which g~t(Œ∑0 ) = Œ∑. Notice each œÜi is a coordinate on a
circle, with œÜi = 0 representing the same point as œÜi = 2œÄ, so the manifold
Mf~ is diffeomorphic to an n dimensional torus T n = (S 1 )n .
1

An Abelian group is one whose elements all commute with each other, A B = B A
for all A, B ‚àà G. When Abelian group elements are expressed as exponentials of a set of
independent infinitesimal generators, group multiplication corresponds to addition of the
parameters multiplying the generators in the exponent.

7.1. INTEGRABLE SYSTEMS

199

Under an infinitesimal generator
Œ¥ti Fi , a point of Mf~ is translated
P
by Œ¥Œ∑ =
Œ¥ti [Œ∑, Fi ]. This is true for any choice of the coordinates Œ∑, in
particular it can be applied to the œÜj , so
P

Œ¥œÜj =

X

Œ¥ti [œÜj , Fi ],

i

where we have already expressed
Œ¥~t =

X

Œ¥œÜk~ek /2œÄ.

k

We see that the Poisson bracket is the inverse of the matrix Aji given by
the j‚Äôth coordinate of the i‚Äôth basis vector
Aji =

1
(~ei )j ,
2œÄ

Œ¥~t = A ¬∑ Œ¥œÜ,



[œÜj , Fi ] = A‚àí1


ji

.

As the Hamiltonian H = F1 corresponds to the generator with ~t = (1, 0, . . . , 0),
an infinitesimal time translation generated by Œ¥tH produces a change Œ¥œÜi =
(A‚àí1 )i1 Œ¥t = œâi Œ¥t, for some vector œâ
~ which is determined by the ~ei . Note that
the periodicities ~ei may depend on the values of the integrals of the motion,
so œâ
~ does as well, and we have
~
dœÜ
=œâ
~ (f~).
dt
~ are not conjugate to the integrals of the motion Fi ,
The angle variables œÜ
but rather to combinations of them,
Ii =
for then

1
~ei (f~) ¬∑ F~ ,
2œÄ



1  ~
~ei (f ) [œÜj , Fk ] = Aki A‚àí1
= Œ¥ij .
k
jk
2œÄ
These Ii are the action variables, which are functions of the original set Fj of
integrals of the motion, and therefore are themselves integrals of the motion.
In action-angle variables the motion is very simple, with I~ constant and
~Àô = œâ
œÜ
~ = constant. This is called conditionally periodic motion, and the
œâi are called the frequencies. If all the ratios of the œâi ‚Äôs are rational, the

[œÜj , Ii ] =

200

CHAPTER 7. PERTURBATION THEORY

motion will be truly periodic, with a period the least common multiple of
the individual periods 2œÄ/œâi . More generally, there may be some relations
X

ki œâi = 0

i

for integer values ki . Each of these is called a relation among the frequencies. If there are no such relations the frequencies are said to be independent frequencies.
In the space of possible values of œâ
~ , the subspace of values for which
the frequencies are independent is surely dense. In fact, most such points
have independent frequencies. We should be able to say then that most of
the invariant tori Mf~ have independent frequencies if the mapping œâ
~ (f~) is
one-to-one. This condition is
!
!
‚àÇ~œâ
‚àÇ~œâ
6= 0, or equivalently det
6= 0.
det
‚àÇ I~
‚àÇ f~
When this condition holds the system is called a nondegenerate system.
As œâi = ‚àÇH/‚àÇIi , this condition can also be written as det ‚àÇ 2 H/‚àÇIi ‚àÇIj 6= 0.
Consider a function g on Mf~. We define two averages of this function.
~ 0 and averaging
One is the time average we get starting at a particular point œÜ
over over an infinitely long time,
Z T

~0 + œâ
~ 0 ) = lim 1
g(œÜ
~ t)dt.
hgit (œÜ
T ‚Üí‚àû T 0
We may also define the average over phase space, that is, over all values of
~ describing the submanifold M ~,
œÜ
f
‚àín

hgiMf~ = (2œÄ)

Z 2œÄ

...

0

Z 2œÄ
0

~
g(œÜ)dœÜ
1 . . . dœÜn ,

where we have used the simple measure dœÜ1 . . . dœÜn on the space Mf~. Then
an important theorem states that, if the frequencies are independent, and
g is a continuous function on Mf~, the time and space averages of g are
the same. Note any such function g can be expanded in a Fourier series,
~ = P~ n g~ ei~k¬∑œÜ~ , with hgiM = g~ , while
g(œÜ)
0
k
k‚ààZ
f~
hgit =

1ZTX
~ ~
~
g~k eik¬∑œÜ0 +ik¬∑~œât dt
T ‚Üí‚àû T 0
~
lim

k

= g~0 +

X
~k6=~0

~ ~

1 Z T i~k¬∑~œât
e
dt = g~0 ,
T ‚Üí‚àû T 0

g~k eik¬∑œÜ0 lim

7.1. INTEGRABLE SYSTEMS

201

because
~

1 Z T i~k¬∑~œât
1 eik¬∑~œâT ‚àí 1
e
= lim
= 0,
T ‚Üí‚àû T 0
T ‚Üí‚àû T
i~k ¬∑ œâ
~
lim

as long as the denominator does not vanish. It is this requirement that ~k ¬∑~œâ 6=
0 for all nonzero ~k ‚àà Zn , which requires the frequencies to be independent.
As an important corrolary of this theorem, when it holds the trajectory is
dense in Mf~, and uniformly distributed, in the sense that the time spent in
each specified volume of Mf~ is proportional to that volume, independent of
the position or shape of that volume. This leads to the notion of ergodicity,
that every state of a system left for a long time will have average values of
various properties the same as the average of all possible states with the same
conserved values.
If instead of independence we have relations among the frequencies, these
relations, each given by a ~k ‚àà Zn , form a subgroup of Zn (an additive group of
translations by integers along each of the axes). Each such ~k gives a constant
~ Each independent relation among the frequencies thereof the motion, ~k ¬∑ œÜ.
fore restricts the dimensionality of the motion by an additional dimension,
so if the subgroup is generated by r such independent relations, the motion
is restricted to a manifold of reduced dimension n ‚àí r, and the motion on
this reduced torus T n‚àír is conditionally periodic with n ‚àí r independent
frequencies. The theorem and corrolaries just discussed then apply to this
reduced invariant torus, but not to the whole n-dimensional torus with which
we started. In particular, hgit (œÜ0 ) can depend on œÜ0 as it varies from one
submanifold T n‚àír to another, but not along paths on the same submanifold.
While having relations among the frequencies for arbitrary values of the
integrals of the motion might seem a special case, unlikely to happen, there
are important examples where they do occur. We saw that for Keplerian motion, there were five invariant functions on the six-dimensional phase space of
the relative coordinate, because energy, angular momentum, and the RungeLenz are all conserved, giving five independent conserved quantities. The
locus of points in the six dimensional space with these five functions taking
on assigned values is therefore one-dimensional, that is, a curve on the three
dimensional invariant torus. This is responsible for the stange fact that the
oscillations in r have the same period as the cycles in œÜ. Even for other
central force laws, for which there is no equivalent to the Runge-Lenz vector,
there are still four conserved quantities, so there must still be one relation,

202

CHAPTER 7. PERTURBATION THEORY

which turns out to be that the periods of motion in Œ∏ and œÜ are the same2 .
If the system is nondegenerate, for typical I~ the œâi ‚Äôs will have no relations
and the invariant torus will be densely filled by the motion of the system.
Therefore the invariant tori are uniquely defined, although the choices of
action and angle variables is not. In the degenerate case the motion of
the system does not fill the n dimensional invariant torus, so it need not be
uniquely defined. This is what happens, for example, for the two dimensional
harmonic oscillator or for the Kepler problem.
This discussion has been somewhat abstract, so it might be well to give
some examples. We will consider
‚Ä¢ the pendulum
‚Ä¢ the two-dimensional isotropic harmonic oscillator
‚Ä¢ the three dimensional isotropic anharmonic oscillator
The Pendulum
The simple pendulum is a mass connected by a fixed length massless rod to
a frictionless joint, which we take to be at the origin, hanging in a uniform
gravitational field. The generalized coordinates may be
taken to be the angle Œ∏ which the rod makes with the downward vertical, and the azimuthal angle œÜ. If ` is the length
of the rod, U = ‚àímg` cos Œ∏, and as shown in section 2.2.1 or

section 3.1.2, the kinetic energy is T = 21 m`2 Œ∏Ãá2 + sin2 Œ∏œÜÃá2 .
So the lagrangian,
Œ∏


1
L = m`2 Œ∏Ãá2 + sin2 Œ∏œÜÃá2 + mg` cos Œ∏
2

is time independent and has an ignorable coordinate œÜ,

œÜ

~ in the z direction, which
The usual treatment for spherical symmetry is to choose L
sets z and pz to zero and reduces our problem to a four-dimensional phase space with two
integrals of the motion, H and Lz . But without making that choice, we do know that the
motion will be resticted to some plane, so ax x + ay y + az z = 0 for some fixed coefficients
ax , ay , az , and in spherical coordinates r(az cos Œ∏ + ax sin Œ∏ cos œÜ + ay sin Œ∏ sin œÜ) = 0. The
r dependence factors out, and thus œÜ can be solved for, in terms of Œ∏, and must have the
same period.
2

7.1. INTEGRABLE SYSTEMS

203

so pœÜ = m`2 sin2 Œ∏œÜÃá is conserved, and so is H. As pŒ∏ = m`2 Œ∏Ãá, the Hamiltonian
is
!
2
p
1
œÜ
H=
p2 +
‚àí mg` cos Œ∏.
2m`2 Œ∏ sin2 Œ∏
In the four-dimensional phase space one coordinate, pœÜ , is fixed, and the equation H(Œ∏, œÜ, pŒ∏ ) = E gives a two-dimensional surface in the three-dimensional
space which remains. Let us draw this in cylindrical coordiates with radial
coordinate Œ∏, angular coordinate œÜ,
and z coordinate pŒ∏ . Thus the motion will be restricted to the invariant torus shown. The generators
F2 = pœÜ and F1 = H generate motions along the torus as shown, with
pœÜ generating changes in œÜ, leaving
Œ∏ and pŒ∏ fixed. Thus a point moves
as on the blue path shown, looking
like a line of latitude. The change
in œÜ generated by g (0,t2 ) is just t2 ,
so we may take œÜ = œÜ2 of the last section. H generates the dynamical motion
of the system,
Œ∏Ãá =

pŒ∏
‚àÇH
=
,
‚àÇpŒ∏
m`2

œÜÃá =

‚àÇH
pœÜ
=
,
2
‚àÇpœÜ
m` sin2 Œ∏

p2 cos Œ∏
‚àÇH
= œÜ2 3 ‚àí mg` sin Œ∏.
‚àÇŒ∏
m` sin Œ∏
This is shown by the red path, which goes around the bottom, through the
hole in the donut, up the top, and back, but not quite to the same point
as it started. Ignoring œÜ, this is periodic motion in Œ∏ with a period TŒ∏ , so
g (TŒ∏ ,0) (Œ∑0 ) is a point at the same latitude as Œ∑0 . This t ‚àà [0, TŒ∏ ] part of the
trajectory is shown as the thick red curve. There is some tÃÑ2 which, together
~
with tÃÑ1 = TŒ∏ , will cause g tÃÑ to map each point on the torus back to itself.
Thus ~e1 = (TŒ∏ , tÃÑ2 ) and ~e2 = (0, 2œÄ) constitute the unit vectors of the
lattice of ~t values which leave the points unchanged. The trajectory generated
by H does not close after one or a few TŒ∏ . It could be continued indefinitely,
and as in general there is no relation among the frequencies (tÃÑ2 /2œÄ is not
rational, in general), the trajectory will not close, but will fill the surface of
the torus. If we wait long enough, the system will sample every region of the
torus.
pÃáŒ∏ = ‚àí

204

CHAPTER 7. PERTURBATION THEORY

The 2-D isotropic harmonic oscillator
A different result occurs for the two dimensional zero-length isotropic oscillator,
1
1
1
1
L = m(xÃá2 + yÃá 2 ) ‚àí k(x2 + y 2 ) = m(rÃá2 + r2 œÜÃá2 ) ‚àí kr2 .
2
2
2
2
While this separates in cartesian coordinates, from which we easily see that
the orbit closes because the two periods are the same, we will look instead
at polar coordinates, where we have a conserved Hamiltonian
p2œÜ
1
p2r
+
+ kr2 ,
F1 = H =
2
2m 2mr
2
and conserved momentum pœÜ conjugate to the ignorable coordinate œÜ.
As before, pœÜ simply changes œÜ, as
shown in blue. But now if we trace
the action of H,
dr
= pr (t)/m,
dt

dœÜ
pœÜ
=
,
dt
mr2

p2œÜ
dpr
=
‚àí kr(t),
dt
mr3 (t)
we get the red curve which closes
on itself after one revolution in œÜ
and two trips through the donut
hole. Thus the orbit is a closed
curve, there is a relation among the frequencies. Of course the system now
only samples the points on the closed curve, so a time average of any function
on the trajectory is not the same as the average over the invariant torus.
The 3-D isotropic anharmonic oscillator
Now consider the spherically symmetric oscillator for which the potential
energy is not purely harmonic, say U (r) = 21 kr2 + cr4 . Then the Hamiltonian
in spherical coordinates is
H=

p2œÜ
p2r
p2
1 2
+ Œ∏2+
+
kr + cr4 .
2
2
2m 2mr
2
2mr sin Œ∏

7.1. INTEGRABLE SYSTEMS

205

This is time independent, so F1 = H is conserved, the first of our integrals
of the motion. Also œÜ is an ignorable coordinate, so F2 = pœÜ = Lz is the
~ is conserved. While Lx is an integral of
second. But we know that all of L
the motion, it is not in involution with Lz , as [Lz , Lx ] = Ly 6= 0, so it will
P
not serve as an additional generator. But L2 = k L2k is also conserved and
has zero Poisson bracket with H and Lz , so we can take it to be the third
generator
F3 = L2 = (~r √ó p~)2 = r2 p~ 2 ‚àí (~r ¬∑ p~)2 = r2
= p2Œ∏ +

p2
p2
p2r + 2Œ∏ + 2 œÜ 2
r
r sin Œ∏

!

‚àí r2 p2r

p2œÜ
.
sin2 Œ∏

The full phase space is six dimensional, and as pœÜ is constant we are left,
in general, with a five dimensional space with two nonlinear constraints.
On the three-dimensional hypersurface, pœÜ generates motion only in œÜ, the
Hamiltonian generates the dynamical trajectory with changes in r, pr , Œ∏, pŒ∏
and œÜ, and F3 generates motion in Œ∏, pŒ∏ and œÜ, but not in r or pr .
Now while Lx is not in involution with the three Fi already chosen, it is
a constant of the (dynamical) motion, as [Lx , H] = 0. But under the flow
generated by F2 = Lz , which generates changes in Œ∑j proportional to [Œ∑j , Lz ],
we have
X ‚àÇLx (Œ∑)
X ‚àÇLx (Œ∑)
d
‚àÇLz
Lx (g ŒªLz ~Œ∑ ) =
[Œ∑j , Lz ] =
Jjk
dŒª
‚àÇŒ∑j
‚àÇŒ∑j
Œ∑k
j
jk

= [Lx , Lz ] 6= 0.
Thus the constraint on the dynamical motion that Lx is conserved tells us
that motion on the invariant torus generated by Lz is inconsistent with the
dynamical evolution ‚Äî that the trajectory lies in a discrete subspace (two dimensional) rather than being dense in the three-dimensional invariant torus.
This also shows that there must be one relation among the frequencies.
Of course we could have reached this conclusion much more easily, as we
did in the last footnote, by choosing the z-axis of the spherical coordinates
~ points, so the motion restricts ~r to the xy plane,
along whatever direction L
and throwing in pr gives us a two-dimensional torus on which the motion
remains.

206

CHAPTER 7. PERTURBATION THEORY

7.2

Canonical Perturbation Theory

We now consider a problem with a conserved Hamiltonian which is in some
sense approximated by an integrable system with n degrees of freedom. This
integrable system is described with a Hamiltonian H (0) , and we assume we
(0)
(0)
have described it in terms of its action variables Ii and angle variables œÜi .
This system is called the unperturbed system, and theHamiltonian

is, of
(0) ~(0) ~ (0)
(0) ~(0)
course, independent of the angle variables, H
I ,œÜ
=H
I
.
The action-angle variables of the unperturbed system are a canonical set
of variables for the phase space, which is still the same phase space for the
full system. We write the Hamiltonian of the full system as












~ (0) = H (0) I~(0) + H1 I~(0) , œÜ
~ (0) .
H I~(0) , œÜ

(7.1)

We have included the parameter  so that we may regard the terms in H1 as
fixed in strength relative to each other, and still consider a series expansion
in , which gives an overall scale to the smallness of the perturbation.
We might imagine that if the perturbation is small, there are some new
action-angle variables Ii and œÜi for the full system, which differ by order
 from the unperturbed coordinates. These are new canonical coordinates,
and may be generated by a generating function3 (of type 2),




~ (0) =
~ œÜ
F I,



X (0)



~ (0) + ....
~ œÜ
œÜi Ii + F1 I,

This is a time-independent canonical transformation, so the full Hamiltonian
is the same function on phase-space whether the unperturbed or full actionangle variables are used, but has a different functional form,




~ = H I~(0) , œÜ
~ (0) .
~ œÜ)
HÃÉ(I,

(7.2)

Note that the phase space itself is described periodically by the coordinates
~ (0) , so the Hamiltonian perturbation H1 and the generating function F1 are
œÜ
periodic functions (with period 2œÄ) in these variables. Thus we can expand
them in Fourier series:


~ (0)
H1 I~(0) , œÜ



=

X

~ ~ (0)
H1~k I~(0) eik¬∑œÜ ,

(7.3)

~ ~ (0)
F1~k I~ eik¬∑œÜ ,

(7.4)





~k



~ (0)
~ œÜ
F1 I,



=

X

 

~k
3

To avoid confusion, note that here F1 is not the first integral of the motion.

7.2. CANONICAL PERTURBATION THEORY

207

where the sum is over all n-tuples of integers ~k ‚àà Zn . The zeros of the new
~ so we may choose F ~ (I) = 0.
angles are arbitrary for each I,
10
The unperturbed action variables, on which H0 depends, are the old
(0)
(0)
(0)
momenta given by Ii = ‚àÇF/‚àÇœÜi = Ii + ‚àÇF1 /‚àÇœÜi + ..., so to first order


H0 I~(0)



‚àÇF1
+ ...
(0)
(0)
‚àÇIj ‚àÇœÜj

 

X ‚àÇH0

 

X (0) X

= H0 I~ + 

j

= H0 I~ + 

œâj

j
(0)

where we have noted that ‚àÇH0 /‚àÇIj
turbed problem. Thus


~
~ œÜ
HÃÉ I,





~ i~k¬∑œÜ~(0) + ...,
ikj F1~k (I)e

(7.5)

~k
(0)

= œâj , the frequencies of the unper-







~ (0) = H (0) I~(0) + 
= H I~(0) , œÜ

X

~ ~ (0)
H1~k I~(0) eik¬∑œÜ





~k

=

Ô£´
Ô£∂
 


X X
(0)
~ + H ~ I~(0) Ô£∏ ei~k¬∑œÜ~(0) .
Ô£≠
H0 I~ + 
ikj œâ F ~ (I)
j

~k

1k

1k

j

~ is in fact
~ œÜ)
The I~ are the action variables of the full Hamiltonian, so HÃÉ(I,
~ In the sum over Fourier modes on the right hand side,
independent of œÜ.
(0)
the œÜ dependence of the terms in parentheses due to the difference of I~(0)
~ ~ (0)
from I~ is higher order in , so the the coefficients of eik¬∑œÜ may be considered
constants in œÜ(0) and therefore must vanish for ~k 6= ~0. Thus the generating
function is given in terms of the Hamiltonian perturbation
F1~k = i

H1~k
~k ¬∑ œâ
~
~ (0) (I)

,

~k 6= ~0.

(7.6)

We see that there may well be a problem in finding new action variables
if there is a relation among the frequencies. If the unperturbed system is
not degenerate, ‚Äúmost‚Äù invariant tori will have no relation among the frequencies. For these values, the extension of the procedure we have described
to a full power series expansion in  may be able to generate new actionangle variables, showing that the system is still integrable. That this is true
(0)
for sufficiently small perturbations and ‚Äúsufficiently irrational‚Äù œâJ is the
conclusion of the famous KAM theorem4 .
4

See Arnold[2], pp 404-405, though he calls it Kolmogorov‚Äôs Theorem, denying credit
to himself and Moser, or JoseÃÄ and Saletan[8], p. 477.

208

CHAPTER 7. PERTURBATION THEORY

What happens if there is a relation among the frequencies? Consider a
(0)
(0)
two degree of freedom system with pœâ1 + qœâ2 = 0, with p and q relatively
prime. Then the Euclidean algorithm shows us there are integers m and
(0)
n such that pm + qn = 1. Instead of our initial variables œÜi ‚àà [0, 2œÄ] to
describe the torus, we can use the linear combinations


œà1
œà2





=

p
q
n ‚àím



(0)

œÜ1
(0)
œÜ2

(0)

!

=B¬∑

œÜ1
(0)
œÜ2

!

.

Then œà1 and œà2 are equally good choices for the angle variables of the unperturbed system, as œài ‚àà [0, 2œÄ] is a good coordinate system on the torus. The
corresponding action variables are Ii0 = (B ‚àí1 )ji Ij , and the corresponding
new frequencies are
œâi0 =

‚àÇH X ‚àÇH ‚àÇIj
(0)
=
= Bij œâj ,
0
0
‚àÇIi
j ‚àÇIj ‚àÇIi
(0)

(0)

and so in particular œâ10 = pœâ1 + qœâ2 = 0 on the chosen invariant torus.
This conclusion is also obvious from the equations of motion œÜÃái = œâi .
In the unperturbed problem, on our initial invariant torus, œà1 is a constant
of the motion, so in the perturbed system we might expect it to vary slowly
with respect to œà2 . Then it is appropriate to use the adiabatic approximation
of section 7.3

7.2.1

Time Dependent Perturbation Theory

Now we will consider problems for which the Hamiltonian H is approximately
that of an exactly solvable problem, H0 . So we write
H(q, p, t) = H0 (q, p, t) + HI (q, p, t),
where HI (q, p, t) is considered a small ‚Äúinteraction‚Äù Hamiltonian. We assume we know Hamilton‚Äôs principal function S0 (q, P, t) for the unperturbed
problem, which gives a canonical transformation (q, p) ‚Üí (Q, P ), and in the
limit  ‚Üí 0, QÃá = PÃá = 0. For the full problem,
K(Q, P, t) = H0 + HI +

‚àÇS0
= HI ,
‚àÇt

7.2. CANONICAL PERTURBATION THEORY

209

and is small. Expressing HI in terms of the new variables (Q, P ), we have
that
QÃá = 

‚àÇHI
,
‚àÇP

PÃá = ‚àí

‚àÇHI
‚àÇQ

and these are slowly varying because  is small. In symplectic form, with
Œ∂ T = (Q, P ), we have, of course,
Œ∂Ãá = J ¬∑ ‚àáHI (Œ∂).

(7.7)

This differential equation can be solved perturbatively. If we assume an
expansion
Œ∂(t) = Œ∂0 (t) + Œ∂1 (t) + 2 Œ∂2 (t) + ...,
Œ∂Ãán on the left of (7.7) can be determined from only lower order terms Œ∂j ,
j < n on the right hand side. The initial value
Œ∂(0) is arbitrary, so we can
Rt
take it to be Œ∂0 (0), and determine Œ∂n (t) = 0 Œ∂Ãán (t0 )dt0 accurate to order n .
Thus we can recursively find higher and higher order terms in . This is a
good expansion for  small enough, for fixed t, but as we are making an error
in Œ∂Ãá, this will give an error of order t compared to the previous stage., so the
total error at the m‚Äôth step is O([t]m ) for Œ∂(t). Thus for calculating the long
time behavior of the motion, this method is unlikely to work in the sense
that any finite order calculation cannot be expected to be good for t ‚Üí ‚àû.
Even though H and H0 differ only slightly, and so acting on any given Œ∑ they
will produce only slightly different rates of change, as time goes on there is
nothing to prevent these differences from building up. In a periodic motion,
for example, the perturbation is likely to make a change ‚àÜœÑ of order  in the
period œÑ of the motion, so at a time t ‚àº œÑ 2 /2‚àÜœÑ later, the systems will be at
opposite sides of their orbits, not close together at all.
Clearly a better approximation scheme is called for, one in which Œ∂(t) is
compared to Œ∂0 (t0 ) for a more appropriate time t0 . The canonical method
does this, because it compares the full Hamiltonian and the unperturbed one
at given values of œÜ, not at a given time. Another example of such a method
applies to adiabatic invariants.

210

CHAPTER 7. PERTURBATION THEORY

7.3

Adiabatic Invariants

7.3.1

Introduction

We are going to discuss the evolution of a system which is, at every instant,
given by an integrable Hamiltonian, but for which the parameters of that
Hamiltonian are slowly varying functions of time. We will find that this leads
to an approximation in which the actions are time invariant. We begin with a
qualitative discussion, and then we discuss a formal perturbative expansion.
First we will consider a system with one degree of freedom described by
a Hamiltonian H(q, p, t) which has a slow time dependence. Let us call TV
the time scale over which the Hamiltonian has significant variation (for fixed
q, p). For a short time interval  TV , such a system could be approximated
by the Hamiltonian H0 (q, p) = H(q, p, t0 ), where t0 is a fixed time within
that interval. Any perturbative solution based on this approximation may
be good during this time interval, but if extended to times comparable to
the time scale TV over which H(q, p, t) varies, the perturbative solution will
break down. We wish to show, however, that if the motion is bounded and
the period of the motion determined by H0 is much less than the time scale
of variations TV , the action is very nearly conserved, even for evolution over
a time interval comparable to TV . We say that the action is an adiabatic
invariant.

7.3.2

For a time-independent Hamiltonian

In the absence of any explicit time dependence, a Hamiltonian is conserved.
The motion is restricted to lie on a particular contour H(q, p) = Œ±, for all
times. For bound solutions to the equations of motion, the solutions are
periodic closed orbits in phase space. We will call this contour Œì, and the
period of the motion œÑ . Let us parameterize the contour with the actionangle variable œÜ. We take an arbitrary point on Œì to be œÜ = 0 and also
(q(0), p(0)). As action-angles evolve at a fixed rate, every other point is
determined by Œì(œÜ) = (q(œÜœÑ /2œÄ), p(œÜœÑ /2œÄ)), so the complete orbit is given
by Œì(œÜ), œÜ ‚àà [0, 2œÄ). The action is defined as
1 I
pdq.
(7.8)
2œÄ
This may be considered
as an integral along one cycle in extended phase
R t+œÑ
0
space, 2œÄJ(t) = t p(t )qÃá(t0 )dt0 . Because p(t) and qÃá(t) are periodic with
J=

7.3. ADIABATIC INVARIANTS
period œÑ , J is independent of time t. But J can also be
thought
of as an integral in phase space itself, 2œÄJ =
H
pdq,
of a one form œâ1 = pdq along the closed
Œì
path Œì(œÜ), œÜ ‚àà [0, 2œÄ], which is the orbit in question.
By Stokes‚Äô Theorem,
Z
S

dœâ =

Z

œâ,

Œ¥S

211

p
1
-1

0

1

q

-1

Fig. 1. The orbit
of an autonomous
system in phase
space.

true for any n-form œâ Rand suitable region S of a manifold, we have 2œÄJ = A dp ‚àß dq, where A is the area
bounded by Œì.
In extended phase space {q, p, t}, if we start at time t=0 with any point
(q, p) on Œì, the trajectory swept out by the equations of motion, (q(t), p(t), t)
will lie on the surface of a cylinder with base A extended in the time direction.
Let Œìt be the embedding of Œì into the time slice at t, which is the intersection
of the cylinder with that time slice. The
surface of the cylinder can also be viewed
as the set of all the dynamical trajectories
which start on Œì at t = 0. In other words, if
2
TœÜ (t) is the trajectory of the system which
1
starts at Œì(œÜ) at t=0, the set of TœÜ (t) for p0
-1
Œì
‚Ñë
-1
œÜ ‚àà [0, 2œÄ], t ‚àà [0, T ], sweeps out the same -2
t
0q
0
surface as {Œìt }, for all t ‚àà [0, T ]. Because
5
1
10
t 15 20
2
this is an autonomous system, the value
of the action J is the same, regardless of Fig 2. The surface in extended
whether it is evaluated along Œìt , for any phase space, generated by the
t, or evaluated along one period for any ensemble of systems which start
of the trajectories starting on Œì0 . If we at time t = 0 on the orbit Œì
terminate the evolution at time T , the end shown in Fig. 1. One such
of the cylinder, ŒìT , is the same orbit of the trajectory is shown, labelled I,
and also shown is one of the Œìt .
motion, in phase space, as was Œì0 .

7.3.3

Slow time variation in H(q, p, t)

Now consider a time dependent Hamiltonian H(q, p, t). For a short interval
of time near t0 , if we assume the time variation of H is slowly varying, the
autonomous Hamiltonian H(q, p, t0 ) will provide an approximation, one that
has conserved energy and bound orbits given by contours of that energy.

212

CHAPTER 7. PERTURBATION THEORY

Consider extended phase space,
and a closed path Œì0 (œÜ) in the
t=0 plane which is a contour of
H(q, p, 0), just as we had in the
time-independent case. For each
point œÜ on this path, construct
the trajectory TœÜ (t) evolving from
Œì(œÜ) under the influence of the
full Hamiltonian H(q, p, t), up until
some fixed final time t = T . This
collection of trajectories will sweep
out a curved surface Œ£1 with boundary Œì0 at t=0 and another we call
ŒìT at time t=T .

1

p0
-1
0 10

20

2
0q

30

t 40 50 60

-2

Fig. 3. The motion of a harmonic
oscillator with time-varying spring
constant k ‚àù (1 ‚àí t)4 , with  =
0.01. [Note that the horn is not
tipping downwards, but the surface
ends flat against the t = 65 plane.]

Because the Hamiltonian does change with time, these Œìt , the intersections
of Œ£1 with the planes at various times t, are not congruent. Let Œ£0 and Œ£T
be the regions of the t=0 and t=T planes bounded by Œì0 and ŒìT respectively,
oriented so that their normals go forward in time.
This constructs a region which is a deformation of the cylinder5 that we
had in the case where H was independent of time. Of course if the variation
of H is slow on a time scale of T , the path ŒìT will not Hdiffer much from Œì0 ,
so it will be nearly an orbit and the action defined by pdq around ŒìT will
be nearly that around Œì0 . We shall show something much stronger; that if
the time dependence of H is a slow variation compared with the approximate
period of the Hmotion, then each Œìt is nearly an orbit and the action on that
Àú =
path, J(t)
Œìt pdq is constant, even if the Hamiltonian varies considerably
over time T .
The Œ£‚Äôs form a closed surface, which is Œ£1 +Œ£T ‚àíŒ£0 , where we have taken
the orientation of Œ£1 to point outwards, and made up for the inward-pointing
direction of Œ£0 with a negative sign. Call the volume enclosed by this closed
surface V .
Àú and J(T
Àú ) defined on the ends of
We will first show that the actions J(0)
5

Of course it is possible that after some time, which must be on a time scale of order TV
rather than the much shorter cycle time œÑ , the trajectories might intersect, which would
require the system to reach a critical point in phase space. We assume that our final time
T is before the system reaches a critical point.

7.3. ADIABATIC INVARIANTS

213

the cylinder are the same. Again from Stokes‚Äô theorem, they are
Àú =
J(0)

Z

pdq =

Z

Œì0

dp ‚àß dq

Àú )=
and J(T

Z

Œ£0

dp ‚àß dq

Œ£T

respectively. Each of these surfaces
has no component in the t direction, so
Àú = R dœâ3 , where œâ3 = pdq ‚àí Hdt is the one-form
we may also evaluate J(t)
Œ£t
of section (6.6) which determines the motion by Hamilton‚Äôs principle. So
dœâ3 = dp ‚àß dq ‚àí dH ‚àß dt.

(7.9)

Clearly dœâ3 is closed as it is exact.
dp + ‚àÇH
dq + ‚àÇH
dt,
As H is a function on extended phase space, dH = ‚àÇH
‚àÇp
‚àÇq
‚àÇt
and thus
‚àÇH
‚àÇH
dœâ3 = dp ‚àß dq ‚àí
dp ‚àß dt ‚àí
dq ‚àß dt
‚àÇp
‚àÇq
!
!
‚àÇH
‚àÇH
= dp +
dt ‚àß dq ‚àí
dt ,
(7.10)
‚àÇq
‚àÇp
where we have used the antisymmetry of the wedge product, dq ‚àß dt =
‚àídt ‚àß dq, and dt ‚àß dt = 0.
Now the interesting thing about this rewriting of the action in terms of
the new form (7.10) of dœâ3 is that dœâ3 is now a product of two 1-forms
dœâ3 = œâa ‚àß œâb ,

where œâa = dp +

‚àÇH
dt,
‚àÇq

œâb = dq ‚àí

‚àÇH
dt,
‚àÇp

and each of œâa and œâb vanishes along any trajectory of the motion, along
which Hamilton‚Äôs equations require
‚àÇH
dp
=‚àí
,
dt
‚àÇq

dq
‚àÇH
=
.
dt
‚àÇp

As a consequence, dœâ3 vanishes at any point when evaluated on a surface
which contains a physical trajectory, so in particular dœâ3 vanishes over the
surface Œ£1 generated by the trajectories. Because dœâ3 is closed,
Z
Œ£1 +Œ£T ‚àíŒ£0

dœâ3 =

Z
V

d(dœâ3 ) = 0

where the first equality is due to Gauss‚Äô law, one form of the generalized
Stokes‚Äô theorem. Then we have
Àú )=
J(T

Z
Œ£T

dœâ3 =

Z
Œ£0

Àú
dœâ3 = J(0).

214

CHAPTER 7. PERTURBATION THEORY

What we have shown here for the area in phase space enclosed by an orbit
holds equally well for any area in phase space. If A is a region in phase space,
and if we define B as that region in phase space in which
systemsRwill lie at
R
time t = T if the system was in A at time t = 0, then A dp ‚àß dq = B dp ‚àß dq.
For systems with n > 1 degrees of freedom, we may consider a set of n
P
forms ( k dpk ‚àß dqk )j , j = 1...n, which are all conserved under dynamical
P
evolution. In particular, ( k dp ‚àß dqk )n tells us the hypervolume in phase
space is preserved under its motion under evolution according to Hamilton‚Äôs
equations of motion. This truth is known as Liouville‚Äôs theorem, though the
P
n invariants ( k dp ‚àß dqk )j are known as PoincareÃÅ invariants.

R

While we have shown that the integral pdq is conserved when evaluated
over an initial contour in phase space at time t = 0, and then compared
to its integral over the path at time t = T given by the time evolution of
the ensembles which started on the first path, neither of these integrals are
exactly an action.

In fact, for a time-varying system
the action is not really well defined,
because actions are defined only for
periodic motion. For the one dimensional harmonic oscillator (with varying spring constant) of Fig. 3, a reasonable substitute definition is to define J
for each ‚Äúperiod‚Äù from one passing to
the right through the symmetry point,
q = 0, to the next such crossing. The

1

p
-2 -1.5

-1 -0.5

1

p

0.5

0

0.5

q1

1.5

-2 -1.5

-1 -0.5

0.5

0

0.5

-0.5

-0.5

-1

-1

q1

1.5

Fig. 4. The trajectory in phase
space of the system in Fig. 3. The
‚Äúactions‚Äù during two ‚Äúorbits‚Äù are
shown by shading. In the adiabatic
approximation the areas are equal.

7.3. ADIABATIC INVARIANTS

215
1

p

trajectory of a single such system as it
0
moves through phase space
is shown in
-2
-1
1
1.5
q
R
Fig. 4. The integrals p(t)dq(t) over
time intervals between successive for-1
ward crossings of q = 0 is shown for
the first and last such intervals. While Fig. 5. The differences between the
these appear to have roughly the same actual trajectories (thick lines) durarea, what we have shown is that the ing the first and fifth oscillations,
integrals over the curves Œìt are the and the ensembles Œìt at the mosame. In Fig. 5 we show Œìt for t at ments of the beginnings of those pethe beginning of the first and fifth ‚Äúpe- riods. The area enclosed by the latriods‚Äù, together with the actual motion ter two curves are strictly equal, as
through those periods. The deviations we have shown. The figure indiare of order œÑ and not of T , and so are cates the differences between each
negligible as long as the approximate of those curves and the actual traperiod is small compared to TV ‚àº 1/. jectories.
Another way we can define an action in our time-varying problem is to
write an expression for the action on extended phase space, J(q, p, t0 ), given
by the action at that value of (q, p) for a system with hamiltonian fixed at
the time in question,qHt0 (q, p) := H(q, p, t0 ). This is an ordinary harmonic
oscillator with œâ = k(t0 )/m. For an autonomous harmonic oscillator the
area of the elliptical orbit is
2
2œÄJ = œÄpmax qmax = œÄmœâqmax
,

while the energy is
p2
mœâ 2 2
mœâ 2 2
+
q =E=
q ,
2m
2
2 max
so we can write an expression for the action as a function on extended phase
space,
1
p2
mœâ(t) 2
2
J = mœâqmax
= E/œâ =
+
q .
2
2mœâ(t)
2
With this definition, we can assign a value for the action to the system as a
each time, which in the autonomous case agrees with the standard action.

216

CHAPTER 7. PERTURBATION THEORY

From this discussion, we see that if
the Hamiltonian varies slowly on the
time scale of an oscillation of the system, the action will remain fairly close 1.2
to the JÀút , which is conserved. Thus
J
the action is an adiabatic invariant, con1
served in the limit that œÑ /TV ‚Üí 0.
To see how this works in a particular
0.8
example, consider the harmonic oscillator with a time-varying spring constant,
which we have chosen to be k(t) = 0.6
k0 (1 ‚àí t)4 . With  = 0.01, in units
given by the initial œâ, the evolution is 0.4
œâ
E
shown from time 0 to time 65. During
this time the spring constant becomes 0.2
over 66 times weaker, and the natural
frequency decreases by a factor of more
0
20
40
60
t
than eight, as does the energy, but the
action remains quite close to its origi- Fig. 6. The change in angular
nal value, even though the adiabatic ap- frequency, energy, and action
proximation is clearly badly violated by for the time-varying springa spring constant which changes by a constant harmonic oscillator,
factor of more than six during the last with k(t) ‚àù (1 ‚àí t)4 , with
 = œâ(0)/100
oscillation.
We see that the failure of the action to be exactly conserved is due to
the descrepancy between the action evaluated on the actual path of a single
system and the action evaluated on the curve representing the evolution,
after a given time, of an ensemble of systems all of which began at time t = 0
on a path in phase space which would have been their paths had the system
been autonomous.
This might tempt us to consider a different problem, in which the time
dependance of the hamiltonian varies only during a fixed time interval, t ‚àà
[0, T ], but is constant before t = 0 and after T . If we look at the motion
during an oscillation before t = 0, the system‚Äôs trajectory projects exactly
Àú
onto Œì0 , so the initial action J = J(0).
If we consider a full oscillation
beginning after time T , the actual trajectory is again a contour of energy in
phase space. Does this mean the action is exactly conserved?
There must be something wrong with this argument, because the con-

7.3. ADIABATIC INVARIANTS

217

Àú did not depend on assumptions of slow variation of the Hamilstancy of J(t)
tonian. Thus it should apply to the pumped swing, and claim that it is
impossible to increase the energy of the oscillation by periodic changes in
the spring constant. But every child knows that is not correct. Examining
this case will point out the flawed assumption in the argument. In Fig. 7,
we show the surface generated
by time evolution of an ensemble of systems initially on an energy contour for a harmonic oscillator. Starting at time 0, the
spring constant is modulated by
10% at a frequency twice the
1.5
1
natural frequency, for four nat0.5
1.5
0
ural periods. Thereafter the
1
-0.5
0.5
-1
Hamiltonian is the same as is
0
-1.5
-0.5
was before t = 0, and each sys-1
0
10
-1.5
20
30
tem‚Äôs path in phase space conFig. 7. The surface Œ£1 for a harmonic
tinues as a circle in phase space
oscillator with a spring constant which
(in the units shown), but the envaries, for the interval t ‚àà [0, 8œÄ], as
semble of systems form a very
k(t) = k(0)(1 + 0.1 sin 2t).
elongated figure, rather than a
circle.
What has happened is that some of the systems in the ensemble have
gained energy from the pumping of the spring constant, while others have
lost energy. Thus there has been no conservation of the action for individual
systems, but rather there is some (vaguely understood) average action which
is unchanged.
Thus we see what is physically the crucial point in the adiabatic expansion: if all the systems in the ensemble experience the perturbation in the
same way, because the time variation of the hamiltonian is slow compared
to the time it takes for each system in the ensemble to occupy the initial
position (in phase space) of every other system, then each system will have
its action conserved.

7.3.4

Systems with Many Degrees of Freedom

In the discussion above we considered as our starting point an autonomous
system with one degree of freedom. As the hamiltonian is a conserved

218

CHAPTER 7. PERTURBATION THEORY

function on phase space, this is an integrable system. For systems with
n > 1 degrees of freedom, we wish to again start with an integrable system. Such systems have n invariant ‚Äúintegrals of the motion in involution‚Äù,
and their phase space can be described in terms of n action variables Ji and
corresponding coordinates œÜi . Phase
space is periodic in each of the œÜi with
period 2œÄ, and the submanifold Mf~ of
phase space which has a given set {fi }
of values for the Ji is an n-dimensional
torus. As the Ji are conserved, the motion is confined to Mf~, and indeed the
equations of motion are very simple,
dœÜi /dt = œâi (constant). Mf~ is known
Œì2
as an invariant torus.
Œì1
In the one variable case we related
the action to the 1-form p dq. On the Fig 8. For an integrable system
invariant torus, the actions are con- with two degrees of freedom, the
stantsH and so it is trivially true that motion is confined to a 2-torus,
J = Ji dœÜi /2œÄ, where the integral is and the trajectories are uniform
R i2œÄ
motion in each of the angles, with
0 dœÜi with the other œÜ‚Äôs held fixed.
The
This might lead one to think about n independent frequencies.
1-forms without a sum, but it is more two actions J1 and J2 may be
profitable to recognize that the single considered as integrals of the single
P
P
Ji dœÜi over two
1-form œâ1 = Ji dœÜi alone contains all 1-form œâ1 =
of the information we need. First note independant cycles Œì1 and Œì2 as
that, restricted to Mf~ , dJi vanishes, shown.
so œâ1 is closed on Mf~, and its integral is a topological invariant, that is,
unchanged under continuous deformations of the path. We can take a set of
paths, or cycles, Œìi , each winding
around the torus only in the œÜi direction,
1 R
œâ
.
and we then have Ji = 2œÄ
Œìi 1 The answer is completely independent of
where the path Œìi is drawn on Mf~ , as long as its topology is unchanged.
Thus the action can be thought of as a function on the simplicial homology
H1 of Mf~ . The actions can also be expressed as an integral over a surface
1 R P
Œ£i bounded by the Œìi , Ji = 2œÄ
dJi ‚àß dœÜi . Notice that this surface
Œ£i
does not lie on the invariant torus but cuts across it. This formulation has
P
two advantages. First,
dpi ‚àß dqi is invariant under arbitrary canonical
P
transformations, so dJi ‚àß dœÜi is just one way to write it. Secondly, on a

7.3. ADIABATIC INVARIANTS

219

surface of constant t, such as Œ£i , it is identical to the fundamental form
dœâ3 =

n
X

dpi ‚àß dqi ‚àí dH ‚àß dt,

i=1

the generalization to several degrees of freedom of the form we used to show
the invariance of the integral under time evolution in the single degree of
freedom case.
Now suppose that our system is subject to some time-dependent perturbation, but that at all times its Hamiltonian remains close to an integrable
system, though that system might have parameters which vary with time.
Let‚Äôs also assume that after time T the hamiltonian again becomes an autonomous integrable system, though perhaps with parameters different from
what it had at t = 0.
Consider the evolution in time, under the full hamiltonian, of each system which at t = 0 was at some
~ 0 on the invariant torus M ~ of
point œÜ
f
Œì1
the original unperturbed system. FolŒì2
low each such system until time T .
We assume that none of these systems
reaches a critical point during this evolution. The region in phase space thus
varies continuously, and at the fixed
later time T , it still will be topologically an n-torus, which we will call
~
Œì2
B. The image of each of the cycles
~
Œì1
Œìi will be a cycle ŒìÃÉi on B, and together these images will be a a basis Fig. 9. Time evolution of the inof the homology H1 of the B. Let Œ£ÃÉi variant torus, and each of two of the
cycles on it.
be surfaces within the t = T hyperplane
bounded by ŒìÃÉi . Define JÀúi to be
R P
1
the integral on Œ£ÃÉi of dœâ3 , so JÀúi = 2œÄ Œ£ÃÉi j dpj ‚àß dqj , where we can drop
the dH ‚àß dt term on a constant t surface, as dt = 0. We can now repeat
the argument from the one-degree-of-freedom case to show that the integrals
JÀúi = Ji , again because dœâ3 is a closed 2-form which vanishes on the surface
of evolution, so that its integrals on the end-caps are the same.

220

CHAPTER 7. PERTURBATION THEORY

Now we have assumed that the system is again integrable at t = T , so
there are new actions Ji0 , and new invariant tori
M~0g = {(~q, p~) 3 Ji0 (~q, p~) = gi }.
~ 0 winds up on some new invariant torus
Each initial system which started at œÜ
~
with ~g (œÜ0 ).
If the variation of the hamiltonian is sufficiently slow and smoothly varying on phase space, and if the unperturbed motion is sufficiently ergotic that
each system samples the full invariant torus on a time scale short compared
~ 0 may
to the variation time of the hamiltonian, then each initial system œÜ
be expected to wind up with the same values of the perturbed actions, so
~ 0 . That means that the torus B is, to some good ap~g is independant of œÜ
proximation, one of the invariant tori M~0g , that the cycles of B are cycles of
M~0g , and therefore that Ji0 = JÀúi = Ji , and each of the actions is an adiabatic
invariant.

7.3.5

Formal Perturbative Treatment

Consider a system based on a system H(~q, p~, ~Œª), where ~Œª is a set of parameters, which is integrable for each constant value of ~Œª within some domain
of interest. Now suppose our ‚Äúreal‚Äù system is described by the same Hamiltonian, but with ~Œª(t) a given slowly varying function of time. Although the
full Hamiltonian is not invariant, we will show that the action variables are
approximately so.
For each fixed value of ~Œª, there is a generating function of type 1 to the
corresponding action-angle variables:
~ ~Œª) : (~q, p~) ‚Üí (œÜ,
~ I).
~
F1 (~q, œÜ,
This is a time-independent transformation, so the Hamiltonian may be writ~ q , p~), ~Œª), independent of the angle variable. This constant ~Œª
ten as H(I(~
Hamiltonian has equations of motion œÜÃái = ‚àÇH/‚àÇIi = œâi (~Œª), IÀôi = 0. But
in the case where ~Œª is a function of time, the transformation F1 is not a
time-independent one, so the correct Hamiltonian is not just the reexpressed
Hamiltonian but has an additional term
~ I,
~ ~Œª) = H(I,
~ ~Œª) +
K(œÜ,

X ‚àÇF1 dŒªn
n

‚àÇŒªn dt

,

7.3. ADIABATIC INVARIANTS

221

where the second term is the expansion of ‚àÇF1 /‚àÇt by the chain rule. The
equations of motion involve differentiating K with respect to one of the variables (œÜj , Ij ) holding the others, and time, fixed. While these are not the
~ for F1 , they are coordinates of phase space, so F1 can
usual variables (~q, œÜ)
be expressed in terms of (œÜj , Ij ), and as shown in (7.2), it is periodic in the
œÜj . The equation of motion for Ij is
œÜÃái = œâi (~Œª) +
IÀôi =

‚àÇ 2 F1
ŒªÃán ,
n ‚àÇŒªn ‚àÇIi

X

‚àÇ 2 F1
ŒªÃán ,
n ‚àÇŒªn ‚àÇœÜi

X

~ I,
~ ~Œª. We
where all the partial derivatives are with respect to the variables œÜ,
first note that if the parameters Œª are slowly varying, the ŒªÃán ‚Äôs in the equations
of motion make the deviations from the unperturbed system small, of first
order in /œÑ = ŒªÃá/Œª, where œÑ is a typical time for oscillation of the system.
But in fact the constancy of the action is better than that, because the
expression for IÀôj is predominantly an oscillatory term with zero mean. This
is most easily analyzed when the unperturbed system is truly periodic, with
period œÑ . Then during one period t ‚àà [0, œÑ ], ŒªÃá(t) ‚âà ŒªÃá(0) + tŒªÃà. Assuming
Œª(t) varies smoothly on a time scale œÑ /, ŒªÃà ‚àº ŒªO(2 /œÑ 2 ), so if we are willing
to drop terms of order 2 , we may treat ŒªÃá as a constant. We can then also
evaluate F1 on the orbit of the unperturbed system, as that differs from the
true orbit by order , and the resulting value is multiplied by ŒªÃá, which is
already of order /œÑ , and the result is to be integrated over a period œÑ . Then
we may write the change of Ij over one period as
‚àÜIj ‚âà

X
n

ŒªÃán

Z œÑ
0

‚àÇ
‚àÇœÜj

!

‚àÇF1
dt.
‚àÇŒªn

But F1 is a well defined single-valued function on the invariant manifold, and
so are its derivatives with respect to Œªn , so we may replace the time integral
by an integral over the orbit,
œÑ I ‚àÇ
‚àÜIj ‚âà
ŒªÃán
L ‚àÇœÜj
n
X

!

‚àÇF1
dœÜj = 0,
‚àÇŒªn

where L is the length of the orbit, and we have used the fact that for the
unperturbed system dœÜj /dt is constant.

222

CHAPTER 7. PERTURBATION THEORY

Thus the action variables have oscillations of order , but these variations
do not grow with time. Over a time t, ‚àÜI~ = O()+tO(2 /œÑ ), and is therefore
conserved up to order  even for times as large as œÑ /, corresponding to
many natural periods, and also corresponding to the time scale on which the
Hamiltonian is varying significantly.
This form of perturbation, corresponding to variation of constants on a
time scale slow compared to the natural frequencies of the unperturbed system, is known as an adiabatic variation, and a quantity conserved to order
 over times comparable to the variation itself is called an adiabatic invariant. Classic examples include ideal gases in a slowly varying container,
a pendulum of slowly varying length, and the motion of a rapidly moving
charged particle in a strong but slowly varying magnetic field. It is interesting to note that in Bohr-Sommerfeld quantization in the old quantum
mechanics, used before the SchroÃàdinger equation clarified such issues, the
quantization of bound states was related to quantization of the action. For
example, in Bohr theory the electrons are in states with action nh, with n a
positive integer and h Planck‚Äôs constant. Because these values are preserved
under adiabatic perturbation, it is possible that an adiabatic perturbation
of a quantum mechanical system maintains the system in the initial quantum mechanical state, and indeed this can be shown, with the full quantum
theory, to be the case in general. An important application is cooling by
adiabatic demagnetization. Here atoms with a magnetic moment are placed
in a strong magnetic field and reach equilibrium according to the Boltzman
distribution for their polarizations. If the magnetic field is adiabatically reduced, the separation energies of the various polarization states is reduced
proportionally. As the distribution of polarization states remains the same
for the adiabatic change, it now fits a Boltzman distribution for a temperature reduced proportionally to the field, so the atoms have been cooled.

7.4

Rapidly Varying Perturbations

At the other extreme from adiabatic perturbations, we may ask what happens to a system if we add a perturbative potential which oscillates rapidly
with respect to the natural frequencies of the unperturbed system. If these
forces are of the same magnitude as those of the unperturbed system, we
would expect that they would cause in the coordinates and momenta a small
rapid oscillation, small because a finite acceleration could make only small

7.4. RAPIDLY VARYING PERTURBATIONS

223

changes in velocity and position over a small oscillation time. Then we might
expect the effects of the force to be little more than adding jitter to the unperturbed motion. Consider the case that the external force is a pure sinusoidal
oscillation,
H(~q, p~) = H0 (~q, p~) + U (~q) sin œât,
and let us write the resulting motion as
qj (t) = qÃÑj (t) + Œæj (t),
pj (t) = pÃÑj (t) + Œ∑j (t),
where we subtract out the average smoothly varying functions qÃÑ and pÃÑ, leaving the rapidly oscillating pieces Œæ~ and ~Œ∑ , which have natural time scales of
¬® œâ Œæ,
Àô œâ 2 Œæ, Œ∑Ãá and œâŒ∑ should all remain finite as œâ gets large with
2œÄ/œâ. Thus Œæ,
all the parameters of H0 and U (q) fixed. Our naƒ±Ãàve expectation is that the
qÃÑ(t) and pÃÑ(t) are what they would have been in the absence of the perturbation, and Œæ(t) and Œ∑(t) are purely due to the oscillating force.
This is not exactly right, however, because the force due to H0 depends
on the q and p at which it is evaluated, and it is being evaluated at the full
q(t) and p(t) rather than at qÃÑ(t) and pÃÑ(t). In averaging over an oscillation,
the first derivative terms in H0 will not contributed to a change, but the
second derivative terms will cause the average value of the force to differ
from its value at (qÃÑ(t), pÃÑ(t)). The lowest order effect (O(œâ ‚àí2 )) is from the
oscillation of p(t), with Œ∑ ‚àù œâ ‚àí1 ‚àÇU/‚àÇq, changing the average force by an
amount proportional to Œ∑ 2 times ‚àÇ 2 H0 /‚àÇpk ‚àÇp` . We shall see that a good
approximation is to take qÃÑ and pÃÑ to evolve with the effective ‚Äúmean motion
Hamiltonian‚Äù
K(qÃÑ, pÃÑ) = H0 (qÃÑ, pÃÑ) +

1 X ‚àÇU ‚àÇU ‚àÇ 2 H0
.
4œâ 2 k` ‚àÇ qÃÑk ‚àÇ qÃÑ` ‚àÇ pÃÑk ‚àÇ pÃÑ`

(7.11)

Under this hamiltonian, we have
qÃÑÀôj =

‚àÇH0
‚àÇK
1 X ‚àÇU ‚àÇU ‚àÇ 3 H0
=
.
+ 2
‚àÇpj
‚àÇpj qÃÑ,pÃÑ 4œâ k` ‚àÇ qÃÑk ‚àÇ qÃÑ` ‚àÇ pÃÑk ‚àÇ pÃÑ` ‚àÇ pÃÑj

‚àÇK
(7.12)
‚àÇqj
‚àÇH0
1 X ‚àÇ 2 U ‚àÇU ‚àÇ 2 H0
1 X ‚àÇU ‚àÇU ‚àÇ 3 H0
= ‚àí
‚àí 2
‚àí 2
.
‚àÇqj qÃÑ,pÃÑ 2œâ k` ‚àÇ qÃÑj ‚àÇ qÃÑk ‚àÇ qÃÑ` ‚àÇ pÃÑk ‚àÇ pÃÑ` 4œâ k` ‚àÇ qÃÑk ‚àÇ qÃÑ` ‚àÇ pÃÑk ‚àÇ pÃÑ` ‚àÇ qÃÑj

pÃÑÀôj = ‚àí

224

CHAPTER 7. PERTURBATION THEORY

Of course the full motion for q(t) and p(t) is given by the full Hamiltonian
equations:
qÃÑÀôj + ŒæÀôj =
=

‚àÇH0
‚àÇpj q,p
X
X
‚àÇH0
‚àÇ 2 H0
‚àÇ 2 H0
+
Œæk
+
Œ∑k
‚àÇpj qÃÑ,pÃÑ
‚àÇpj ‚àÇqk qÃÑ,pÃÑ
‚àÇpj ‚àÇpk qÃÑ,pÃÑ
k
k

+
pÃÑÀôj + Œ∑Ãáj = ‚àí
= ‚àí

1X
‚àÇ 3 H0
+ O(œâ ‚àí3 )
Œ∑k Œ∑`
2 k`
‚àÇpj ‚àÇpk ‚àÇp` qÃÑ,pÃÑ

‚àÇH0
‚àÇU
‚àí
sin œât
‚àÇqj q,p ‚àÇqj q,p
X
X
‚àÇ 2 H0
‚àÇ 2 H0
‚àÇH0
Œæk
Œ∑k
‚àí
‚àí
‚àÇqj qÃÑ,pÃÑ
‚àÇqj ‚àÇqk qÃÑ,pÃÑ
‚àÇqj ‚àÇpk qÃÑ,pÃÑ
k
k

‚àí

1X
‚àÇ 3 H0
‚àÇU
Œ∑k Œ∑`
‚àí sin œât
2 k`
‚àÇqj ‚àÇpk ‚àÇp` qÃÑ,pÃÑ
‚àÇqj qÃÑ

‚àí

X

Œæk sin œât

k

‚àÇ 2U
+ O(œâ ‚àí3 ).
‚àÇqj ‚àÇqk qÃÑ

(7.13)

Subtracting (7.12) from (7.13) gives
ŒæÀôj =

X

Œ∑k

k

X
‚àÇ 2 H0
‚àÇ 2 H0
Œæk
+
+
‚àÇpj ‚àÇpk qÃÑ,pÃÑ
‚àÇpj ‚àÇqk qÃÑ,pÃÑ
k

1 ‚àÇU ‚àÇU
1X
Œ∑k Œ∑` ‚àí 2
+
2 k`
2œâ ‚àÇ qÃÑk ‚àÇ qÃÑ`
Œ∑Ãáj = ‚àí sin œât

‚àí

k

‚àÇ 3 H0
+ O(œâ ‚àí3 )
‚àÇpj ‚àÇpk ‚àÇp` qÃÑ,pÃÑ

(7.14)

X
X
‚àÇU
‚àÇ 2 H0
‚àÇ 2 H0
‚àí
Œ∑k
‚àí
Œæk
‚àÇqj qÃÑ
‚àÇqj ‚àÇpk qÃÑ,pÃÑ
‚àÇqj ‚àÇqk qÃÑ,pÃÑ
k
k

1 ‚àÇU ‚àÇU
1X
Œ∑k Œ∑` ‚àí 2
‚àí
2 k`
2œâ ‚àÇ qÃÑk ‚àÇ qÃÑ`
X

!

!

‚àÇ 3 H0
‚àÇqj ‚àÇpk ‚àÇp` qÃÑ,pÃÑ

1 X ‚àÇU ‚àÇ 2 H0
Œæk sin œât ‚àí 2
2œâ ` ‚àÇq` ‚àÇpk ‚àÇp`

!

‚àÇ 2U
+ O(œâ ‚àí3(7.15)
).
‚àÇqj ‚àÇqk qÃÑ

All variables in expressions (7.14) and (7.15) are evaluated at time t. We
wish to show that over a full period œÑ = 2œÄ/œâ, Œ∑ and Œæ grow only negligibly,
that is, ‚àÜŒ∑ and ‚àÜŒæ vanish to O(œâ ‚àí3 ), for which we need the derivatives to

7.4. RAPIDLY VARYING PERTURBATIONS

225

order O(œâ ‚àí2 ). During a period, the change in qÃÑ and pÃÑ will be O(œâ ‚àí1 ), so
in evaluating the H0 and U derivative terms in which they are multiplied by
things already O(œâ ‚àí2 ), we can treat them as constants.
To lowest order in œâ ‚àí1 , we see that
Œ∑j (t0 ) =

‚àÇU
1
+ const + O(œâ ‚àí2 ).
cos œât0
œâ
‚àÇqj qÃÑ

The ambiguity in the integration constant is an ambiguity in our initial condition for pÃÑ, so we can set the constant to zero, or better yet, arranged so
that the average value of Œ∑j over one period is zero. So we require <Œ∑k > = 0.
Our expression for Œ∑j (t0 ) is good enough to integrate (7.14) for Œæj (t0 ) to order
O(œâ ‚àí3 ),
X ‚àÇU ‚àÇ 2 H0
1
Œæj (t0 ) = 2 sin œât0
+ O(œâ ‚àí3 ),
œâ
‚àÇ
qÃÑ
‚àÇp
‚àÇp
k
j
k
k
where we have again dropped the integration constant as a correction to the
initial condition for qÃÑ. Notice that the average of Œæj over one period is zero,
to the order required.
Now we are ready to find whether Œ∑ and Œæ change over the course of one
period. We will use
Z t+ œÑ
2œÄ df
2
sin œât0 f (t0 ) dt0 =
cos œât + O(œâ ‚àí3 )
2
œÑ
œâ dt
t‚àí 2
Z t+ œÑ
2œÄ df
2
cos œâtf (t) dt = ‚àí 2 sin œât + O(œâ ‚àí3 )
œÑ
œâ dt
t‚àí 2
In particular,
Z t+ œÑ

2

t‚àí œÑ2

sin œât0

X ‚àÇ 2U
2œÄ
‚àÇU
dt0 =
cos
œât
qÃák
‚àÇqj qÃÑ(t0 )
œâ2
k ‚àÇqj ‚àÇqk qÃÑ(t)

=

X ‚àÇ 2U
2œÄ
‚àÇH0
cos
œât
.
2
œâ
k ‚àÇqj ‚àÇqk qÃÑ(t) ‚àÇpk qÃÑ(t),pÃÑ(t)

We also see that
Z t+ œÑ

2

t‚àí œÑ2

Œ∑k (t0 )f (t0 ) dt0 =

Z t+ œÑ

2

t‚àí œÑ2

df
Œ∑k (t0 ) f (t) + (t0 ‚àít)
dt t
œÑ

!

dt0 + O(œâ ‚àí3 )

df Z t+ 2 0
2œÄ
<Œ∑k >f (t) +
(t ‚àí t)Œ∑k (t0 ) dt0
œâ
dt t t‚àí œÑ2
2œÄ
=
<Œ∑k >f (t) + O(œâ ‚àí3 )
œâ

=

226

CHAPTER 7. PERTURBATION THEORY

because Œ∑k (t0 ) is already O(œâ ‚àí1 ), is multiplied by something less than œÑ and
integrated over an interval of lenght œÑ .
So we can write that the changes in Œ∑ and Œæ over one period are
‚àÜŒæj =

Z t+ œÑ

2

t‚àí œÑ2

ŒæÀôj (t0 ) dt0

X
2œÄ X
‚àÇ 2 H0
‚àÇ 2 H0
<Œ∑k >
=
+
<Œæk >
œâ k
‚àÇpj ‚àÇpk qÃÑ,pÃÑ
‚àÇpj ‚àÇqk qÃÑ,pÃÑ
k
"

1X
1 ‚àÇU ‚àÇU
+
<Œ∑k Œ∑` > ‚àí 2
2 k`
2œâ ‚àÇ qÃÑk ‚àÇ qÃÑ`

‚àÜŒ∑j =

Z t+ œÑ

2

t‚àí œÑ2

= ‚àí

!

‚àÇ 3 H0
+ O(œâ ‚àí4 )
‚àÇpj ‚àÇpk ‚àÇp` qÃÑ,pÃÑ
#

Œ∑Ãáj (t0 ) dt0

‚àÇ 2 H0
2œÄ X ‚àÇ 2 U ‚àÇH0
2œÄ X
<Œ∑
>
cos
œât
‚àí
k
œâ 2 k ‚àÇqj ‚àÇqk ‚àÇpk
œâ k
‚àÇqj ‚àÇpk qÃÑ,pÃÑ
œÄX
1 ‚àÇU ‚àÇU
‚àí
<Œ∑k Œ∑` > ‚àí 2
œâ k`
2œâ ‚àÇ qÃÑk ‚àÇ qÃÑ`

!

‚àÇ 3 H0
‚àÇqj ‚àÇpk ‚àÇp` qÃÑ,pÃÑ

2œÄ X
1 X ‚àÇU ‚àÇ 2 H0
‚àí
<Œæk sin œât> ‚àí 2
œâ k
2œâ ` ‚àÇq` ‚àÇpk ‚àÇp`

!

‚àÇ 2U
+ O(œâ ‚àí4 ).
‚àÇqj ‚àÇqk qÃÑ

We need
œÑ

œâ Z t+ 2 1
1 ‚àÇU ‚àÇU
‚àÇU ‚àÇU 0
<Œ∑k Œ∑` > =
cos2 œât0
dt =
,
2
œÑ
2œÄ t‚àí 2 œâ
‚àÇqk ‚àÇq`
2œâ 2 ‚àÇqk ‚àÇq`
œÑ
X ‚àÇU ‚àÇ 2 H0
œâ Z t+ 2 1
2
0
sin
œât
dt0
<Œæk sin œât> =
2œÄ t‚àí œÑ2 œâ 2
‚àÇ
qÃÑ
‚àÇp
‚àÇp
k
j
k
k
=

1 X ‚àÇU ‚àÇ 2 H0
2œâ 2 k ‚àÇ qÃÑk ‚àÇpj ‚àÇpk

These, together with our requirement <Œ∑k > = 0, show that all the terms
vanish except
2œÄ X ‚àÇ 2 U ‚àÇH0
‚àÜŒ∑j = ‚àí 2
cos œât.
œâ k ‚àÇqj ‚àÇqk ‚àÇpk

7.4. RAPIDLY VARYING PERTURBATIONS

227

Thus the system evolves as if with the mean field hamiltonian, with with a
small added oscillatory motion which does not grow (to order œâ ‚àí2 for q(t))
with time.
We have seen that there are excellent techniques for dealing with perturbations which are either very slowly varying modifications of a system which
would be integrable were the parameters not varying, or with perturbations
which are rapidly varying (with zero mean) compared to the natural motion
of the unperturbed system.

Exercises
7.1 Consider the harmonic oscillator H = p2 /2m + 12 mœâ 2 q 2 as a perturbation
on a free particle H0 = p2 /2m. Find Hamilton‚Äôs Principle Function S(q, P ) which
generates the transformation of the unperturbed hamiltonian to Q, P the initial
position and momentum. From this, find the Hamiltonian K(Q, P, t) for the full
harmonic oscillator, and thus equations of motion for Q and P . Solve these iteratively, assuming P (0) = 0, through fourth order in œâ. Express q and p to this
order, and compare to the exact solution for an harmonic oscillator.
7.2 Consider the Kepler problem in two dimensions. That is, a particle of (reduced) mass ¬µ moves in two dimensions under the influence of a potential
K
U (x, y) = ‚àí p 2
.
x + y2
This is an integrable system, with two integrals of the motion which are in involution. In answering this problem you are expected to make use of the explicit
solutions we found for the Kepler problem.
a) What are the two integrals of the motion, F1 and F2 , in more familiar terms
and in terms of explicit functions on phase space.
b) Show that F1 and F2 are in involution.
c) Pick an appropriate Œ∑0 ‚àà Mf~, and explain how the coordinates ~t are related
to the phase space coordinates Œ∑ = g~t(Œ∑0 ). This discussion may be somewhat
qualitative, assuming we both know the explicit solutions of Chapter 3, but it
should be clearly stated.
d) Find the vectors ~ei which describe the unit cell, and give the relation between
the angle variables œÜi and the usual coordinates Œ∑. One of these should be explicit,
while the other may be described qualitatively.
e) Comment on whether there are relations among the frequencies and whether
this is a degenerate system.

228

CHAPTER 7. PERTURBATION THEORY

7.3 Consider a mass m hanging at the end of a length of string which passes
through a tiny hole, forming a pendulum. The length of string below the hole, `(t)
is slowly shortened by someone above the hole pulling on the string. How does
the amplitude (assumed small) of the oscillation of the pendulum depend on time?
(Assume there is no friction).
7.4 A particle of mass m slides without friction on a flat
ramp which is hinged at one end, at which
there is a fixed wall. When the mass hits the
wall it is reflected perfectly elastically. An external agent changes the angle Œ± very slowly
compared to the interval between successive
times at which the particle reaches a maximum height. If the angle varies from from
an initial value of Œ±I to a final value Œ±F , and
L
if the maximum excursion is LI at the beginning, what is the final maximum excursion
Œ±
1
0
1
0
LF ?
1
0

11
00
11
00
11
00
11
00
11
00
11
00
11
00
11
00
111
000
111
000
111
000

7.5 Consider a particle of mass m and charge q in the field of a fixed electric dipole
with moment p~. Using spherical coordinates with the axis in the p~ direction, the
potential energy is given by
U (~r) =

1 qp
cos Œ∏.
4œÄ0 r2

There is no explicit t or œÜ dependence, so H and pœÜ = Lz are conserved.
a) Show that
p2œÜ
qpm
+
cos Œ∏
A = p2Œ∏ +
sin2 Œ∏ 2œÄ0
is also conserved.
b) Given these three conserved quantities, what else must you show to find if this
is an integrable system? Is it true? What, if any, conditions are there for the
motion to be confined to an invariant torus?

Chapter 8
Field Theory
8.1

Lagrangian Mechanics for Fields

In sections 5.3 and 5.4 we considered the continuum limit of a chain of point
masses on stretched string. We had a situation in which the potential energy
had interaction terms for particle A which depended only on the relative displacements of particles in the neighborhood of A. If we take our coordinates
to be displacements from equilibrium, and consider only motions for which
the displacement Œ∑ = Œ∑(x, y, z, t) becomes differentiable in the continuum
limit, then the leading term in the potential energy is proportional to the
square of derivatives in the spatial coordinates. For our points on a string at
tension œÑ , with mass density œÅ, we found
1 ZL 2
yÃá (x)dx,
œÅ
T =
2 0
!2
œÑ Z L ‚àÇy
U =
dx,
2 0 ‚àÇx
and we can write the Lagrangian as an integral of a Lagrangian density
L(y, yÃá, y 0 , x, t) over x. Actually for our stringR we had no y or x or t dependence, because we ignored gravity Ug = œÅgy(x, t)dx, and had a homogeneous string whose properties were also time independent. In general,
however, such dependence is quite possible. For a three dimensional object,
such as the equations for the displacement of the atoms in a crystal, we
discussed fields ~Œ∑ , the three components of the displacement of a particle,
as a function of the three coordinates (x, y, z) determining the particle, as
229

230

CHAPTER 8. FIELD THEORY

well as time. Thus the generalized coordinates are the functions Œ∑i (x, y, z, t),
and the Lagrangian density will depend on these, their gradients, their time
derivatives, as well as possibly on x, y, z, t. Thus
L = L(Œ∑i ,

‚àÇŒ∑i ‚àÇŒ∑i ‚àÇŒ∑i ‚àÇŒ∑i
,
,
,
, x, y, z, t)
‚àÇx ‚àÇy ‚àÇz ‚àÇt

and
L =
I =

Z
Z

dx dy dz L,
dx dy dz dt L.

The actual motion of the system will be given by a particular set of
functions Œ∑i (x, y, z, t), which are functions over the volume in question and
of t ‚àà [tI , tf ]. The function will be determined by the laws of dynamics of
the system, together with boundary conditions which depend on the initial
configuration Œ∑i (x, y, z, tI ) and perhaps a final configuration. Generally there
are some boundary conditions on the spatial boundaries as well. For example,
our stretched string required y = 0 at x = 0 and x = L.
Before taking the continuum limit we say that the configuration of the
system at a given t was a point in a large N dimensional configuration space,
and the motion of the system is a path Œì(t) in this space. In the continuum
limit N ‚Üí ‚àû, so we might think of the path as a path in an infinite dimensional space. But we can also think of this path as a mapping t ‚Üí Œ∑(¬∑, ¬∑, ¬∑, t)
of time into the (infinite dimensional) space of functions on ordinary space.
Hamilton‚Äôs principal says that the actual path is an extremum of the
action. If we consider small variations Œ¥Œ∑i (x, y, z, t) which vanish on the
boundaries, then
Z
Œ¥I =

dx dy dz dt Œ¥L = 0

determines the equations of motion.
Note that what is varied here are the functions Œ∑i , not the coordinates
(x, y, z, t). x, y, z do not represent the position of some atom ‚Äî they represent
a label which tells us which atom it is that we are talking about. They may
well be the equilibrium position of that atom, but they are independent of the
motion. It is the Œ∑i which are the dynamical degrees of freedom, specifying
the configuration of the system. In our discussion of section 5.4 Œ∑i specified

8.1. LAGRANGIAN MECHANICS FOR FIELDS

231

the displacement from equilibrium, but here we generalize to an arbitrary set
of dynamical fields1 .
The variation of the Lagrangian density is
‚àÇŒ∑i ‚àÇŒ∑i ‚àÇŒ∑i ‚àÇŒ∑i
,
,
,
, x, y, z, t)
‚àÇx ‚àÇy ‚àÇz ‚àÇt
‚àÇL
‚àÇL
‚àÇŒ∑
‚àÇL
‚àÇŒ∑
‚àÇL
‚àÇŒ∑
=
Œ¥Œ∑ +
Œ¥
+
Œ¥
+
Œ¥
‚àÇŒ∑
‚àÇ(‚àÇŒ∑/‚àÇx) ‚àÇx ‚àÇ(‚àÇŒ∑/‚àÇy) ‚àÇy ‚àÇ(‚àÇŒ∑/‚àÇz) ‚àÇz
‚àÇL
‚àÇŒ∑
+
Œ¥ .
‚àÇ(‚àÇŒ∑/‚àÇt) ‚àÇt

Œ¥L(Œ∑i ,

Notice there is no variation of x, y, z, and t, as we discussed.
The notation is getting awkward, so we need to reintroduce the notation
A,i = ‚àÇA/‚àÇri . In fact, we see that ‚àÇ/‚àÇt enters in the same way as ‚àÇ/‚àÇx,
so it is time to introduce notation which will become crucial when we consider relativistic dynamics, even though we are not doing so here. So we
will consider time to be an additional component of the position, called the
zeroth rather than the fourth component. We will also change our notation
for coordinates to anticipate needs from relativity, by writing the indices of
coordinates as superscripts rather than subscripts. Thus we write x0 = ct,
where c will eventually be taken as the speed of light, but for the moment
is an arbitrary scaling factor. Until we get to special relativity, one should
consider whether an index is raised or lowered as irrelevant, but they are
written here in the place which will be correct once we make the distinction
between them. In particular the Kronecker delta is now written Œ¥¬µ ŒΩ . For the
partial derivatives we now have
‚àÇ
=
‚àÇ¬µ :=
‚àÇx¬µ

!

‚àÇ ‚àÇ ‚àÇ ‚àÇ
, , ,
,
c‚àÇt ‚àÇx ‚àÇy ‚àÇz

for ¬µ = 0, 1, 2, 3, and write Œ∑,¬µ := ‚àÇ¬µ Œ∑. If there are several fields Œ∑i , then
‚àÇ¬µ Œ∑i = Œ∑i,¬µ . The comma represents the beginning of differentiation, so we
must not use one to separate different ordinary indices.
In this notation, we have
Œ¥L =

X ‚àÇL
i

1

‚àÇŒ∑i

Œ¥Œ∑i +

3
XX

‚àÇL
Œ¥Œ∑i,¬µ ,
i ¬µ=0 ‚àÇŒ∑i,¬µ

Note in particular that {Œ∑i } is not the set of coordinates of phase space as it was in
the last chapter.

232

CHAPTER 8. FIELD THEORY

and
Œ¥I =

Z

Ô£´
3
X ‚àÇL
XX
Ô£≠
Œ¥Œ∑i +
i

Ô£∂

‚àÇL
Œ¥Œ∑i,¬µ Ô£∏ d4 x,
i ¬µ=0 ‚àÇŒ∑i,¬µ

‚àÇŒ∑i

where d4 x = dx dy dz dt. Except for the first term, we integrate by parts,
Œ¥I =

Z

Ô£Æ
3
X ‚àÇL
XX
Ô£∞
‚àí
i

‚àÇŒ∑i

i ¬µ=0

!Ô£π

‚àÇL Ô£ª
‚àÇ¬µ
Œ¥Œ∑i d4 x,
‚àÇŒ∑i,¬µ

where we have thrown away the boundary terms which involve Œ¥Œ∑i evaluated
on the boundary, which we assume to be zero. Inside the region of integration,
the Œ¥Œ∑i are independent, so requiring Œ¥I = 0 for all functions Œ¥Œ∑i (x¬µ ) implies
‚àÇ¬µ

‚àÇL
‚àÇL
‚àí
= 0.
‚àÇŒ∑i,¬µ ‚àÇŒ∑i

(8.1)

We have written the equations of motion (which are now partial differential equations rather than coupled ordinary differential equations), in a
form which looks like we are dealing with a relativistic problem, because t
and spatial coordinates are entering in the same way. We have not made
any assumption of relativity, however, and our problem will not be relativistically invariant unless the Lagrangian density is invariant under Lorentz
transformations (as well as translations).
Now consider how the Lagrangian changes from one point in space-time
to another, including the variation of the fields, assuming the fields obey the
equations of motion. Then the total derivative for a variation of x¬µ is
‚àÇL
‚àÇL
‚àÇL
dL
=
+
Œ∑i,¬µ +
Œ∑i,ŒΩ,¬µ .
¬µ
¬µ
dx
‚àÇx Œ∑ ‚àÇŒ∑i
‚àÇŒ∑i,ŒΩ
As we did previously with d/dt, we are using ‚Äútotal‚Äù derivative notation
d/dx¬µ to represent the variation from a change in one x¬µ , including the
changes induced in the fields which are the arguments of L, though it is still
a partial derivative in the sense that the other three xŒΩ need to be held fixed
while varying x¬µ .
Plugging the equations of motion into the second term,
dL
‚àÇL X
=
+
‚àÇŒΩ
dx¬µ
‚àÇx¬µ
i

‚àÇL
‚àÇŒ∑i,ŒΩ

!

Œ∑i,¬µ +

X
i

!

X
‚àÇL
‚àÇL
=
+ ‚àÇŒΩ
Œ∑i,¬µ .
¬µ
‚àÇx
‚àÇŒ∑i,ŒΩ
i

‚àÇL
Œ∑i,¬µ,ŒΩ
‚àÇŒ∑i,ŒΩ

8.1. LAGRANGIAN MECHANICS FOR FIELDS

233

Thus
‚àÇL
,
‚àÇx¬µ
where the stress-energy tensor T¬µ ŒΩ is defined by
‚àÇŒΩ T¬µ ŒΩ = ‚àí

T¬µ ŒΩ (x) =

X
i

‚àÇL
Œ∑i,¬µ ‚àí LŒ¥¬µ ŒΩ .
‚àÇŒ∑i,ŒΩ

(8.2)

(8.3)

We will often talk about T¬µ ŒΩ as a function of xœÅ , understanding that x dependence to include the implicit dependence through the fields, for T is a
function of x¬µ , Œ∑i (x) and Œ∑i,¬µ (x). It is that total derivative that we are evaluating on the left of equation (8.2), despite the use of partial derivative
notation. But the partial derivatives on the right of that equation do not
include the variations through the fields. Sorry about that, it is just the way
it is.
Note that if the Lagrangian density has no explicit dependence on the
coordinates x¬µ , equation (8.2) tells us the stress-energy tensor satisfies an
equation ‚àÇŒΩ T¬µ ŒΩ = 0 which is a continuity equation.
What does that mean? In fluid mechanics, we have the equation of continuity
~ ¬∑ (œÅ~v ) = 0,
‚àÇœÅ/‚àÇt + ‚àá
which expresses the conservation of mass. That equation has the interpretation that the rate of change in the mass contained in some volume is equal
to the flux into the volume, because œÅ~v is the flow of mass outward past a
unit surface area. In general, if we have a scalar field œÅ(~x, t) which, together
with a vector field ~j(~x, t), satisfies the equation
‚àÇœÅ
(~x, t) + ‚àá ¬∑ ~j(~x, t) = 0,
‚àÇt

(8.4)

we can interpret œÅ as the density of, and ~j as the flow of, a material property
which is conserved. Given any volume V with a boundary
surfaceR S, the rate
R
~ = ‚àá ¬∑ ~j dV ,
at which this property is flowing out of the volume, S ~j ¬∑ dS
V
is the rate Rat which the total amount of the substance in the volume is
decreasing, V ‚àí(dœÅ/dt)dV . If we define j 0 = cœÅ, we can rewrite this equation
P
of continuity (8.4), as ŒΩ ‚àÇŒΩ j ŒΩ = 0, and we say that j ŒΩ is a conserved current2 .
2

More accurately, the set of four fields j ŒΩ (~x, t) is a conserved current.

234

CHAPTER 8. FIELD THEORY

If we integrate over
the whole volume of our field, we can define a total
R
0
‚Äúcharge‚Äù Q(t) = V j (~x, t)/c d3 x, and its time derivative is
Z
Z
Z
d
dœÅ
3
3
~
~
Q(t) =
(~x, t) d x = ‚àí
‚àá ¬∑ j(~x, t) d x = ‚àí ~j ¬∑ dS.
dt
V dt
V
S

We see that this is the integral of the divergence of a vector current ~j, which
by Gauss‚Äô law becomes a surface integral of the flux of j out of the volume
of our system. We have been sloppy about our boundary conditions, but
in many cases it is reasonable to assume there is no flux out of the entire
volume, either because of boundary conditions, as in a stretched string, or
because we are working in an infinite space and expect any flux to vanish at
infinity. Then the surface integral vanishes, and we find that the charge is
conserved.
We have seen that when the lagrangian density has no explicit x¬µ dependence, for each value of ¬µ, T¬µ ŒΩ represents such a conserved current. Thus
we should have four conserved currents (J¬µ )ŒΩ := T¬µ ŒΩ , each of which gives a
conserved ‚Äúcharge‚Äù
Q¬µ (t) =

Z
V

T¬µ 0 (~x, t) d3 x = constant.

We will return to what these conserved quantities are in a moment.
In dynamics of discrete systems we defined the momenta pi = ‚àÇL/‚àÇ qÃái ,
P
and defined the Hamiltonian as H = i pi qÃái ‚àí L(q, p, t). In considering the
continuum limit of the loaded string, we noted that the momentum corresponding to each point particle (of vanishing mass) disappears in the limit,
but the appropriate thing to do is define a momentum density
Œ¥ Z
‚àÇL
Œ¥
P (x) =
L=
L(y(x0 ), yÃá(x0 ), x0 , t)dx0 =
,
Œ¥ yÃá(x)
Œ¥ yÃá(x)
‚àÇ yÃá x
Œ¥
having defined both the ‚Äúvariation at a point‚Äù Œ¥yÃá(x)
and the lagrangian density
L. In considering
the
three
dimensional
continuum
as a limit, say on a cubic
R 3
P
lattice, L = d xL is the limit of ijk ‚àÜx‚àÜy‚àÜzLijk , where Lijk depends on
~Œ∑ijk and a few of its neighbors, and also on ~Œ∑Àô ijk . The conjugate momentum
to ~Œ∑ (i, j, k) is p~ijk = ‚àÇL/‚àÇ ~Œ∑Àô ijk = ‚àÜx‚àÜy‚àÜz‚àÇLijk /‚àÇ ~Œ∑Àô ijk , which would vanish
in the continuum limit. So we define instead the momentum density

œÄ` (x, y, z) = (~pijk )` /‚àÜx‚àÜy‚àÜz = ‚àÇLijk /‚àÇ(~Œ∑Àô ijk )` = ‚àÇL/‚àÇ Œ∑Ãá` (x, y, z).

8.1. LAGRANGIAN MECHANICS FOR FIELDS

235

The Hamiltonian
H =
=

X
Z

p~ijk ¬∑ ~Œ∑Àô ijk ‚àí L =

X



‚àÜx‚àÜy‚àÜz~œÄ (x, y, z) ¬∑ ~Œ∑Àô (xyz) ‚àí L



d3 x ~œÄ (~r) ¬∑ ~Œ∑Àô (~r) ‚àí L =

Z

d3 x H,

where the Hamiltonian density is defined by H(~r) = ~œÄ (~r) ¬∑ ~Œ∑Àô (~r) ‚àí L(~r).
This assumed the dynamical fields were the vector displacements ~Œ∑ (~r, t), but
the same discussion applies to any set of dynamical fields Œ∑` (~r, t), even if Œ∑
refers to some property other than a displacement. Then
H(~r) =

X

œÄ` (~r)Œ∑Ãá` (~r) ‚àí L(~r).

`

where
œÄ` (~r) =

‚àÇL
1 ‚àÇL
=
.
‚àÇ Œ∑Ãá` (~r)
c ‚àÇŒ∑`,0 (~r)

Notice from (8.3) that T¬µ 0 = c ` œÄ` Œ∑`,¬µ ‚àí Œ¥¬µ 0 L, and in particular T0 0 =
P
` œÄ` Œ∑Ãá` ‚àí L = H is the Hamiltonian density, which we see is one component
of the stress-energy tensor.
Consider again the case where L does not depend explicitly on (~x, t),
P3
so ŒΩ=0 ‚àÇŒΩ T¬µ ŒΩ = 0, which, as we have seen, tells us that the four currents (J
)ŒΩ := T ŒΩ are conserved currents, leading to conserved ‚Äúcharges‚Äù
R ¬µ 0 3 ¬µ
Q¬µ = V T¬µ d x. For ¬µ = 0, T00 is the hamiltonian density, so under appropriate conditions Q0 is the conserved total energy. Then T0 j should be the j
component of the flow of energy. As an example, let‚Äôs return to thinking of Œ∑i
as the displacement, and make the small deviation approximation of section
~ of the surface of a volume V , then the
5.4. If we consider a small piece dS
P
inside is exerting a force dFi = j Pij dSj on the outside, and if the surface
P
~ But
is moving with velocity ~v , the inside is doing work i vi dFi = ~v ¬∑ P ¬∑ dS.
~v = d~Œ∑ /dt or vi = cŒ∑i,0 , so energy is flowing out of the volume at a rate
P

Z
Z X
dE
~
‚àí
= c ~Œ∑,0 ¬∑ P ¬∑ dS = c
‚àÇj (Œ∑i,0 Pij ))
dt
S
V ij

= c

Z X
V

j

j

‚àÇj T0 = c

Z X
V

ij

‚àÇj

‚àÇL
Œ∑i,0
‚àÇŒ∑i,j

!

236

CHAPTER 8. FIELD THEORY

which encourages us to conclude
Pij =

‚àÇL
.
‚àÇŒ∑i,j

A force on the surface of our volume transfers not only energy but also
momentum. In fact, the force A exerts on B represents the rate of momentum
transfer from A to B, and the force per unit area across a surface gives the
flux of momentum across that surface. As the outside is exerting a force
P
‚àídFi = ‚àí j Pij dSj on the inside, this force will cause the momentum Pi of
the inside of the volume to be changing at a rate
Z X
Z X
Z
X
‚àÇL
d
Pi =
‚àí
Pij dSj = ‚àí
‚àÇj Pij = ‚àí
‚àÇj
dt
‚àÇŒ∑i,j
V j
V j
S
j

=

Z
V

d ‚àÇL
cdt ‚àÇŒ∑i,0

!

‚àí

‚àÇL
,
‚àÇŒ∑i

where in the last step we used the equations of motion. If it were not for
the last term, we would take this as expected, because we would expect, if
the Lagrangian is of the usual form, that the momentum density would be
‚àÇL
‚àÇL
= ‚àÇcŒ∑
. We will return to the interpretation of this last term after we
‚àÇ Œ∑Ãái
i,0
discuss what happens in its absence.
Cyclic coordinates
In discrete mechanics, when L was independent of a coordinate qi , even
though it depended on qÃái , we called the coordinate cyclic or ignorable, and
found a conserved momentum conjugate to it. In particular, if we use the
center-of-mass coordinates in an isolated system those will be ignorable coordinates and the conserved momentum of the system will be their conjugate
variables. In field theory, however, the center of mass is not a suitable dynamical variable. The variables are not ~x but Œ∑i (~x, t). For fields in general,
L(Œ∑, Œ∑Ãá, ‚àáŒ∑) depends on spatial derivates of Œ∑ as well, and we may ask whether
we need to require absence of dependence on ‚àáŒ∑ for a coordinate to be cyclic.
Independence of both Œ∑ and ‚àáŒ∑ implies independence on an infinite number of discrete coordinates, the values of Œ∑(~r) at every point ~r, which is too
restrictive a condition for our discussion. We will call a coordinate field Œ∑i
cyclic if L does not depend directly on Œ∑i , although it may depend on its
derivatives Œ∑Ãái and ‚àáŒ∑i .

8.1. LAGRANGIAN MECHANICS FOR FIELDS

237

The Lagrange equation then states
X
¬µ

‚àÇ¬µ

‚àÇL
= 0,
‚àÇŒ∑i,¬µ

or

X
d
‚àÇL
œÄi +
= 0,
‚àÇj
dt
‚àÇŒ∑i,j
j

which constitutes continuity equations for the densities œÄi (~r, t) and currents
(~ji )` = ‚àÇL/‚àÇŒ∑i,j . If we integrate this equation over all space, and define
Œ†i (t) =

Z

œÄi (~r)d3 r,

then the derivative dŒ†/dt involves the integral of a divergence, which by
Gauss‚Äô law is a surface term
Z
dŒ†(t)
‚àÇL
=‚àí
(dS)j .
dt
‚àÇŒ∑i,j

If we assume the spatial boundary conditions are such that we may ignore this
boundary term, we see that the Œ†i (t) will be constants of the motion. These
are the total canonical momentum conjugate to Œ∑, and not, except when Œ∑
represents a displacement, the components of the total ordinary momentum
of the system.
If we considered our continuum with Œ∑i representing the displacement, and
placed
it in a gravitational field, we would have an additional potential energy
R
V œÅgŒ∑3 , and our equation for dœÄi /dt would have an extra term corresponding
to the volume force:
Ô£´

Ô£∂

X
‚àÇL Ô£∏
dœÄi
‚àÇL
‚àÇj
,
= ‚àÜV Ô£≠‚àí
+
Fivol + Fisurf = ‚àÜV
dt
‚àÇŒ∑i,j
‚àÇŒ∑ i
j

so
Fivol = ‚àÜV

‚àÇL
= ‚àíœÅgeÃÇz ‚àÜV,
‚àÇŒ∑ i

as expected, and the total momentum is not conserved.
From equation (8.3) we found that if L is independent of ~x, the stressenergy tensor gives conserved currents. Linear momentum conservation in
field dynamics is connected not to ignorable coordinates but to a lack of
dependence on the labels. This is best viewed as an invariance under a
transformation of all the fields, Œ∑i (~x) ‚Üí Œ∑i (~x + ~a), for a constant vector
~a. This is a change in the integrand which can be undone by a change in

238

CHAPTER 8. FIELD THEORY

the variable of integration, ~x ‚Üí ~x 0 = ~x + ~a, under which the Lagrangian
is unchanged if the integration is over all space and the Lagrangian density
does not depend explicitly on ~x. This is a special case of conserved quantities
arising because of symmetries, a topic we will pursue in the next section.
Before we do so, let us return to our treatment of elasticity in the linear
continuum approximation of a solid, with the dynamical fields being the
displacements Œ∑i (~x, t). We saw that the stress tensor Pij = ‚àÇŒ∑‚àÇLi,j , and if we
intend to describe a material obeying the generalized Hooke‚Äôs law,
Œ±‚àíŒ≤
Œ±‚àíŒ≤ X
Œ≤
‚àÇL
= Pij = ‚àí
Œ¥ij Tr S ‚àí Œ≤Sij = ‚àí
Œ¥ij
Œ∑k,k ‚àí (Œ∑i,j + Œ∑j,i ) .
‚àÇŒ∑i,j
3
3
2
k
This suggests a term in the Lagrangian
Œ≤‚àíŒ± X
Œ∑k,k
L1 =
6
k

!2

‚àí

Œ≤
(Œ∑i,j + Œ∑j,i )2 .
8

We will also need a kinetic energy term to give a momentum density, which
we would expect to be just ~œÄ = œÅ~Œ∑Àô , so we take that term to be
L2 =

c2 X 2
Œ∑ .
œÅ
2 i i,0

~ r) due to some external potential ‚àí~Œ∑ ¬∑ E,
~
Finally, if we have a volume force E(~
~ Thus our total lagrangian density is
this will be from L3 = ~Œ∑ ¬∑ E.
c2 X 2
Œ≤‚àíŒ± X
L= œÅ
Œ∑i,0 +
Œ∑k,k
2 i
6
k

!2

‚àí

Œ≤
~
(Œ∑i,j + Œ∑j,i )2 + ~Œ∑ ¬∑ E.
8

Now
Œ≤‚àíŒ± X
Œ≤
‚àÇL
=
Œ¥ij
Œ∑k,k ‚àí (Œ∑i,j + Œ∑j,i )
‚àÇŒ∑i,j
3
2
k
‚àÇL
= c2 œÅŒ∑i,0
‚àÇŒ∑i,0
‚àÇL
= Ei
‚àÇŒ∑i
so the equations of motion are
"

#

X Œ≤‚àíŒ±
X
‚àÇL
‚àÇL
Œ≤
0 = ‚àÇ¬µ
‚àí
= œÅŒ∑Ãài +
Œ¥ij
Œ∑k,k,j ‚àí (Œ∑i,j,j + Œ∑j,i,j ) ‚àí Ei ,
‚àÇŒ∑i,¬µ ‚àÇŒ∑i
3
2
j
k

8.2. SPECIAL RELATIVITY

239

or
œÅ~Œ∑¬® =

!

Œ± Œ≤
Œ≤
~
+
‚àá(‚àá ¬∑ ~Œ∑ ) + ‚àá2 ~Œ∑ + E,
3
6
2

in agreement with (5.6).

8.2

Special Relativity

We have commented several times that a continuous symmetry of the dynamics, such as invariance under translation or rotation, is reflected in conservation laws. We will give a formal development of Noether‚Äôs theorem, which
makes this connection generally, in the next section. When we do that, we
will certainly want to consider relativistic invarinance, so first we will revise
and clarify our notation appropriately.
So we now consider the symmetry known as special relativity, the postulate that the laws of physics are equally valid in all inertial reference frames.
We will assume familiarity with the basic ideas3 , so we will only deal with notational issues here. The relation of coordinates in different inertial reference
frames is determined by the invariance of
(ds)2 = ‚àíc2 (dt)2 + (dx)2 + (dy)2 + (dz)2 ,
where c is the speed of light in vacuum. This looks something like the
Pythagorian length, except that the time component is scaled and has the
wrong sign. The scaling is not a problem, we could just choose to define
x0 = ct and measure time with x0 in meters. Then we can treat the spacetime coordinates as a four-vector4 x¬µ = (ct, x, y, z). The minus sign is more
significant, so that (ds)2 is not a true length. We introduce the Minkowski
metric tensor
Ô£´
Ô£∂
‚àí1 0 0 0
Ô£¨ 0
1 0 0Ô£∑
Ô£¨
Ô£∑
Œ∑¬µŒΩ = Ô£¨
Ô£∑
Ô£≠ 0
0 1 0Ô£∏
0 0 0 1
3

The student who has not learned about Einstein‚Äôs theory is referred to Smith ([15])
or French ([5]) for elementary introductions.
4
Actually x¬µ is a position in space-time and not truly a vector, a distinction discussed
in section (1.2.1) but not important here.

240

CHAPTER 8. FIELD THEORY

so we can write5
(ds)2 =

X

Œ∑¬µŒΩ dx¬µ dxŒΩ .

¬µŒΩ
¬µ

Notice we have defined x with superscripts rather than subscripts, and any
vector (or tensor) with such indices is said to be contravariant. From any
such vector V ¬µ we can also define a covariant vector
V¬µ =

X

Œ∑¬µŒΩ V ŒΩ .

ŒΩ

This is a somewhat trivial distinction in special relativity, only changing the
sign of the zeroth component6 . But it is useful, because it enables us to define
P
an invariant inner product ¬µ V¬µ W ¬µ . One can also make a contravariant
P
vector from a covariant one, W ¬µ = ŒΩ Œ∑ ¬µŒΩ WŒΩ , where Œ∑ ¬µŒΩ is the inverse7 , as
a matrix, of Œ∑¬µŒΩ . We will also redefine the Einstein summation convention:
an index which occurs twice is summed over only if it appears once upper
and once lower. (Otherwise it is probably a mistake!) We also redefine what
we mean by the square of a vector V ¬µ : V 2 := Œ∑¬µŒΩ V ¬µ V ŒΩ = V¬µ V ¬µ and not
P
¬µ 2
¬µ (V ) .
The relationship between coordinates in different inertial frames,
x0 ¬µ = Œõ¬µŒΩ xŒΩ
is given by the Lorentz transformation matrix Œõ¬µŒΩ . The invariance of (ds)2
tells us
Œ∑¬µŒΩ Œõ¬µœÅ ŒõŒΩ œÉ = Œ∑œÅœÉ ,
(8.5)
which says that Œõ is pseudo-orthogonal.
We have defined position to be naturally described by a contravariant
vector, but some objects are naturally defined as covariant. In particular,
the partial derivative operator
‚àÇ¬µ =
5

‚àÇ
is, for ‚àÇ¬µ xŒΩ = Œ¥¬µŒΩ .
¬µ
‚àÇx

Note that this is not a two-form, as Œ∑ is symmetric.
In general relativity Œ∑¬µŒΩ is replaced by the metric tensor g¬µŒΩ which is a dynamical
degree of freedom of space-time rather than a fixed matrix, and this distinction becomes
less P
trivial.
7
¬µœÅ
¬µ
œÅ Œ∑ Œ∑œÅŒΩ = Œ¥ ŒΩ = 1 if ¬µ = ŒΩ and 0 otherwise. Note the Kronecker delta function
needs one upper and one lower index in order to be properly covariant, and in fact it and
Œ∑ are different forms of the same tensor, using the usual lowering or raising procedures
with Œ∑. Don‚Äôt be misled by the fact that for each ¬µ and ŒΩ, Œ∑ ¬µŒΩ is the same as Œ∑¬µŒΩ .
6

8.2. SPECIAL RELATIVITY

241

With this four dimensional notation we see that time translation and
spatial translations are unified in x¬µ ‚Üí x¬µ + c¬µ , and rotations are just special
cases of Lorentz transformations, with
1
Ô£¨
0
Œõ¬µ ŒΩ = Ô£¨
Ô£≠0
0
Ô£´

0 0 0

Ô£∂

R

Ô£∑
Ô£∑.
Ô£∏

As for rotations, we may ask how objects transform under Lorentz transformations. For rotations, we saw that in addition to scalars and vectors, we
may have tensors with multiple indices. The same is true in relativity ‚Äî a
large class of covariant objects may be written in terms of multiple indices,
and the transformation properties are simply multiplicative. First of all,
how does a covariant vector transform? From V 0 ¬µ = Œõ¬µŒΩ V ŒΩ and the lowered
forms VœÅ0 = Œ∑œÅ¬µ V 0 ¬µ = Œ∑œÅ¬µ Œõ¬µŒΩ V ŒΩ = Œ∑œÅ¬µ Œõ¬µŒΩ Œ∑ ŒΩœÉ VœÉ , we see that V 0 ¬µ = ŒõœÅœÉ VœÉ ,
where we have used Œ∑‚Äôs to lower and raise the indices on the Lorentz matrix,
ŒõœÅœÉ = Œ∑œÅ¬µ Œõ¬µŒΩ Œ∑ ŒΩœÉ . So we see that covariant indices transform with ŒõœÅœÉ . Note
that ŒõœÅœÉ ŒõœÅœÑ = Œ∑œÅ¬µ Œõ¬µŒΩ Œ∑ ŒΩœÉ ŒõœÅœÑ = Œ∑œÑ ŒΩ Œ∑ ŒΩœÉ = Œ¥œÑœÉ , so ŒõœÅœÉ = (Œõ‚àí1 )œÉœÅ . Note also
that the order of indices matters, Œõ¬µŒΩ 6= ŒõŒΩ ¬µ .
Now more generally we may define a multiply-indexed tensor
¬µ ...¬µ
¬µ
...¬µ
T 1 jŒΩ1 ...ŒΩk j+1 ` and it will transform with each index suitably transformed:
T

k
`
Y
Y
¬µ0j+1 ...¬µ0`
0 ¬µ01 ...¬µ0j
¬µ0i
ŒΩ
ŒõŒΩn0 n T ¬µ1 ...¬µjŒΩ1 ...ŒΩk ¬µj+1 ...¬µ` .
Œõ
=
0
0
¬µi
ŒΩ1 ...ŒΩk
n=1
i=1

(8.6)

If we contract two indices, they don‚Äôt contribute to the transformation:
T 0¬µ ¬µ = Œõ¬µŒΩ Œõ¬µœÅ TŒΩ œÅ = (Œõ‚àí1 )ŒΩ ¬µ Œõ¬µœÅ TŒΩ œÅ = Œ¥œÅŒΩ TŒΩ œÅ = TŒΩ ŒΩ .
So we see that we can make an invariant object (a scalar) by contracting
all indices. We should mention that in addition to tensors, another possible
transformation possibility is that of a spinor, but we will not explore that
here.
For a point particle, the momentum three-vector is coupled by Lorentz
transformation to the energy8 , P ¬µ = (E/c, p~). Then we see that to make an
8

Why P 0 rather than P0 for the energy? In quantum mechanics we have p~ associated
~ and a partial derivative is naturally covariant. But
with the gradient operator, p~ = ‚àíihÃÑ‚àá,
the energy is H = ihÃÑ‚àÇ/‚àÇt, because SchroÃàdinger arbitrarily chose that sign when he wrote
down his equation. So if we write P¬µ = ‚àíihÃÑ‚àÇ/‚àÇx¬µ , we have P¬µ = (‚àíE/c, p~).

242

CHAPTER 8. FIELD THEORY

invariant,
P ¬µ P ŒΩ Œ∑¬µŒΩ = p~ 2 ‚àí E 2 /c2 = ‚àím2 c2 .
We are going to be interested in infinitesimal Lorentz transformations,
with Œõ¬µŒΩ = Œ¥ŒΩ¬µ + L¬µŒΩ . From the condition (8.5) for Œõ to be a Lorentz
transformation, we have








Œ∑¬µŒΩ Œ¥œÅ¬µ + L¬µœÅ (Œ¥œÉŒΩ + LŒΩ œÉ ) = Œ∑œÅœÉ +  Œ∑¬µœÉ L¬µœÅ + Œ∑œÅŒΩ LŒΩ œÉ + O(2 ) = Œ∑œÅœÉ ,
so
Œ∑¬µœÉ L¬µœÅ + Œ∑œÅŒΩ LŒΩ œÉ = LœÉœÅ + LœÅœÉ = 0,
so the condition is that L is antisymmetric when its indices are both lowered.
Thus L is a 4 √ó 4 antisymmetric real matrix, and has 6 independent parameters, and the infinitesimal Lorentz transformations form a 6 dimensional Lie
algebra.
Now we are ready to discuss symmetries more generally.

8.3

Noether‚Äôs Theorem

We have seen in several ways that there is a connection between conserved
quantities and an invariance of the dynamics under some continuous transformations. First we saw, in discrete dynamics, that ignorable coordinates
have conserved conjugate momenta. A coordinate is ignorable if the Lagrangian is unchanged under its translation, œÜ ‚Üí œÜ + c, for arbitrary c. In
particular invariance under translation of all coordinates ~rj ‚Üí ~rj +~c leads to
conservation of the total momentum. In field theory momentum conservation
is not associated with ignorable field coordinates, but rather to invariance
under translations of the labels, that is, under Œ∑` (~r) ‚Üí Œ∑` (~r + ~c), which is
a consequence of ~r being an integration variable, so changing it makes no
difference as long as L has no explicit dependence on it, and as long as we
are integrating over all ~r. For rotations in discrete mechanics we saw that
~ could be considered conserved because œÜ is ignorable,
one component of L
but the other two components, which are also conserved, must be attributed
to a less obvious symmetry, that of rotations about directions other than z.
Now we will discuss more generally the relationship between symmetries
and conserved quantities, a general connection given in a famous theorem
by Emmy Noether9 . Symmetry means the dynamics is unchanged under
9

This section relies heavily on Goldstein, ‚ÄúClassical Mechanics‚Äù, 2nd Ed., section 12-7.

8.3. NOETHER‚ÄôS THEOREM

243

a change in the values of the degrees of freedom Œ∑ ‚Üí Œ∑ 0 which will in general
depend on those degrees of freedom. In the discrete case the dependence is
commonly on a related set, such as the new x component of the electric field
experienced by a point charge being dependent on all three old components
under a general rotation. In the case of fields, it would in principle be possible for the new field Œ∑`0 (~x) to depend on all the values of all fields at all
points in space, but this is not useful to consider. We might consider only
local symmetries, for which it depends only on the old fields at the same
point, Œ∑k0 (~x), which might for example be the case for considering the spins
of atoms under rotation of all the spins. But if we want to consider the more
fundamental symmetry under a true rotation, for which the atoms are also
rotating, we need to consider a symmetry which relates new fields at x0 to
old fields at x, where the symmetry maps x ‚Üí x0 as well as transforming
the fields. Then we find that the new field Œ∑`0 (~x 0 ) depends on the old fields
at a different point ~x. This is what we have in the case of translation we
just discussed, as well as for rotations and other possible symmetries. These
symmetries may be thought of in a passive sense as having the physics unchanged when we translate, rotate, or boost (in a relativistic theory) the
coordinate system describing the physics. Then the new coordinates x0¬µ describe the same physical point as the old x¬µ , with a definite map Œ¶ : x 7‚Üí x0
which describes the change of coordinates of space(time). While the physics
at that point is unchanged, its description in terms of fields may be, so we
need to consider a rule for transforming the fields, which gives Œ∑` (x0¬µ ) as a
function of fields at xŒΩ .
We will only be concerned with continuous symmetries, which can be generated by infinitesimal transformations, so we can consider an infinitesimal
transformation with x0¬µ = x¬µ + Œ¥x¬µ , along with a rule that gives the change
of Œ∑`0 (x0¬µ ) from the set of Œ∑k (xŒΩ ). For a scalar field, like temperature, under a
rotation, we would define the new field
Œ∑ 0 (x0 ) = Œ∑(x),
but more generally the field may also change, in a way that may depend on
other fields,
Œ∑i0 (x0 ) = Œ∑i (x) + Œ¥Œ∑i (x; Œ∑k (x)).
~ under rotations, because
This is what you would expect for a vector field E
0
the new Ex gets a component from the old Ey .

244

CHAPTER 8. FIELD THEORY

To say that
x¬µ ‚Üí x0¬µ ,

Œ∑i ‚Üí Œ∑i0

is a symmetry means, at the least, that if Œ∑i (x) is a specific solution of the
equations of motion, the set of transformed fields Œ∑i0 (x0 ) is also a solution.
The equations of motion are determined by varying the action, so if the
corresponding actions are equal for each pair of configurations (Œ∑(x), Œ∑ 0 (x0 )),
so are the equations of motion. Notice here that what we are saying is that
the same Lagrangian function applied to the
fields Œ∑i0 and integrated over
R
0
0
x ‚àà R should give the same action as S = R L(Œ∑i (x)...)d4 x, where R0 is the
range of x0 corresponding to the domain R of x. [Of course our argument
applies also if Œ¥x¬µ = 0, when the transformation does not involve a change
in coordinates. Such symmetries are called internal symmetries, with isospin
an example.]
Actually, the above condition that the actions be unchanged is far more
demanding than is needed to insure that the same equations of motion arise.
The variations required to derive the equations of motion only compare actions for field configurations unchanged at the boundaries, so if the actions
0

S =

Z

L(Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 )d4 x0 and S =
R0

Z
R

L(Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x)d4 x (8.7)

differ by a function only of the values of Œ∑i on the boundary ‚àÇR, they will
give the same equations of motion. Even in quantum mechanics, where the
transition amplitude is given by integrating eiS/hÃÑ over all configurations, a
change in the action which depends only on surface values is only a phase
change in the amplitude. In classical mechanics we could also have an overall
change multiplying the Lagrangian and the action by a constant c 6= 0, which
would still have extrema for the same values of the fields, but we will not
consider such changes because quantum mechanically they correspond to
changing Planck‚Äôs constant.
The Lagrangian density is a given function of the old fields L(Œ∑i , ‚àÇ¬µ Œ∑i , x¬µ ).
If we substitute in the values of Œ∑(x) in terms of Œ∑ 0 (x0 ) we get a new density
L0 , defined by
L0 (Œ∑i0 , ‚àÇ¬µ0 Œ∑i0 , x0¬µ ) = L(Œ∑i , ‚àÇ¬µ Œ∑i , x¬µ )

‚àÇxŒΩ
,
‚àÇx0¬µ

where the last factor is the Jacobian of the transformation x ‚Üí x0 , required
because these are densities, intended to be integrated. This change in functional form for the Lagrangian is not the symmetry transformation, for as

8.3. NOETHER‚ÄôS THEOREM

245

long as x ‚Üî x0 is one-to-one, the integral is unchanged
Z

L (Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 )d4 x0
0
R
0

=
=

‚àÇxŒΩ 4 0
L(Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x)
dx
‚àÇx0¬µ
R0

Z

Z
R

L(Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x)d4 x = S

(8.8)

regardless of whether this transformation is a symmetry.
We see that the change in the action, Œ¥S = S 0 ‚àí S, which must vanish
up to surface terms for a symmetry, may be written
as an integral over R0
R
of the variation of the Lagrangian density, Œ¥S = R0 Œ¥L, with
Œ¥L(Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 ) := L(Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 ) ‚àí L0 (Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 )
= L(Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 ) ‚àí L(Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x)

‚àÇxŒΩ
.
‚àÇx0¬µ

(8.9)

Here we have used the first of Eq. (8.7) for S 0 and Eq. (8.8) for S.
Expanding to first order, the Jacobian is
‚àÇx0¬µ
det
‚àÇxŒΩ

‚àí1
¬µ ‚àí1

= det (Œ¥ŒΩ¬µ + ‚àÇŒΩ Œ¥x )

‚àÇŒ¥x¬µ
= 1 + Tr
‚àÇxŒΩ

!‚àí1

= 1 ‚àí ‚àÇ¬µ Œ¥x¬µ , (8.10)

while
L(Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 ) = L(Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x)
‚àÇL
‚àÇL
Œ¥L
+Œ¥Œ∑i
+ Œ¥(‚àÇ¬µ Œ∑i )
+ Œ¥x¬µ ¬µ , (8.11)
‚àÇŒ∑i
‚àÇ‚àÇ¬µ Œ∑i
Œ¥x
Thus10
Œ¥L = L‚àÇ¬µ Œ¥x¬µ + Œ¥Œ∑i

‚àÇL
‚àÇL
Œ¥L
+ Œ¥(‚àÇ¬µ Œ∑i )
+ Œ¥x¬µ ¬µ ,
‚àÇŒ∑i
‚àÇ‚àÇ¬µ Œ∑i
Œ¥x

(8.12)

and if this is a divergence, Œ¥L = ‚àÇ¬µ Œõ¬µ for some Œõ¬µ , we will have a symmetry.
There are subtleties in this expression11 . The last term involves a derivative of L with its first two arguments fixed, and as such is not the derivative
with respect to x¬µ with the functions Œ∑i fixed. For this reason we used a
different symbol, because it is customary to use ‚àÇ¬µ to mean only that xŒΩ is
10

This is the equation to use on homework.
There is also a summation understood on the repeated i index as well as on the
repeated ¬µ index.
11

246

CHAPTER 8. FIELD THEORY

fixed for ŒΩ 6= ¬µ, and not to indicate that the other arguments of L are held
fixed. That form of derivative is the stream derivative,




‚àÇL Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x
‚àÇxŒΩ



=



Œ¥L Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x
Œ¥xŒΩ

+ (‚àÇŒΩ Œ∑i )

‚àÇL
‚àÇL
+ (‚àÇŒΩ ‚àÇ¬µ Œ∑i )
.
‚àÇŒ∑i
‚àÇ‚àÇ¬µ Œ∑i

Note also that Œ¥Œ∑i (x) = Œ∑i0 (x0 )‚àíŒ∑i (x) is not simply the variation of the field at
a point, Œ∑i (x) = Œ∑i0 (x) ‚àí Œ∑i (x), but includes in addition the change (Œ¥x¬µ )‚àÇ¬µ Œ∑i
due to the displacement of the argument. Thus
Œ¥Œ∑i (x) = Œ∑i (x) + (Œ¥xŒΩ )‚àÇŒΩ Œ∑i .

(8.13)

The variation with respect to ‚àÇ¬µ0 Œ∑i0 needs to be examined carefully, because
the Œ¥ variation effects the coordinates, and therefore in general ‚àÇ¬µ Œ¥Œ∑i 6= Œ¥‚àÇ¬µ Œ∑i .
By definition,
Œ¥‚àÇ¬µ Œ∑i = ‚àÇŒ∑i0 /‚àÇx0¬µ |x0 ‚àí ‚àÇŒ∑i /‚àÇx¬µ |x
‚àÇxŒΩ ‚àÇ
[Œ∑i + (Œ¥xœÅ )‚àÇœÅ Œ∑i + Œ∑i ] ‚àí ‚àÇŒ∑i /‚àÇx¬µ |x
=
‚àÇx0¬µ ‚àÇxŒΩ
x
‚àÇ
= ‚àí (‚àÇ¬µ Œ¥xŒΩ ) ‚àÇŒΩ Œ∑i + ¬µ [(Œ¥xœÅ )‚àÇœÅ Œ∑i + Œ∑i ]
‚àÇx
= (Œ¥xŒΩ )‚àÇ¬µ ‚àÇŒΩ Œ∑i + ‚àÇ¬µ Œ∑i

(8.14)

where in the last line we used ‚àÇ¬µ Œ∑i = ‚àÇ¬µ Œ∑i , because the variation is
defined at a given point and does commute with ‚àÇ¬µ .
Notice that the Œ¥xŒΩ terms in (8.13) and (8.14) are precisely what is required in (8.11) to change the last term to a full stream derivative. Thus
L(Œ∑i0 (x0 ), ‚àÇ¬µ0 Œ∑i0 (x0 ), x0 ) = L(Œ∑i (x), ‚àÇ¬µ Œ∑i (x), x)
‚àÇL
‚àÇL
‚àÇL
+ ‚àÇ¬µ Œ∑i
+ Œ¥x¬µ ¬µ , (8.15)
+ Œ∑i
‚àÇŒ∑i
‚àÇ‚àÇ¬µ Œ∑i
‚àÇx
where now ‚àÇL/‚àÇx¬µ means the stream derivative, including the variations of
Œ∑i (x) and its derivative due to the variation Œ¥x¬µ in their arguments.
Inserting this and (8.10) into the expression (8.9) for Œ¥L, we see that the
change of action is given by the integral of
‚àÇL
‚àÇL
‚àÇL
+ Œ∑i
+ ‚àÇ¬µ Œ∑i
¬µ
‚àÇx
‚àÇŒ∑i
‚àÇ‚àÇ¬µ Œ∑i
!
!
‚àÇL
‚àÇL
‚àÇ ‚àÇL
¬µ
Œ¥x L + Œ∑i
+ Œ∑i
‚àí
‚àÇ‚àÇ¬µ Œ∑i
‚àÇŒ∑i ‚àÇx¬µ ‚àÇ‚àÇ¬µ Œ∑i

Œ¥L = (‚àÇ¬µ Œ¥x¬µ ) L + Œ¥x¬µ
=

‚àÇ
‚àÇx¬µ

(8.16)

8.3. NOETHER‚ÄôS THEOREM

247

We will discuss the significance of this in a minute, but first, I want to present
an alternate derivation.
Observe that in the expression (8.7) for S 0 , x0 is a dummy variable and
can be replaced by x, and the difference can be taken at the same x values,
except that the ranges of integration differ. That is,
Z

0

S =

L (Œ∑ 0 (x), ‚àÇ¬µ Œ∑ 0 (x), x) d4 x,

R0

and this differs from S(Œ∑) because
1. the Lagrangian is evaluated with the field Œ∑ 0 (x) rather than Œ∑(x), producing a change
Œ¥1 S =

!

‚àÇL
‚àÇL
Œ∑i +
‚àÇ¬µ Œ∑i d4 x,
‚àÇŒ∑i
‚àÇ‚àÇ¬µ Œ∑i

Z

where the variation with respect to the fields is now in terms of Œ∑i (x) :=
Œ∑i0 (x) ‚àí Œ∑i (x), at the same argument x.
2. Change in the region of integration, R0 rather than R,
Z

Œ¥2 S =

R0

‚àí

Z 

L(Œ∑i , ‚àÇ¬µ Œ∑i , x) d4 x.

R

If we define dS¬µ to be an element of the three dimensional surface ‚àÇR of R,
with outward-pointing normal in the direction of dS¬µ , the difference in the
regions of integration may be written as an integral over the surface,
Z
R0

‚àí

Z 

d4 x =

Z

R

‚àÇR

Œ¥x¬µ ¬∑ dS¬µ .

Thus
Œ¥2 S =

Z
‚àÇR

LŒ¥x¬µ ¬∑ dS¬µ =

Z
R

‚àÇ¬µ (LŒ¥x¬µ )

(8.17)

by Gauss‚Äô Law (in four dimensions).
As is a difference of two functions at the same values of x, this operator
commutes with partial differentiation, so ‚àÇ¬µ Œ∑i = ‚àÇ¬µ Œ∑i . Using this in the
second term of Œ¥1 S, and using A‚àÇ¬µ B = ‚àÇ¬µ (AB) ‚àí B‚àÇ¬µ A, we have
Œ¥1 S =

Z
R

"
4

d x ‚àÇ¬µ

‚àÇL
Œ∑i
‚àÇ‚àÇ¬µ Œ∑i

!

+ Œ∑i

‚àÇL
‚àÇL
‚àí ‚àÇ¬µ
‚àÇŒ∑i
‚àÇ‚àÇ¬µ Œ∑i

!#

248

CHAPTER 8. FIELD THEORY

Thus altogether S 0 ‚àí S = Œ¥1 S + Œ¥2 S = R d4 xŒ¥L, with Œ¥L
given by (8.16).
R
0
This completes our alternate derivation that S ‚àí S = R d4 xŒ¥L, and Eq.
(8.16).
Note that Œ¥L is a divergence plus a piece which vanishes if the dynamical
fields obey the equation of motion, quite independent of whether or not the
infinitesimal variation we are considering is a symmetry. As we mentioned,
to be a symmetry, Œ¥L must be a divergence for all field configurations, not
just those satisfying the equations of motion, so that the variations over
configurations will give the correct equations of motion.
We have been assuming the variations Œ¥x and Œ¥Œ∑ can be treated as infinitesimals. This is appropriate for a continuous symmetry, that is, a symmetry group12 described by a (or several) continuous parameters. For example,
symmetry under displacements x¬µ ‚Üí x¬µ + c¬µ , where c¬µ is any arbitrary fixed
4-vector, or rotations through an arbitrary angle Œ∏ about a fixed axis. Each
element of such a group lies in a one-parameter subgroup, and can be obtained, in the limit, from an infinite number of applications of an infinitesimal
transformation. If we call the parameter , the infinitesimal variations in x¬µ
and Œ∑i are given by derivatives of x0 (, x) and Œ∑ 0 with respect to the parameter
. Thus
dŒ∑ 0 (x0 )
dx0¬µ
,
Œ¥Œ∑i =  i
.
Œ¥x¬µ = 
d xŒΩ
d xŒΩ
R

The divergence must also be first order in , so Œ¥L = ‚àÇ¬µ Œõ¬µ if we have a
symmetry.
We define the current for the transformation
J

¬µ

‚àÇL
dx0¬µ
‚àÇL dŒ∑i0
dx0ŒΩ
+
‚àíL
+ Œõ¬µ .
= ‚àí
‚àÇŒΩ Œ∑i
‚àÇ‚àÇ¬µ Œ∑i d
‚àÇ‚àÇ¬µ Œ∑i
d
d

(8.18)

Recalling that Œ∑i = Œ¥Œ∑i ‚àí (Œ¥xŒΩ )‚àÇŒΩ Œ∑i , we can rewrite (8.16)
‚àÇ
‚àÇL
‚àÇL
Œ¥L =
Œ¥x¬µ L + Œ¥Œ∑i
‚àí Œ¥xŒΩ (‚àÇŒΩ Œ∑i )
¬µ
‚àÇx
‚àÇ‚àÇ¬µ Œ∑i
‚àÇ‚àÇ¬µ Œ∑i
!
‚àÇ ‚àÇL
‚àÇL
+ Œ∑i
‚àí ¬µ
‚àÇŒ∑i ‚àÇx ‚àÇ‚àÇ¬µ Œ∑i
12

!

Symmetries always form a group. Continuous symmetries form a Lie group, whose elements can be considered exponentials of linear combinations of generators. The generators
form a Lie algebra.

8.3. NOETHER‚ÄôS THEOREM

249

and see that
!

‚àÇ¬µ J

¬µ

‚àÇ
‚àÇ
‚àÇL
‚àÇL
=
‚àí
Œ¥Œ∑i +
‚àÇŒΩ Œ∑i Œ¥xŒΩ ‚àí ¬µ (LŒ¥x¬µ ) + Œ¥L
¬µ
‚àÇx
‚àÇ‚àÇ¬µ Œ∑i
‚àÇ‚àÇ¬µ Œ∑i
‚àÇx
!
‚àÇ ‚àÇL
‚àÇL
‚àí ¬µ
= Œ∑i
‚àÇŒ∑i ‚àÇx ‚àÇ‚àÇ¬µ Œ∑i

Thus we have
‚àÇ¬µ J ¬µ = 0

for a symmetry, when the fields obey the equations of motion.

This condition is known as current conservation. Associated with each
such current, we may define the charge enclosed in a constant volume V
QV (t) =

Z

d3 xJ 0 (~x, t).

V

If we evaluate the time derivative of the charge, we have
Z
Z
Z
X
d
3
i
3
0
~ ¬∑ J(~
~ x, t)
‚àÇi J (~x, t) = ‚àí d3 x‚àá
d x‚àÇ0 J (~x, t) ‚âà ‚àí d x
QV (t) =
dt
V
V
V
i=1,3

= ‚àí

Z

~
J~ ¬∑ dS,

‚àÇV

~ an element of surface area.
where ‚àÇV is the boundary of the volume and dS
We have used the conservation of the current and Gauss‚Äô Law. If, as can
usually be assumed, the current vanishes as we move infinitely far way from
the region of interest, the surface integral vanishes if we take V to be all
of space, and we find that the total charge is conserved, dQ/dt = 0, in the
same sense that equations of motion are satisfied. The assumption about
asymptotic behavior is not always valid, and we must consider whether we
have grounds for it in particular applications. We will see later that in some
circumstances there are ‚Äúanomolies‚Äù when this assumption is not justified.
It should be mentioned that, because we are only considering infinitesimal
transformations, it is possible to describe the symmetry without relating new
fields at new points to old fields at the old points. We could simply consider
whether the transformation of fields Œ∑i (x) ‚Üí Œ∑i0 (x) = Œ∑i (x) + Œ∑i (x) is a
symmetry, where Œ∑i (x) = Œ¥Œ∑i (x) ‚àí (Œ¥xŒΩ )‚àÇŒΩ Œ∑i includes not only the natural
variation Œ¥Œ∑ (that is, zero for a scalar and an orthogonal transformation for a
vector), but also the derivative piece. The derivation then need not consider

250

CHAPTER 8. FIELD THEORY

change of integration region, but will in general require a nonzero choice of Œõ
to compensate. This is not necessary in simple applications using the method
described here. Another disadvantage of starting with is that it obscures
the local nature of the field dependence.

8.3.1

Applications of Noether‚Äôs Theorem

Now it is time to use the very powerful though abstract formalism Noether
developed for continuous symmetries to ask about symmetries we expect our
theories to have. At the very least, in this class, we are going to deal only
with theories which are invariant under
‚Ä¢ spatial translations, ~x ‚Üí ~x 0 = ~x + ~c.
‚Ä¢ time translations, t ‚Üí t0 = t + c0 , or in four dimensional notation,
x 0 ‚Üí x 0 0 = x 0 + c0 .
‚Ä¢ rotations, xi ‚Üí x0 i =

i
i j
j R j x , with R j an orthogonal matrix.

P

‚Ä¢ Lorentz boost transformations.
where Rij is an orthogonal real matrix of determinant 1. The first two of
these together are four dimensional translations,
x ¬µ ‚Üí x 0 ¬µ = x ¬µ + c¬µ ,

(8.19)

and the last two (actually Lorentz transformations already include both) can
P
be written x¬µ ‚Üí x0 ¬µ = ŒΩ Œõ¬µŒΩ xŒΩ = Œõ¬µŒΩ xŒΩ , (using the Einstein summation convention), where the matrix Œõ is a real matrix satisfying the pseudoorthogonality condition
Œõ¬µŒΩ Œ∑¬µœÅ ŒõœÅœÑ = Œ∑ŒΩœÑ ,
which is required so that the length of a four-vector is preserved, x0 2 :=
x0 ¬µ x0¬µ = x2 .
All together, this symmetry group is called the inhomogeneous Lorentz
group, or PoincareÃÅ group.

8.3. NOETHER‚ÄôS THEOREM

251

Translation Invariance
First, let us consider the conserved quantities generated by translation invariance, for which Œ¥x¬µ = c¬µ . All fields we will deal with are invariant, or
transform as scalars, under translations, so Œ¥Œ∑` = 0. From (8.18) the conserved current is
‚àÇL
‚àÇŒΩ Œ∑` ‚àí Lc¬µ = cŒΩ TŒΩ ¬µ ,
Jc¬µ = cŒΩ
‚àÇ‚àÇ¬µ Œ∑`
so the four conserved currents are nothing but the energy-momentum tensor
whose conservation we found in (8.3) directly from the equations of motion.
The conserved charges from this current are
P¬µ =

Z
V

T¬µ 0 (~x, t)d3 x,

with P 0 = H, P j the total momentum for j = 1, 2, 3.
Lorentz Transformations
Now consider an infinitesimal Lorentz transformation, with




x0 ¬µ = Œõ¬µŒΩ xŒΩ = Œ¥ŒΩ¬µ + L¬µŒΩ xŒΩ ,

or Œ¥x¬µ = L¬µŒΩ xŒΩ .

The pseudo-orthogonality of Œõ requires
Œ∑¬µŒΩ L¬µœÅ Œ¥ ŒΩœÉ + Œ∑¬µŒΩ Œ¥ ¬µœÅ LŒΩ œÉ = 0 = LœÉœÅ + LœÅœÉ ,
so the infinitesimal generator, when its indices are lowered, is antisymmetric.
The fields may transform is many ways. A scalar field13 will have Œæ 0 (x0 ) =
Œæ(x), with Œ¥Œæ = 0, but a field Œæ might transform like a contravariant vector,
Œ¥Œæ ¬µ = L¬µŒΩ Œæ ŒΩ , or in an even more complex fashion such as a tensor or a
spinor. Whatever the change in Œæ` is, it will be proportional to L¬µŒΩ , so
Œ¥Œ∑` = L¬µŒΩ ‚àÜ¬µŒΩ ` , and the current generated is
J ¬µ = LœÅŒΩ M¬µœÅŒΩ = ‚àí

‚àÇL
‚àÇL œÅ
L œÉ ‚àÜœÅœÉ` +
‚àÇœÑ Œæ` LœÑ Œ∫ xŒ∫ ‚àí LL¬µŒΩ xŒΩ .
‚àÇ‚àÇ¬µ Œæ`
‚àÇ‚àÇ¬µ Œæ`

As LœÅŒΩ is antisymmetric under œÅ ‚Üî ŒΩ, there are six independant infinitesimal
generators which can produce currents. Only the part antisymmetric under
13

Now that our fields may be developing space-time indices, we will change their name
from Œ∑ to Œæ to avoid confusion with Œ∑¬µŒΩ .

252

CHAPTER 8. FIELD THEORY

œÅ ‚Üî ŒΩ in M¬µœÅŒΩ enters in this expression, so we take M¬µœÅŒΩ and ‚àÜœÅŒΩ ` to be
antisymmetric under œÅ ‚Üî ŒΩ, and thus
M¬µœÅŒΩ = ‚àí

‚àÇL œÅŒΩ 1 ‚àÇL
1
‚àÜ `+
[Œ∑ œÅœÑ (‚àÇœÑ Œæ` )xŒΩ ‚àíŒ∑ ŒΩœÑ (‚àÇœÑ Œæ` )xœÅ ]‚àí L (Œ∑ ¬µœÅ xŒΩ ‚àíŒ∑ ¬µŒΩ xœÅ ) .
‚àÇ‚àÇ¬µ Œæ`
2 ‚àÇ‚àÇ¬µ Œæ`
2

Of course the six currents M¬µœÅŒΩ are conserved only if the action is invariant,
which will be the case only if the lagrangian density transforms like a scalar
under lorentz transformations. This will be assured if all the vector indices
of the fields are contracted correctly, one up and one down. Note that part
of the current M¬µœÅŒΩ is related to the energy-momentum tensor,
M¬µœÅŒΩ =

‚àÇL œÅŒΩ
1 ŒΩ œÅ¬µ
(x T ‚àí xœÅ T ŒΩ¬µ ) ‚àí
‚àÜ `.
2
‚àÇ‚àÇ¬µ Œæ`

As T œÅ¬µ is a 4-current of the 4-momentum, we see that the first term is the
4-current of the four dimensional version of orbital angular momentum. The
last term is then the contribution of the spin to the current of the total
angular momentum.

8.4

Examples of Relativistic Fields

As we mentioned, Noether‚Äôs theorem will generate conserved generators of
Lorentz transformations if the lagrangian density transforms as a scalar under
PoincareÃÅ transformations. For convenience we will take c = 1. The easiest
example to consider is a single scalar field, with what is called the KleinGordon Lagrangian:
!


‚àÇœÜ ‚àÇœÜ
1 2
1
~ 2 ‚àí m2 œÜ2 .
œÜÃá ‚àí (‚àáœÜ)
L=
‚àíŒ∑ ¬µŒΩ ¬µ ŒΩ ‚àí m2 œÜ2 =
2
‚àÇx ‚àÇx
2

The canonical momentum field is œÄ = ‚àÇL
= œÜÃá, and
‚àÇ œÜÃá
T¬µ ŒΩ =


‚àÇL
1 
~ 2 + m2 œÜ2 .
œÜ,¬µ ‚àí LŒ¥¬µŒΩ = ‚àíœÜ,ŒΩ œÜ,¬µ + Œ¥¬µŒΩ ‚àíœÜÃá2 + (‚àáœÜ)
‚àÇœÜ,ŒΩ
2

The Hamiltonian is
H=

Z

T 00 d3 x =

i
1Z h 2
~ 2 + m2 œÜ2 d3 x,
œÜÃá + (‚àáœÜ)
2

8.4. EXAMPLES OF RELATIVISTIC FIELDS

253

the three-momentum is
(P~ )j =

Z

0

3

Tj d x =

Z

~ j d3 x
œÜÃá(‚àáœÜ)

or P~ =

Z

~ d3 x.
œÄ ‚àáœÜ

The equation of motion (8.1) is




Œ∑ ¬µŒΩ ‚àÇ¬µ ‚àÇŒΩ ‚àí m2 œÜ = 0,

or œÜÃà ‚àí ‚àá2 œÜ + m2 œÜ = 0,

which has solutions which are waves, decomposable into plane waves œÜ(~x, t) ‚àù
~
ei(k¬∑~x‚àíœât) , with œâ 2 = k 2 + m2 . Identifying k with the momentum and œâ with
the energy, as one would in quantum mechanics (with hÃÑ = 1) gives the
relation one would expect for a particle of mass m: E 2 = p2 + m2 (as we
have set c = 1 also. E 2 = p2 c2 + m2 c4 if you want to put c back in).
The only relativistic field we are familiar with from classical (non-quantum)
~ and B
~ as fields
mechanics is the electromagnetic field. We are familiar with E
~ and B
~ satisfy
defined throughout space and also functions of time. But E
constraint equations. Maxwell‚Äôs equations (in free space and SI units) are
~ ¬∑E
~ = œÅ/0
‚àá
(8.20)
~ ¬∑B
~ = 0
‚àá
(8.21)
~
~ √óE
~ + 1 ‚àÇB = 0
‚àá
(8.22)
c ‚àÇt
~
~ √óB
~ ‚àí 1 ‚àÇ E = ¬µ0~j
‚àá
(8.23)
c2 ‚àÇt
Notice that (8.20) and (8.21) are not equations of motion, as they do not
involve time derivatives. Instead they are equations of constraint, best implemented by solving them in terms of independent degrees of freedom. As
~ and B
~ as
we saw in section (2.7), these equations allow us to consider E
~ x, t) and the electrostatic poderivatives of the magnetic vector potential A(~
~ =‚àá
~ √ó A,
~ and E
~ = ‚àí‚àáœÜ
~ ‚àí 1 ‚àÇ A~ . We also saw
tential œÜ(~x, t). Then we have B
c ‚àÇt
that the interaction of these fields with a charged particle could be given in
terms of a potential
¬µ

~ r, t) = ‚àí q dx A¬µ ,
U (~r, ~v ) = q œÜ(r, t) ‚àí (~v /c) ¬∑ A(~
c dt
0
if I take A0 = ‚àíœÜ = ‚àíA . This is the first step in writing electromagnetism
in relativistic notation14 .


14



Note U is not an invariant, nor should it be, as it is part of the energy. Therefore it
is expected that it should transform like d/dt of a scalar.

254

CHAPTER 8. FIELD THEORY

~ and B
~ is best understood if we define a 1-form from
The connection to E
A and its exterior derivative:
A := A¬µ (xŒΩ )dx¬µ ,

F := dA =

‚àÇA¬µ ŒΩ
1
¬µ
F¬µŒΩ dx¬µ ‚àß dxŒΩ .
dx
‚àß
dx
=
‚àÇxŒΩ
2

Examining the components, we have
1
‚àÇœÜ
= ‚àíEj = ‚àíFj0 ,
AÃáj +
c
‚àÇxj
X
‚àÇAj
‚àÇAi X
~ √ó A)
~ k=
=
‚àí
=
ijk (‚àá
ijk Bk .
‚àÇxi
‚àÇxj
k
k

F0j =

(8.24)

Fij

(8.25)

As F := dA we know that dF = 0. dF is a 3-form,
1
1
dF = (dF)¬µŒΩœÅ dx¬µ dxŒΩ dxœÅ = ¬µŒΩœÅœÉ V œÉ dx¬µ dxŒΩ dxœÅ ,
6
6
where V œÉ = (‚àí1/6)¬µŒΩœÅœÉ (dF)¬µŒΩœÅ . As we saw in three dimensions in section
(6.5), a k-form œâ in D dimensions can be associated not only with an antisymmetric tensor of rank k, but also with one of rank D ‚àí k. That tensor is
associated with a (D‚àík)-form, called the Hodge dual15 of œâ, written ‚àóœâ.
On the basis vectors we define
‚àó(dx¬µ1 ‚àß ¬∑ ¬∑ ¬∑ dx¬µk ) =

1
¬µ1 ¬∑¬∑¬∑¬µk ŒΩ1 ¬∑¬∑¬∑ŒΩD‚àík dxŒΩ1 ‚àß ¬∑ ¬∑ ¬∑ dxŒΩD‚àík .
(D ‚àí k)!

In particular, if œâ is a 2-form in four dimensional Minkowski space,
œâ =
‚àóœâ =
dœâ =
‚àó dœâ =
‚àód‚àóœâ =
15

k.

1
œâ¬µŒΩ dx¬µ ‚àß dxŒΩ
2

1 1 ¬µŒΩ

œâ¬µŒΩ dxœÅ ‚àß dxœÉ
2 2 œÅœÉ
1
œâ¬µŒΩ,œÅ dxœÅ ‚àß dx¬µ ‚àß dxŒΩ
2
1 ¬µŒΩœÅ
 œÉ œâ¬µŒΩ,œÅ dxœÉ
2


1 ¬µŒΩ
Œ∫œÅœÉ
 œÑ
œâ¬µŒΩ,Œ∫ dxœÑ = œâœÑ Œ∫,Œ∫ dxœÑ .

4 œÅœÉ

Warning: the dual of the dual of a k-form œâ is ¬±œâ, with the sign depending on D and

8.4. EXAMPLES OF RELATIVISTIC FIELDS

255

In particular for our 2-form F, the fact that dF = 0, and thus ‚àódF = 0 tells
us the vector V œÉ = (‚àí1/6)¬µŒΩœÅœÉ FŒΩœÅ,¬µ = 0. The œÉ = 0 component of this
1
1
~ ¬∑ B,
~
0 = 3V 0 = ijk Fjk,i = ijk jk` B`,i = Œ¥i` B`,i = ‚àá
2
2
giving us the constraint equation (8.21). For the spatial component,
0 = ‚àí3V i =

3
3 

1 X
1 X
¬µŒΩœÅi FŒΩœÅ,¬µ =
jki Fjk,0 + 2jki Fk0,j
2 ¬µ,ŒΩ,œÅ=0
2 j,k=1

3
1 X
1
=
jki jk` BÃá` + 2jki ‚àÇj Ek
2 j,k=1
c





=



1 ~Àô
~ √óE
~ ,
B+‚àá
c
i


which gives us the constraint (8.22). So the two constraint equations among
Maxwell‚Äôs four are
dF = 0.
(8.26)
What are the two dynamical equations? If we evaluate ‚àó d ‚àó F =
F¬µŒΩ,ŒΩ dx¬µ =: V¬µ dx¬µ , we see the zeroth component contains only F0j = ‚àíEj ,
P
~ ¬∑ E,
~ which Maxwell tells us is ‚àíœÅ/0 . The spawith V0 = j ‚àÇF0j /‚àÇxj = ‚àí‚àá


P
~Àô + ‚àá
~ √óB
~
tial component is Vi = Fi0,0 + j Fij,j = EÃáj /c + ijk ‚àÇj Bk = E/c
i

which Maxwell tells us is (modulo c) ¬µ0 (~j)i . This encourages us to define the
4-vector J ¬µ = (œÅ, ~j) and its accompanying 1-form J = J¬µ dx¬µ , and to write
the two dynamical equations as
‚àó d ‚àó F = ‚àíJ or d ‚àó F = ‚àóJ.

(8.27)

How should we write the lagrangian density for the electromagnetic fields?
As the dynamics is determined by the action, the integral of L over fourdimensional space-time, we should expect L to be essentially a 4-form, which
needs to be made out of the 2-form F. Our first idea might be to try F ‚àß F,
which is a 4-form, but unfortunately it is a closed 4-form, for d(F ‚àß F) =
(dF) ‚àß F + (F) ‚àß (dF), and dF = ddA = 0. Because we are working on a
contractable space, F ‚àß F is thereform
exact,
and an exact form is useless
R
R
as a lagrangian density because dœâd4 x = S œâ which depends only on the
boundaries, both in space and time, but this is exactly where variations of

256

CHAPTER 8. FIELD THEORY

the dynamical degrees of freedom are kept fixed in determing the variation
of the action.
There is another 2-form available, however, ‚àó F , so we might consider
1
1
1 1
Ldtd3 x = ‚àí F ‚àß ‚àóF = ‚àí ¬∑ F¬µŒΩ dx¬µ ‚àß dxŒΩ ¬∑ Œ∫ŒªœÅœÉ FŒ∫Œª ‚àß dxœÅ ‚àß dxœÉ
2
2 2
4
1 Œ∫Œª ¬µŒΩœÅœÉ
= ‚àí  œÅœÉ 
F¬µŒΩ FŒ∫Œª dx0 ‚àß dx1 ‚àß dx2 ‚àß dx3
16
c
c
L = ‚àí Œ∫ŒªœÅœÉ ¬µŒΩœÅœÉ F¬µŒΩ FŒ∫Œª = ‚àí (F ¬µŒΩ F¬µŒΩ ‚àí F ¬µŒΩ FŒΩ¬µ )
16
8
c ¬µŒΩ
1
c
1
2
= ‚àí F F¬µŒΩ = ‚àí (‚àíF0j + ijk Bk ij` B` = (E 2 ‚àí B 2 )
4
2
2
2

Exercises
8.1 The Lagrangian density for the electromagnetic field in vacuum may be written
1  ~ 2 ~ 2
L=
E ‚àíB ,
2
~ and B,
~ but rather A
~ and œÜ,
where the dynamical degrees of freedom are not E
where
~ = ‚àá
~ √óA
B
~ = ‚àí‚àáœÜ
~ ‚àí 1A
~Àô
E
c
a) Find the canonical momenta, and comment on what seems unusual about one
of the answers.
b) Find the Lagrange Equations for the system. Relate to known equations for
the electromagnetic field.
8.2 A tensor transforms properly under Lorentz transformations as specified by
equation (8.6), with each index being contracted with a suitable L¬∑¬∑ or L¬∑¬∑ as
appropriate.
(a) The Minkowsky metric Œ∑¬µŒΩ should then be transformed into a new tensor by
contracting with two L¬∑¬∑ ‚Äôs. Show that the new tensor Œ∑ 0 is nonetheless the same as
Œ∑. [That is, each element still has the same value].
(b) The Levi-Civita symbol in one reference frame is defined by 0123 = 1 and
¬µŒΩœÅœÉ is antisymmetric under any interchange of two indices. Being a four-index
contravariant tensor, it will transform with four L¬∑¬∑ ‚Äôs. Show that the transformed

8.4. EXAMPLES OF RELATIVISTIC FIELDS

257

tensor still has the same values under proper16 Thus both Œ∑¬µŒΩ and ¬µŒΩœÅœÉ are both
invariant and transform co- or contra-variantly.
œÅ ...œÅ ¬µ
œÅ ...œÅ
(c) Show that if T 1 j œÉ1 ...œÉk transforms correctly, the tensor T 1 j¬µ œÉ1 ...œÉk :=
œÅ1 ...œÅj ŒΩ
Œ∑¬µŒΩ T
œÉ1 ...œÉk transforms correctly as well.
(d) Show that if two indices, one upper and one lower, are contracted, that is, set
equal and summed over, the resulting object transforms as if those indices were
¬µ ...¬µ
ŒΩ¬µ ...¬µ
not there. That is, W 1 jœÅ1 ...œÅk := T 1 jŒΩœÅ1 ...œÅk transforms correctly.

16

Proper Lorentz transformations are those that can be generated continuously from
the identity. That is, they exclude transformations that reverse the direction of time or
convert a right-handed coordinate system to a left-handed one.

258

CHAPTER 8. FIELD THEORY

Appendix A
Appendices
A.1

ijk and cross products

A.1.1

Vector Operations: Œ¥ij and ijk

These are some notes on the use of the antisymmetric symbol ijk for expressing cross products. This is an extremely powerful tool for manipulating
cross products and their generalizations in higher dimensions, and although
many low level courses avoid the use of , I think this is a mistake and I want
you to become proficient with it.
In a cartesian coordinate system a vector V~ has components Vi along each
P
of the three orthonormal basis vectors eÃÇi , or V~ = i Vi eÃÇi . The dot product
~ ¬∑ B,
~ is bilinear and can therefore be written as
of two vectors, A
~¬∑B
~ = (
A

X

Ai eÃÇi ) ¬∑

i

=
=

(A.1)

Ai Bj eÃÇi ¬∑ eÃÇj

(A.2)

Ai Bj Œ¥ij ,

(A.3)

j

XX
i

Bj eÃÇj

j

XX
i

X

j

where the Kronecker delta Œ¥ij is defined to be 1 if i = j and 0 otherwise.
As the basis vectors eÃÇk are orthonormal, i.e. orthogonal to each other and of
unit length, we have eÃÇi ¬∑ eÃÇj = Œ¥ij .
Doing a sum over an index j of an expression involving a Œ¥ij is very simple,
because the only term in the sum which contributes is the one with j = i.
P
Thus j F (i, j)Œ¥ij = F (i, i), which is to say, one just replaces j with i in all
259

260

APPENDIX A. APPENDICES

the other factors, and drops the Œ¥ij and the summation over j. So we have
~¬∑B
~ = Pi Ai Bi , the standard expression for the dot product1
A
~ √ó B,
~ which is also
We now consider the cross product of two vectors, A
P
~√óB
~ = ( i Ai eÃÇi ) √ó (Pj Bj eÃÇj ) =
a bilinear expression, so we must have A
P P
i
j Ai Bj (eÃÇi √ó eÃÇj ). The cross product eÃÇi √ó eÃÇj is a vector, which can therefore
P
be written as V~ = k Vk eÃÇk . But the vector result depends also on the two
input vectors, so the coefficients Vk really depend on i and j as well. Define
them to be ijk , so
X
eÃÇi √ó eÃÇj =
kij eÃÇk .
k

It is easy to evaluate the 27 coefficients kij , because the cross product of two
orthogonal unit vectors is a unit vector orthogonal to both of them. Thus
eÃÇ1 √ó eÃÇ2 = eÃÇ3 , so 312 = 1 and k12 = 0 if k = 1 or 2. Applying the same
argument to eÃÇ2 √ó eÃÇ3 and eÃÇ3 √ó eÃÇ1 , and using the antisymmetry of the cross
~√óB
~ = ‚àíB
~ √ó A,
~ we see that
product, A
123 = 231 = 312 = 1;

132 = 213 = 321 = ‚àí1,

and ijk = 0 for all other values of the indices, i.e. ijk = 0 whenever any
two of the indices are equal. Note that  changes sign not only when the last
two indices are interchanged (a consequence of the antisymmetry of the cross
product), but whenever any two of its indices are interchanged. Thus ijk is
zero unless (1, 2, 3) ‚Üí (i, j, k) is a permutation, and is equal to the sign of
the permutation if it exists.
Now that we have an expression for eÃÇi √ó eÃÇj , we can evaluate
~√óB
~ =
A

XX
i

j

Ai Bj (eÃÇi √ó eÃÇj ) =

XXX
i

j

kij Ai Bj eÃÇk .

(A.4)

k

Much of the usefulness of expressing cross products in terms of ‚Äôs comes
from the identity
X
kij k`m = Œ¥i` Œ¥jm ‚àí Œ¥im Œ¥j` ,
(A.5)
k

which can be shown as follows. To get a contribution to the sum, k must be
different from the unequal indices i and j, and also different from ` and m.
Thus we get 0 unless the pair (i, j) and the pair (`, m) are the same pair of
1

Note that this only holds because we have expressed our vectors in terms of orthonormal basis vectors.

A.1. IJK AND CROSS PRODUCTS

261

different indices. There are only two ways that can happen, as given by the
two terms, and we only need to verify the coefficients. If i = ` and j = m,
the two ‚Äôs are equal and the square is 1, so the first term has the proper
coefficient of 1. The second term differs by one transposition of two indices
on one epsilon, so it must have the opposite sign.
We now turn to some applications. Let us first evaluate
~ ¬∑ (B
~ √ó C)
~ =
A

X

Ai

i

X

ijk Bj Ck =

jk

X

ijk Ai Bj Ck .

(A.6)

ijk

~ ¬∑ (B
~ √ó C)
~ is, up to sign, the volume of the parallelopiped formed
Note that A
~ B,
~ and C.
~ From the fact that the  changes sign under
by the vectors A,
transpositions of any two indices, we see that the same is true for transposing
the vectors, so that
~ ¬∑ (B
~ √ó C)
~ = ‚àíA
~ ¬∑ (C
~ √ó B)
~ = B
~ ¬∑ (C
~ √ó A)
~ = ‚àíB
~ ¬∑ (A
~ √ó C)
~
A
~ ¬∑ (A
~ √ó B)
~ = ‚àíC
~ ¬∑ (B
~ √ó A).
~
= C
~ √ó (B
~ √ó C).
~ Using our formulas,
Now consider V~ = A
V~ =

X

~ √ó C)
~ j=
kij eÃÇk Ai (B

ijk

X

kij eÃÇk Ai

ijk

X

jlm Bl Cm .

lm

Notice that the sum on j involves only the two epsilons, and we can use
X

kij jlm =

X

jki jlm = Œ¥kl Œ¥im ‚àí Œ¥km Œ¥il .

j

j

X X

kij jlm )Ai Bl Cm =

Thus
Vk =

(

ilm

=

X

j

X
i

(Œ¥kl Œ¥im ‚àí Œ¥km Œ¥il )Ai Bl Cm

ilm

Œ¥kl Œ¥im Ai Bl Cm ‚àí

ilm

=

X

X

Œ¥km Œ¥il Ai Bl Cm

ilm

Ai Bk Ci ‚àí

X

~¬∑C
~ Bk ‚àí A
~¬∑B
~ Ck ,
Ai Bi Ck = A

i

so
~ √ó (B
~ √ó C)
~ =B
~A
~¬∑C
~ ‚àíC
~A
~ ¬∑ B.
~
A
This is sometimes known as the bac-cab formula.

(A.7)

262

APPENDIX A. APPENDICES

Exercise: Using (A.5) for the manipulation of cross products, show
that
~ √ó B)
~ ¬∑ (C
~ √ó D)
~ =A
~¬∑C
~B
~ ¬∑D
~ ‚àíA
~¬∑D
~B
~ ¬∑ C.
~
(A
The determinant of a matrix can be defined using the  symbol. For a
3 √ó 3 matrix A,
det A =

X

ijk A1i A2j A3k =

ijk

X

ijk Ai1 Aj2 Ak3 .

ijk

From the second definition, we see that the determinant is the volume of the
parallelopiped formed from the images under the linear map A of the three
unit vectors eÃÇi , as
(AeÃÇ1 ) ¬∑ ((AeÃÇ2 ) √ó (AeÃÇ3 )) = det A.
In higher dimensions, the cross product is not a vector, but there is a generalization of  which remains very useful. In an n-dimensional space, i1 i2 ...in
has n indices and is defined as the sign of the permutation (1, 2, . . . , n) ‚Üí
(i1 i2 . . . in ), if the indices are all unequal, and zero otherwise. The analog of
(A.5) has (n ‚àí 1)! terms from all the permutations of the unsummed indices
on the second . The determinant of an n √ó n matrix is defined as
det A =

X

i1 i2 ...in

Ap,ip .

p=1

i1 ,...,in

A.2

n
Y

The gradient operator

We can define the gradient operator
~ =
‚àá

X
i

eÃÇi

‚àÇ
.
‚àÇxi

(A.8)

While this looks like an ordinary vector, the coefficients are not numbers Vi
but are operators, which do not commute with functions of the coordinates
xi . We can still write out the components straightforwardly, but we must be
careful to keep the order of the operators and the fields correct.
The gradient of a scalar field Œ¶(~r) is simply evaluated by distributing the
gradient operator
~ =(
‚àáŒ¶

X
i

eÃÇi

X ‚àÇŒ¶
‚àÇ
)Œ¶(~r) =
eÃÇi
.
‚àÇxi
‚àÇxi
i

(A.9)

A.2. THE GRADIENT OPERATOR

263

‚àÇA
‚àÇB
Because the individual components obey the Leibnitz rule ‚àÇAB
= ‚àÇx
B+A ‚àÇx
,
‚àÇxi
i
i
so does the gradient, so if A and B are scalar fields,

~
~
~
‚àáAB
= (‚àáA)B
+ A‚àáB.

(A.10)

~ to a vector A
~ gives an
The general application of the gradient operator ‚àá
object with coefficients with two indices, a tensor. Some parts of this tensor,
however, can be simplified. The first (which is the trace of the tensor) is
called the divergence of the vector, written and defined by
~ ¬∑A
~ = (
‚àá

X
i

=

eÃÇi

X
X
‚àÇBj X ‚àÇBj
‚àÇ
) ¬∑ ( eÃÇj Bj ) =
=
Œ¥ij
eÃÇi ¬∑ eÃÇj
‚àÇxi
‚àÇxi
‚àÇxi
j
ij
ij

X ‚àÇBi

‚àÇxi

i

.

(A.11)

In asking about Leibnitz‚Äô rule, we must remember to apply the divergence
~
operator only to vectors. One possibility is to apply it to the vector V~ = Œ¶A,
with components Vi = Œ¶Ai . Thus
~ ¬∑ (Œ¶A)
~ =
‚àá

X ‚àÇ(Œ¶Ai )

=

X ‚àÇŒ¶

‚àÇxi
i ‚àÇxi
~
~ + Œ¶‚àá
~ ¬∑ A.
~
= (‚àáŒ¶)
¬∑A

Ai + Œ¶

i

X ‚àÇAi
i

‚àÇxi
(A.12)

We could also apply the divergence to the cross product of two vectors,
~ ¬∑ (A
~ √ó B)
~ =
‚àá

~ √ó B)
~ i
X ‚àÇ(A
i

‚àÇxi

=

P
X ‚àÇ( jk ijk Aj Bk )

‚àÇxi

i

X
‚àÇAj
‚àÇBk
ijk
=
ijk Aj
Bk +
.
‚àÇx
‚àÇx
i
i
ijk
ijk
X

=

X
ijk

ijk

‚àÇ(Aj Bk )
‚àÇxi
(A.13)

~ and B.
~
This is expressible in terms of the curls of A
The curl is like a cross product with the first vector replaced by the
differential operator, so we may write the i‚Äôth component as
~ √ó A)
~ i=
(‚àá

X

ijk

jk

‚àÇ
Ak .
‚àÇxj

(A.14)

We see that the last expression in (A.13) is
X X

(

k

ij

kij

X
X
‚àÇAj
‚àÇBk
~ √ó A)
~ ¬∑B
~ ‚àíA
~ ¬∑ (‚àá
~ √ó B).
~ (A.15)
)Bk ‚àí
Aj
jik
= (‚àá
‚àÇxi
‚àÇx
i
j
ik

264

APPENDIX A. APPENDICES

where the sign which changed did so due to the transpositions in the indices
on the , which we have done in order to put things in the form of the
definition of the curl. Thus
~ ¬∑ (A
~ √ó B)
~ = (‚àá
~ √ó A)
~ ¬∑B
~ ‚àíA
~ ¬∑ (‚àá
~ √ó B).
~
‚àá

(A.16)

Vector algebra identities apply to the curl as to any ordinary vector,
except that one must be careful not to change, by reordering, what the
differential operators act on. In particular, Eq. A.7 is
~ √ó (‚àá
~ √ó B)
~ =
A

X
i

A.3

~ i‚àí
Ai ‚àáB

X
i

Ai

~
‚àÇB
.
‚àÇxi

(A.17)

Gradient in Spherical Coordinates

The transformation between Cartesian and spherical coordinates is given by
1
r= (x2 + y 2 + z 2 ) 2
x= r sin Œ∏ cos œÜ
Œ∏= cos‚àí1 (z/r)
y= r sin Œ∏ sin œÜ
‚àí1
œÜ= tan (y/x)
z= r cos Œ∏
The basis vectors {eÃÇr , eÃÇŒ∏ , eÃÇœÜ } at the point (r, Œ∏, œÜ) are given in terms of
the cartesian basis vectors by
eÃÇr = sin Œ∏ cos œÜ eÃÇx + sin Œ∏ sin œÜ eÃÇy + cos Œ∏ eÃÇz
eÃÇŒ∏ = cos Œ∏ cos œÜ eÃÇx + cos Œ∏ sin œÜ eÃÇy ‚àí sin Œ∏ eÃÇz
eÃÇœÜ = ‚àí sin œÜ eÃÇx + cos œÜ eÃÇy .
By the chain rule, if we have two sets of coordinates, say si and ci , and we
know the form a function f (si ) and the dependence of si on cj , we can find
P ‚àÇf
‚àÇsj
‚àÇf
= j ‚àÇs
, where |s means hold the other s‚Äôs fixed while varying
‚àÇci
j s ‚àÇci c
sj . In our case, the sj are the spherical coordinates r, Œ∏, œÜ, while the ci are
x, y, z.
Thus
Ô£´

Ô£∂

‚àÇf
‚àÇr
‚àÇf
‚àÇŒ∏
‚àÇf
‚àÇœÜ Ô£∏
~
‚àáf
= Ô£≠
+
+
eÃÇx
‚àÇr Œ∏œÜ ‚àÇx yz
‚àÇŒ∏ rœÜ ‚àÇx yz ‚àÇœÜ rŒ∏ ‚àÇx yz
Ô£´

Ô£∂

‚àÇf
‚àÇr
‚àÇf
‚àÇŒ∏
‚àÇf
‚àÇœÜ Ô£∏
+Ô£≠
+
+
eÃÇy (A.18)
‚àÇr Œ∏œÜ ‚àÇy xz
‚àÇŒ∏ rœÜ ‚àÇy xz ‚àÇœÜ rŒ∏ ‚àÇy xz

A.3. GRADIENT IN SPHERICAL COORDINATES

265
Ô£∂

Ô£´

‚àÇr
‚àÇŒ∏
‚àÇœÜ Ô£∏
‚àÇf
‚àÇf
‚àÇf
+
+
eÃÇz
+Ô£≠
‚àÇr Œ∏œÜ ‚àÇz xy
‚àÇŒ∏ rœÜ ‚àÇz xy ‚àÇœÜ rŒ∏ ‚àÇz xy
j
We will need all the partial derivatives ‚àÇs
. From r2 = x2 + y 2 + z 2 we see
‚àÇci
that
x
y
z
‚àÇr
‚àÇr
‚àÇr
=
=
= .
‚àÇx yz
r
‚àÇy xz
r
‚àÇz xy r
‚àö
From cos Œ∏ = z/r = z/ x2 + y 2 + z 2 ,

‚àí sin Œ∏

‚àízx
‚àÇŒ∏
‚àír2 cos Œ∏ sin Œ∏ cos œÜ
=
=
‚àÇx yz (x2 + y 2 + z 2 )3/2
r3

so
cos Œ∏ cos œÜ
‚àÇŒ∏
=
.
‚àÇx yz
r
Similarly,
‚àÇŒ∏
cos Œ∏ sin œÜ
.
=
‚àÇy xz
r
There is an extra term when differentiating w.r.t. z, from the numerator, so
‚àí sin Œ∏

‚àÇŒ∏
1 z2
1 ‚àí cos2 Œ∏
= ‚àí 3 =
= r‚àí1 sin2 Œ∏,
‚àÇz xy r r
r

so
‚àÇŒ∏
= ‚àír‚àí1 sin Œ∏.
‚àÇz xy
Finally, the derivatives of œÜ can easily be found from differentiating tan œÜ =
y/x. Using differentials,
sec2 œÜdœÜ =

dy
dy ydx
dx sin Œ∏ sin œÜ
‚àí 2 =
‚àí
x
x
r sin Œ∏ cos œÜ r sin2 Œ∏ cos2 œÜ

so
‚àÇœÜ
1 sin œÜ
=‚àí
‚àÇx yz
r sin Œ∏

‚àÇœÜ
1 cos œÜ
=
‚àÇy xz r sin Œ∏

‚àÇœÜ
= 0.
‚àÇz xy

266

APPENDIX A. APPENDICES

Now we are ready to plug this all into (A.18). Grouping together the
terms involving each of the three partial derivatives, we find
~
‚àáf
=

x
y
z
‚àÇf
eÃÇx + eÃÇy + eÃÇz
‚àÇr Œ∏œÜ r
r
r




cos Œ∏ cos œÜ
‚àÇf
cos Œ∏ sin œÜ
sin Œ∏
+
eÃÇx +
eÃÇy ‚àí
eÃÇz
‚àÇŒ∏ rœÜ
r
r
r
‚àÇf
1 sin œÜ
1 cos œÜ
+
‚àí
eÃÇx +
eÃÇy
‚àÇœÜ rŒ∏
r sin Œ∏
r sin Œ∏
=

!

!

1 ‚àÇf
1 ‚àÇf
‚àÇf
eÃÇr +
eÃÇŒ∏ +
eÃÇœÜ
‚àÇr Œ∏œÜ
r ‚àÇŒ∏ rœÜ
r sin Œ∏ ‚àÇœÜ rŒ∏

Thus we have derived the form for the gradient in spherical coordinates.

Bibliography
[1] Howard Anton. Elementary Linear Algebra. John Wiley, New York,
1973. QA251.A57 ISBN 0-471-03247-6.
[2] V. I. Arnol‚Äôd. Math. Methods of Classical Mechanics. Springer-Verlag,
New York, 1984. QA805.A6813.
[3] R. Creighton Buck. Advanced Calculus. McGraw-Hill, 1956.
[4] Tohru Eguchi, Peter B. Gilkey, and Andrew J. Hanson. Gravitation,
gauge theories and differential geometry. Physics Reports, 66, No. 6:213‚Äì
393, 1980. Doubtless there are more appropriate references, but I learned
this here.
[5] A. P. French. Special Relativity. W. W. Norton, New York, 1968. SBN
393-09793-5.
[6] Herbert Goldstein. Classical Mechanics. Addison-Wesley, Reading, Massachusetts, second edition, 1980. QA805.G6.
[7] I. S. Gradshtein and I. M. Ryzhik. Table of integrals, series, and products. Academic Press, New York, 1965. QA55.R943.
[8] Jorge V. JoseÃÄ and Eugene J. Saletan. Classical Mechanics, a Comtemporary Approach. Cambridge University Press, 1998. QC805.J73 ISBN
0-521-63636-1.
[9] L Landau and Lifschitz. Mechanics. Pergamon Press, Oxford, 2nd
edition, 1969. QA805.L283/1976.
[10] Jerry B. Marion and Stephen T. Thornton.
Classical Dynamics. Harcourt Brace Jovanovich, San Diego, 3rd ed edition, 1988.
QA845.M38/1988.
267

268

BIBLIOGRAPHY

[11] R. A. Matzner and L. C Shepley. Classical Mechanics. Prentice Hall,
Englewood Cliffs, NJ, 91. QC125.2.M37 ISBN 0-13-137076-6.
[12] L. Prandtl and O. G. Tietjens. Applied Hydro- and AeroMechanics.
Dover Publications, New York, NY, 1934. QA911.T564F.
[13] Morris Edgar Rose. Elementary Theory of Angular Momentum. Wiley,
New York, 1957. QC174.1.R7.
[14] Walter Rudin. Principles of Mathematical Analysis. McGraw-Hill, New
York, 1953.
[15] James H. Smith. Introduction to Special Relativity. W. A. Benjamin,
Inc, New York, 1965.
[16] M. Spivak. Differential Geometry, volume 1. Publish or Perish, Inc.,
1970.
[17] Keith R. Symon. Mechanics. Addison-Wesley, Reading, Massachusetts,
3rd edition, 1971. QC125.S98/1971 ISBN 0-201-07392-7.
[18] John R. Taylor. Classical Mechanics. University Science Books, Sausalito, California, 2005. QC125.2.T39 2004 ISBN 1-891389-22-X.
[19] O. G. Tietjens. Fundamentals of Hydro- and Aero-Mechanics. Maple
Press, York, PA, 1934. QA911.T564F.
[20] Eugene Wigner. Group Theory and Its Applications to Quantum Mechanics of Atomic Spectra. Academic Press, New York, 1959.

Index
O(N ), 89
1-forms, 154
accoustic modes, 139
action, 45
action-angle, 192
active, 88
adiabatic invariant, 222
angular momentum, 8
antisymmetric, 95
apogee, 72
apsidal angle, 75
associative, 91
attractor, 27
autonomous, 22
bac-cab, 76, 98, 261
Bernoulli‚Äôs equation, 150
body cone, 108
body coordinates, 86
Born-Oppenheimer, 126
bulk modulus, 145

composition, 89
conditionally periodic motion, 199
configuration space, 5, 44
conformal, 122
conservative force, 7
conserved, 5
conserved quantity, 6
continuum limit, 136
contravariant, 240
cotangent bundle, 20
covariant, 240
current, 248
current conservation, 249
D‚ÄôAlembert‚Äôs Principle, 40
deviatoric part, 144
diffeomorphism, 183
differential cross section, 81
differential k-form, 167
Dirac delta function, 140
dynamical balancing, 105
dynamical systems, 22

canonical transformation, 160
eccentricity, 72
canonical variables, 160
electrostatic potential, 56
center of mass, 9
elliptic fixed point, 30
centrifugal barrier, 68
elliptic integral, 33
Chandler wobble, 111
Emmy Noether, 242
closed, 171
enthalpy, 156
closed under, 91
equation of continuity, 149
complex structure on phase space, 157 ergodicity, 201
269

270
Euler‚Äôs equation, 150
Euler‚Äôs equations, 107
Euler‚Äôs Theorem, 92
exact, 154, 171
extended phase space, 6, 177
exterior derivative, 170
exterior product, 168
fixed points, 26
form invariant, 185
free energy, 156
functional, 45
gauge invariance, 57
gauge transformation, 57
generalized force, 17
generalized Hooke‚Äôs law, 145
generalized momentum, 48
generating function of the canonical
transformation, 179
generator, 95
Gibbs free energy, 156
glory scattering, 82
group, 91
group multiplication, 91

INDEX
identity, 91
ignorable coordinate, 48
impact parameter, 79
independent frequencies, 200
inertia ellipsoid, 109
inertia tensor, 98
inertial coordinates, 86
integrable system, 197
integral of the motion, 197
intrinsic spin, 186
invariant plane, 109
invariant sets of states, 26
invariant torus, 203
inverse, 87, 91
involution, 197
Jacobi identity, 164
kinetic energy, 7
Knonecker delta, 87

lab angle, 108
Lagrangian, 36
Lagrangian density, 139, 229
Laplace-Runge-Lenz vector, 76
Legendre transformation, 155
Levi-Civita, 95
Hamilton‚Äôs characteristic function, 188 Lie algebra, 166
Hamilton‚Äôs equations of motion, 52 line of nodes, 112
Hamilton‚Äôs principal function, 188
Liouville‚Äôs theorem, 166
Hamilton-Jacobi, 188
logistic equation, 22
Hamiltonian, 51, 155
Hamiltonian density, 235
magnetic vector potential, 56
hermitean conjugate, 118
major axis, 72
herpolhode, 110
mass matrix, 19, 53
Hodge dual, 254
material description, 147
holonomic constraints, 13
mean motion Hamiltonian, 223
Hooke‚Äôs constant, 145
minor axis, 72
hyperbolic fixed point, 28
moment of inertia, 100

INDEX
momentum, 5
natural symplectic structure, 176
non-degenerate, 177
nondegenerate system, 200
normal modes, 124
nutation, 117
oblate, 111
optical modes, 139
orbit, 5
orbital angular momentum, 186
order of the dynamical system, 22
orthogonal, 87
parallel axis theorem, 100
passive, 87
perigee, 72
period, 23
periodic, 23
perpendicular axis theorem, 103
phase curve, 21, 26
phase point, 21, 25
phase space, 6, 20
phase trajectory, 179
PoincareÃÅ‚Äôs Lemma, 172
point transformation, 38, 160
Poisson bracket, 163
Poisson‚Äôs theorem, 166
polhode, 109
potential energy, 7
precessing, 117
precession of the perihelion, 73
principal axes, 104
pseudovector, 96
rainbow scattering, 81
reduced mass, 66
relation among the frequencies, 200

271
rotation, 89
rotation about an axis, 89
scattering angle, 79
semi-major axis, 72
separatrix, 30
sign of the permutation, 168
similar, 118
similarity transformation, 118
spatial description, 148
stable, 26, 29
Stokes‚Äô Theorem, 175
strain tensor, 144
stream derivative, 37, 148
stress tensor, 143
stress-energy, 233
strongly stable, 27
structurally stable, 26
subgroup, 92
summation convention, 164
surface force, 142
symplectic, 161
symplectic structure, 22, 157
terminating motion, 27
torque, 8
total external force, 10
total mass, 9
total momentum, 9
trajectory, 5
transpose, 87, 118
turning point, 69, 70
unimodular, 91
unperturbed system, 206
unstable, 28
velocity function, 21
vibrations, 127

272
virtual displacement, 39
viscosity, 149
volume forces, 142
wave numbers, 138
wedge product, 168
work, 7
Young‚Äôs modulus, 145

INDEX

